{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ae588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since kmack/Phishing_urls couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\rrpra\\.cache\\huggingface\\datasets\\kmack___phishing_urls\\default\\0.0.0\\ef1558ba51b6b3e1a2c264ec8227be0a08736e10 (last modified on Sat Oct  4 18:12:33 2025).\n",
      "Using the latest cached version of the dataset since kmack/Phishing_urls couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\rrpra\\.cache\\huggingface\\datasets\\kmack___phishing_urls\\default\\0.0.0\\ef1558ba51b6b3e1a2c264ec8227be0a08736e10 (last modified on Sat Oct  4 18:12:33 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Seed fixed to 42\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from urllib.parse import urlparse\n",
    "from preprocess_datasets import all_dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "import random\n",
    "tqdm.pandas()\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"‚úÖ Seed fixed to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357bf0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî† Encoding structured URLs for Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 405756/405756 [01:01<00:00, 6644.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ train: Encoded 405756 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50719/50719 [00:07<00:00, 6529.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ valid: Encoded 50719 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50720/50720 [00:08<00:00, 6031.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ test: Encoded 50720 URLs\n",
      "\n",
      "‚úÖ All datasets encoded with proper start/end markers and padding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Character Encoding Setup\n",
    "# ============================================================\n",
    "\n",
    "# Allowed printable ASCII chars\n",
    "ascii_chars = [chr(i) for i in range(32, 127)]\n",
    "\n",
    "# Special control tokens\n",
    "special_tokens = [\n",
    "    '<PAD>', '<UNK>',\n",
    "]\n",
    "\n",
    "# Build vocab and mapping\n",
    "vocab = special_tokens + ascii_chars\n",
    "char2idx = {ch: i for i, ch in enumerate(vocab)}\n",
    "\n",
    "\n",
    "\n",
    "def encode(text, max_len=60):\n",
    "    indices = torch.full((max_len,), char2idx[\"<PAD>\"], dtype=torch.long)\n",
    "    text = text.lower()[:max_len]\n",
    "    for i, c in enumerate(text):\n",
    "        indices[i] = char2idx.get(c, char2idx[\"<UNK>\"])\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoded_data = {}\n",
    "frac = 1\n",
    "gen = all_dataset()\n",
    "\n",
    "x=0\n",
    "\n",
    "max_len=60\n",
    "next(gen)\n",
    "next(gen)\n",
    "next(gen)\n",
    "for name, splits in  gen:\n",
    "    encoded_data[name] = {}\n",
    "    print(f\"\\nüî† Encoding structured URLs for {name}...\")\n",
    "\n",
    "    for split_name, df in zip(['train', 'valid', 'test'], splits):\n",
    "        df = df.sample(frac=frac, random_state=42)\n",
    "        df[\"encode\"] = df[\"url\"].progress_apply(encode)\n",
    "        encoded_data[name][split_name] = df\n",
    "        print(f\"  ‚úÖ {split_name}: Encoded {len(df)} URLs\")\n",
    "\n",
    "    x+=1\n",
    "    if x > 0:\n",
    "        next(gen)\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ All datasets encoded with proper start/end markers and padding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeebb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Creating DataLoaders for Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)...\n",
      "‚úÖ DataLoaders ready for Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls) (Train/Val/Test)\n",
      "\n",
      "üöÄ All DataLoaders are ready in `dataloader_dict`!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Convert to TensorDataset and DataLoader\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 524\n",
    "\n",
    "dataloader_dict = {}\n",
    "\n",
    "def make_tensor_dataset(df):\n",
    "    url_tensor = torch.stack(list(df[\"encode\"]))\n",
    "    labels_tensor = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "    return TensorDataset(url_tensor, labels_tensor)\n",
    "\n",
    "for name, splits in encoded_data.items():\n",
    "    dataloader_dict[name] = {}\n",
    "    print(f\"\\nüì¶ Creating DataLoaders for {name}...\")\n",
    "    \n",
    "    train_set = make_tensor_dataset(splits[\"train\"])\n",
    "    val_set = make_tensor_dataset(splits[\"valid\"])\n",
    "    test_set = make_tensor_dataset(splits[\"test\"])\n",
    "    \n",
    "    dataloader_dict[name][\"train_loader\"] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    dataloader_dict[name][\"val_loader\"] = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    dataloader_dict[name][\"test_loader\"] = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    print(f\"‚úÖ DataLoaders ready for {name} (Train/Val/Test)\")\n",
    "\n",
    "print(\"\\nüöÄ All DataLoaders are ready in `dataloader_dict`!\")\n",
    "\n",
    "# Example Access:\n",
    "# dataloader_dict[\"dataset1\"][\"train_loader\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ea480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üîπ  Embeding_layer\n",
    "# =====================================================\n",
    "class Embeding_layer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size=256,\n",
    "                 d_model=128,\n",
    "                 max_len=100,\n",
    "                 n_out=128,):\n",
    "        super().__init__()\n",
    "\n",
    "        # üîπ Byte embedding layer (0‚Äì255)\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # üîπ Positional embeddings\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        # üîπ Final normalization\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.projection = nn.Linear(in_features=d_model, out_features=n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len) ‚Äî byte indices [0‚Äì255]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        positions = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        x = self.embedding(x) + self.pos_embedding(positions)\n",
    "\n",
    "        #x = self.encoder(x)\n",
    "        #x = self.embedding(x)\n",
    "        x = self.projection(self.final_norm(x))\n",
    "\n",
    "        return x  # (B, L, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53464d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        w = x.mean(dim=2)                          # Global Average Pooling -> (B, C)\n",
    "        w = self.dropout(F.elu(self.fc1(w)))\n",
    "        w = self.sigmoid(self.fc2(w))\n",
    "        w = w.unsqueeze(2)                         # (B, C, 1)\n",
    "        return x * w                               # scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc210f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Residual Depthwise-Separable Multi-Kernel Block\n",
    "class ResidualConvBlockDW(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_sizes=[3, 5, 7], reduction=16):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList()\n",
    "\n",
    "        mid_ch = max(in_ch // 16, 8)  # reduce dimension before heavy convs\n",
    "\n",
    "        for k in kernel_sizes:\n",
    "            branch = nn.Sequential(\n",
    "                # (B) Reduce channels first\n",
    "                nn.Conv1d(in_ch, mid_ch, kernel_size=1, bias=False),\n",
    "                #nn.BatchNorm1d(mid_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout1d(0.5),\n",
    "\n",
    "                # (A) Depthwise conv\n",
    "                nn.Conv1d(mid_ch, mid_ch, kernel_size=k, padding=k // 2, groups=mid_ch, bias=False),\n",
    "                #nn.BatchNorm1d(mid_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout1d(0.5),\n",
    "\n",
    "                # Pointwise to expand to out_ch\n",
    "                nn.Conv1d(mid_ch, out_ch, kernel_size=1, bias=False),\n",
    "                #nn.BatchNorm1d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            self.branches.append(branch)\n",
    "\n",
    "        # Combine all kernel branches\n",
    "        self.merge_conv = nn.Conv1d(out_ch * len(kernel_sizes), out_ch, kernel_size=1, bias=False)\n",
    "        #self.merge_bn = nn.BatchNorm1d(out_ch)\n",
    "        \n",
    "        self.se = SEBlock(out_ch, reduction)\n",
    "        self.shortcut = nn.Conv1d(in_ch, out_ch, kernel_size=1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Parallel multi-kernel branches\n",
    "        out = [branch(x) for branch in self.branches]\n",
    "        out = torch.cat(out, dim=1)\n",
    "\n",
    "        out = self.merge_conv(out)\n",
    "        #out = self.merge_bn(out)\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class URLBinaryCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, maxlen=100):\n",
    "        super(URLBinaryCNN, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "        self.embeding_layer = nn.ModuleDict({\n",
    "            \"embeding\":  Embeding_layer(vocab_size=vocab_size, max_len=maxlen, d_model=256, n_out=embed_dim)\n",
    "        })\n",
    "\n",
    "        # 2Ô∏è‚É£ Shared Layer (Global)\n",
    "        self.shared_layer = nn.ModuleDict({\n",
    "            \"conv\": ResidualConvBlockDW(embed_dim, 64, kernel_sizes=[3]),\n",
    "            #\"max_pool\": nn.MaxPool1d(kernel_size=2),\n",
    "            \"bilstm\": nn.LSTM(input_size=64, hidden_size=64, batch_first=True, bidirectional=True),\n",
    "            \"layer_norm\": nn.LayerNorm(64*2),\n",
    "            \"fc1\": nn.Linear(64 *2* maxlen , 64),\n",
    "            \"relu1\": nn.ReLU(),\n",
    "            \"dropout1\": nn.Dropout(0.5),\n",
    "            \n",
    "        })\n",
    "\n",
    "        # 3Ô∏è‚É£ Personalization Layer (Local)\n",
    "        self.personal_layer = nn.ModuleDict({\n",
    "            \"fc2\": nn.Linear(64, 64),\n",
    "            \"relu2\": nn.ReLU(),\n",
    "            \"dropout2\": nn.Dropout(0.5),\n",
    "            \"head\": nn.Linear(64, 1)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transformer\n",
    "        x = self.embeding_layer[\"embeding\"](x)\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        # Shared layers\n",
    "        #x = self.shared_layer[\"conv\"](x)\n",
    "        #x = self.shared_layer[\"max_pool\"](x)\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        x, _ = self.shared_layer[\"bilstm\"](x)\n",
    "        #x = self.shared_layer[\"layer_norm\"](x)\n",
    "        #x = x[:, -1, :]\n",
    "        x = x.flatten(1)\n",
    "        x = self.shared_layer[\"dropout1\"](self.shared_layer[\"relu1\"](self.shared_layer[\"fc1\"](x)))\n",
    "        # Personalization head\n",
    "        x = self.personal_layer[\"dropout2\"](self.personal_layer[\"relu2\"](self.personal_layer[\"fc2\"](x)))\n",
    "        x = self.personal_layer[\"head\"](x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        \"\"\"Return deep features before final FC layers.\"\"\"\n",
    "        # Transformer\n",
    "        x = self.embeding_layer[\"embeding\"](x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # Shared layers\n",
    "        x = self.shared_layer[\"conv\"](x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.shared_layer[\"bilstm\"](x)\n",
    "        x = self.shared_layer[\"layer_norm\"](x)\n",
    "        #x = x[:, -1, :]\n",
    "        x = x.flatten(1)\n",
    "        x = self.shared_layer[\"dropout1\"](self.shared_layer[\"relu1\"](self.shared_layer[\"fc1\"](x)))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64290975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 criterion, \n",
    "                 global_optimizer=None,\n",
    "                 personal_optimizer = None, \n",
    "                 scheduler_g=None,\n",
    "                 scheduler_p=None,\n",
    "                 train_loader=None, \n",
    "                 val_loader=None,   \n",
    "                 run_name=\"my_experiment\",\n",
    "                 save = 0,\n",
    "                 device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        \n",
    "        \"\"\"\n",
    "        optimizer_groups: dict with keys like {\"transformer\": optimizer1, \"cnn\": optimizer2}\n",
    "        schedulers: dict with keys matching optimizer_groups (optional)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_train_loss = float('inf')\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.global_params = []\n",
    "        self.persnalization_params = []\n",
    "        for name, param in model.embeding_layer.named_parameters():\n",
    "            self.global_params.append(param)\n",
    "        for name, param in model.shared_layer.named_parameters():\n",
    "            self.global_params.append(param)\n",
    "        for name, param in model.personal_layer.named_parameters():\n",
    "            self.persnalization_params.append(param)\n",
    "\n",
    "\n",
    "\n",
    "        self.global_optimizer = optim.NAdam(self.global_params, lr=1e-4) if global_optimizer is None  else global_optimizer\n",
    "        self.personal_optimizer = optim.NAdam(self.persnalization_params, lr=1e-3) if personal_optimizer is None else personal_optimizer\n",
    "        self.scheduler_g = optim.lr_scheduler.ReduceLROnPlateau(self.global_optimizer, mode='min', factor=0.5, patience=2) if scheduler_g is None  else scheduler_g\n",
    "        self.scheduler_p = optim.lr_scheduler.ReduceLROnPlateau(self.personal_optimizer, mode='min', factor=0.5, patience=2) if scheduler_p is None  else scheduler_p\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.batch_train_losses = []\n",
    "        self.batch_train_accs = []\n",
    "        self.epoch_train_losses = []\n",
    "        self.epoch_train_accs = []\n",
    "        self.epoch_val_losses = []\n",
    "        self.epoch_val_accs = []\n",
    "\n",
    "        self.batch_time = []\n",
    "        self.epoch_time = []\n",
    "        self.save = save\n",
    "        self._create_run_folder(folder_name=run_name)\n",
    "        self.best_model_path = os.path.join(self.run_folder, \"best_model.pt\")\n",
    "\n",
    "        if self.save > 1: \n",
    "            # --------------------------------------------------------------------\n",
    "            #                SAVE MODEL CONFIGURATION INTO JSON FILE\n",
    "            # --------------------------------------------------------------------\n",
    "\n",
    "            def count_params(module):\n",
    "                return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "            def count_trainable(module):\n",
    "                return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "            model_config = {\n",
    "                \"run_name\": run_name,\n",
    "                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"manual_notes\": '',\n",
    "\n",
    "                # -------------------------\n",
    "                # MODEL STRUCTURE\n",
    "                # -------------------------\n",
    "                \"model_pipeline\": str(model),  # string version\n",
    "                \"model_layers\": {\n",
    "                    \"embedding_layer_params\": count_params(model.embeding_layer),\n",
    "                    \"shared_layer_params\": count_params(model.shared_layer),\n",
    "                    \"personal_layer_params\": count_params(model.personal_layer),\n",
    "                },\n",
    "\n",
    "                # -------------------------\n",
    "                # TRAINABLE / NON-TRAINABLE\n",
    "                # -------------------------\n",
    "                \"trainable_parameters\": count_trainable(model),\n",
    "                \"total_parameters\": sum(p.numel() for p in model.parameters()),\n",
    "\n",
    "                \"global_parameter_count\": len(self.global_params),\n",
    "                \"personal_parameter_count\": len(self.persnalization_params),\n",
    "\n",
    "                # -------------------------\n",
    "                # OPTIMIZER / SCHEDULER SETTINGS\n",
    "                # -------------------------\n",
    "                \"global_optimizer\": str(self.global_optimizer),\n",
    "                \"personal_optimizer\": str(self.personal_optimizer),\n",
    "                \"scheduler_global\": str(self.scheduler_g),\n",
    "                \"scheduler_personal\": str(self.scheduler_p),\n",
    "\n",
    "                # -------------------------\n",
    "                # TRAINING SETTINGS\n",
    "                # -------------------------\n",
    "                \"batch_size\": train_loader.batch_size if train_loader is not None else None,\n",
    "                \"num_train_batches\": len(train_loader) if train_loader is not None else None,\n",
    "                \"num_val_batches\": len(val_loader) if val_loader is not None else None,\n",
    "            }\n",
    "\n",
    "            # Save JSON config\n",
    "            with open(os.path.join(self.run_folder, \"model_configuration.json\"), \"w\") as f:\n",
    "                json.dump(model_config, f, indent=4)\n",
    "\n",
    "            print(\"üìÅ Model configuration saved at:\", os.path.join(self.run_folder, \"model_configuration.json\"))\n",
    "\n",
    "    def freeze_module(self, module):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_module(self, module):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def train(self, epochs_list=[4,3,3], early_stopping=True, frac=1.0, val_frac=1.0,start=0,  log=0):\n",
    "        train_length = len(self.train_loader)\n",
    "        for phase, epochs in enumerate(epochs_list):\n",
    "            for epoch in range(epochs):\n",
    "                et0 = time.perf_counter()\n",
    "                if phase == 0:\n",
    "                    for param in self.model.embeding_layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    for param in self.model.shared_layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    for param in self.model.personal_layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    active_optims = [self.global_optimizer, self.personal_optimizer]\n",
    "                    active_scheds = [self.scheduler_g, self.scheduler_p]\n",
    "                    phase_name = \"global+personal\"\n",
    "                elif phase == 1:\n",
    "                    # üéØ Train CNN/LSTM/FC ‚Äî freeze Transformer\n",
    "                    for param in self.model.embeding_layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    for param in self.model.shared_layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    for param in self.model.personal_layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    active_optims = [self.global_optimizer]\n",
    "                    active_scheds = [self.scheduler_g]\n",
    "                    phase_name = \"global\"\n",
    "                else:\n",
    "                    for param in self.model.embeding_layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    for param in self.model.shared_layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    for param in self.model.personal_layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    active_optims = [self.personal_optimizer]\n",
    "                    active_scheds = [self.scheduler_p]\n",
    "                    phase_name = \"personal\"\n",
    "                self.model.train()\n",
    "                train_loss, correct_train, total_train = 0, 0, 0\n",
    "                max_batches = int(train_length * (frac+start)) +1 \n",
    "                start_batch = int(train_length * start)\n",
    "\n",
    "                for batch_idx, (batch_x, batch_y) in enumerate(self.train_loader):\n",
    "                    if batch_idx < start_batch:\n",
    "                        continue\n",
    "                    elif batch_idx >= max_batches:\n",
    "                        break\n",
    "                    \n",
    "                    bt0 = time.perf_counter()\n",
    "                    batch_x, batch_y = batch_x.to(self.device, non_blocking=True), batch_y.to(self.device, non_blocking=True).float().unsqueeze(1)\n",
    "                    \n",
    "                    for opt in active_optims:\n",
    "                        opt.zero_grad()\n",
    "\n",
    "                    outputs = self.model(batch_x)\n",
    "                    loss = self.criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "\n",
    "                    for opt in active_optims:\n",
    "                        opt.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # === Metrics ===\n",
    "                    batch_loss = loss.item()\n",
    "                    preds = (outputs >= 0.5).float()\n",
    "                    batch_acc = (preds == batch_y).float().mean().item()\n",
    "\n",
    "                    if log >= 1 and (batch_idx + 1) % (20/log) == 0:\n",
    "                        print(f\"\\rEpoch {epoch+1}/{epochs}: Training {phase_name} | \"\n",
    "                            f\"Batch {batch_idx+1}/{max_batches} | \"\n",
    "                            f\"Loss: {batch_loss:.4f}, Acc: {batch_acc:.4f}\", end='')\n",
    "                    \n",
    "                    batch_time = time.perf_counter() - bt0\n",
    "\n",
    "                    self.batch_time.append(batch_time)\n",
    "\n",
    "\n",
    "                    self.batch_train_losses.append(batch_loss)\n",
    "                    self.batch_train_accs.append(batch_acc)\n",
    "\n",
    "\n",
    "                if log >= 2:\n",
    "                    print(f'\\r total training batch size {max_batches-start_batch}'.ljust(100), end='')\n",
    "                    with torch.no_grad():\n",
    "                        for batch_idx, (batch_x, batch_y) in enumerate(self.train_loader):\n",
    "                            if batch_idx < start_batch:\n",
    "                                continue\n",
    "                            elif batch_idx >= max_batches:\n",
    "                                break\n",
    "                            batch_x, batch_y = batch_x.to(self.device, non_blocking=True), batch_y.to(self.device, non_blocking=True).float().unsqueeze(1)\n",
    "\n",
    "                            outputs = self.model(batch_x)\n",
    "                            loss = self.criterion(outputs, batch_y)\n",
    "\n",
    "                            batch_loss = loss.item()\n",
    "                            preds = (outputs >= 0.5).float()\n",
    "                            batch_acc = (preds == batch_y).float().mean().item()\n",
    "\n",
    "                            train_loss += batch_loss * batch_x.size(0)\n",
    "                            correct_train += (preds == batch_y).sum().item()\n",
    "                            total_train += batch_x.size(0)\n",
    "\n",
    "                        avg_train_loss = train_loss / total_train\n",
    "                        train_acc = correct_train / total_train\n",
    "                        self.epoch_train_losses.append(avg_train_loss)\n",
    "                        self.epoch_train_accs.append(train_acc)\n",
    "\n",
    "\n",
    "                    # === Validation ===\n",
    "                if self.val_loader is not None:\n",
    "                    avg_val_loss, val_acc = self.evaluate(val_frac)\n",
    "\n",
    "                    \n",
    "                    if log > 1:\n",
    "                        print(f\"\\rEpoch {epoch+1}/{epochs} Training {phase_name}| \"\n",
    "                            f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "                            f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "                        self.epoch_val_losses.append(avg_val_loss)\n",
    "                        self.epoch_val_accs.append(val_acc)\n",
    "\n",
    "                else:\n",
    "                    if log > 1:\n",
    "                        print(f\"\\rEpoch {epoch+1}/{epochs} Training {phase_name}| \"\n",
    "                            f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "                for sched in active_scheds:\n",
    "                    if phase == 1 or self.val_loader is not None:\n",
    "                        sched.step(round(val_acc, 4))\n",
    "\n",
    "                epoch_time = time.perf_counter() - et0\n",
    "                self.epoch_time.append(epoch_time)\n",
    "\n",
    "                if self.val_loader is not None and avg_val_loss is not None:\n",
    "                    if avg_val_loss < self.best_val_loss:\n",
    "                        self.best_val_loss = avg_val_loss\n",
    "                        torch.save(self.model.state_dict(), os.path.join(self.run_folder, \"best_loss_model.pt\"))\n",
    "                        if log >= 1:\n",
    "                            print(f\"üíæ Best Loss Model Saved! Val Loss = {avg_val_loss:.4f}\")\n",
    "        if self.save > 1:\n",
    "            self.save_training_data()\n",
    "\n",
    "\n",
    "    def evaluate(self, frac=1.0, start=0, log=2):\n",
    "        self.model.eval()\n",
    "        val_loss, correct_val, total_val = 0, 0, 0\n",
    "        max_batches = max(int(len(self.val_loader) * (frac+start)), 0)+1\n",
    "        start_batch = int(len(self.val_loader) * start)\n",
    "        if log > 2:\n",
    "            print('\\rstarting from batch', start_batch, 'ending to batch', max_batches, f'total validation batch size {max_batches}')\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (batch_x, batch_y) in enumerate(self.val_loader):\n",
    "                if batch_idx < start_batch:\n",
    "                    continue\n",
    "                elif batch_idx >= max_batches:\n",
    "                    break\n",
    "                batch_x, batch_y = batch_x.to(self.device, non_blocking=True), batch_y.to(self.device, non_blocking=True).float().unsqueeze(1)\n",
    "                outputs = self.model(batch_x)\n",
    "                loss = self.criterion(outputs, batch_y)\n",
    "                avg_batch_loss = loss.item()\n",
    "                val_loss += avg_batch_loss * batch_x.size(0)\n",
    "                preds = (outputs >= 0.5).float()\n",
    "                correct_val += (preds == batch_y).sum().item()\n",
    "                total_val += batch_x.size(0)\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = correct_val / total_val\n",
    "        return avg_val_loss, val_acc\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device).float().unsqueeze(1)\n",
    "\n",
    "                outputs = self.model(batch_x)\n",
    "                probs = outputs.cpu().numpy().flatten()\n",
    "                preds = (outputs >= 0.5).float().cpu().numpy().flatten()\n",
    "                targets = batch_y.cpu().numpy().flatten()\n",
    "\n",
    "                all_probs.extend(probs)\n",
    "                all_preds.extend(preds)\n",
    "                all_targets.extend(targets)\n",
    "\n",
    "        # Convert to arrays\n",
    "        all_probs = np.array(all_probs)\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_targets = np.array(all_targets)\n",
    "\n",
    "        # Metrics\n",
    "        try:\n",
    "            roc = roc_auc_score(all_targets, all_probs)\n",
    "        except:\n",
    "            roc = None\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": float(accuracy_score(all_targets, all_preds)),\n",
    "            \"precision\": float(precision_score(all_targets, all_preds, zero_division=0)),\n",
    "            \"recall\": float(recall_score(all_targets, all_preds, zero_division=0)),\n",
    "            \"f1\": float(f1_score(all_targets, all_preds, zero_division=0)),\n",
    "            \"roc_auc\": None if roc is None else float(roc),\n",
    "            \"r2_score\": float(r2_score(all_targets, all_probs)),\n",
    "            \"classification_report\": classification_report(all_targets, all_preds, output_dict=True),\n",
    "            \"confusion_matrix\": confusion_matrix(all_targets, all_preds).tolist()\n",
    "        }\n",
    "\n",
    "        # Save to JSON\n",
    "        save_path = os.path.join(self.run_folder, \"test_metrics.json\")\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "\n",
    "        print(f\"‚úÖ Test metrics saved to: {save_path}\")\n",
    "        return metrics\n",
    "\n",
    "    def _create_run_folder(self, folder_name=\"run\"):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "        self.main_dir = \"training_runs\"\n",
    "        os.makedirs(self.main_dir, exist_ok=True)\n",
    "\n",
    "        self.run_folder = os.path.join(self.main_dir, f\"{timestamp}_{folder_name}\")\n",
    "        os.makedirs(self.run_folder, exist_ok=True)\n",
    "\n",
    "        print(\"Run folder created at:\", self.run_folder)\n",
    "\n",
    "    def save_training_data(self):\n",
    "        data = {\n",
    "            \"batch_train_losses\": self.batch_train_losses,\n",
    "            \"batch_train_accs\": self.batch_train_accs,\n",
    "            \"epoch_train_losses\": self.epoch_train_losses,\n",
    "            \"epoch_train_accs\": self.epoch_train_accs,\n",
    "            \"epoch_val_losses\": self.epoch_val_losses,\n",
    "            \"epoch_val_accs\": self.epoch_val_accs,\n",
    "            \"batch_times\": self.batch_time,\n",
    "            \"epoch_times\": self.epoch_time\n",
    "        }\n",
    "\n",
    "\n",
    "        # Save as JSON\n",
    "        with open(os.path.join(self.run_folder, \"logs.json\"), \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14896532",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ Training model on DATASET 4 (KAGGELS/TARUNTIWARIHP/PHISHING-SITE-URLS) dataset\n",
      "======================================================================\n",
      "__________üß© Using 100% of training data___________\n",
      "Run folder created at: training_runs\\2025-11-20_08-26-39_depthwisecnn(64,64)[3] bilstm(64,64) size with layer normalization\n",
      "üìÅ Model configuration saved at: training_runs\\2025-11-20_08-26-39_depthwisecnn(64,64)[3] bilstm(64,64) size with layer normalization\\model_configuration.json\n",
      "Epoch 1/4 Training global+personal| Train Loss: 0.1397, Train Acc: 0.9496 | Val Loss: 0.1336, Val Acc: 0.9503\n",
      "üíæ Best Loss Model Saved! Val Loss = 0.1336\n",
      "Epoch 2/4 Training global+personal| Train Loss: 0.1004, Train Acc: 0.9651 | Val Loss: 0.0986, Val Acc: 0.9642\n",
      "üíæ Best Loss Model Saved! Val Loss = 0.0986\n",
      "Epoch 3/4 Training global+personal| Train Loss: 0.0839, Train Acc: 0.9722 | Val Loss: 0.0859, Val Acc: 0.9696\n",
      "üíæ Best Loss Model Saved! Val Loss = 0.0859\n",
      "Epoch 4/4 Training global+personal| Train Loss: 0.1036, Train Acc: 0.9651 | Val Loss: 0.1100, Val Acc: 0.9618\n",
      "‚úÖ Test metrics saved to: training_runs\\2025-11-20_08-26-39_depthwisecnn(64,64)[3] bilstm(64,64) size with layer normalization\\test_metrics.json\n",
      "\n",
      "üìä Generating graphs...\n",
      "\n",
      "   ‚úî Saved batch_loss_vs_batch.png\n",
      "   ‚úî Saved batch_acc_vs_batch.png\n",
      "   ‚úî Saved batch_loss_vs_time.png\n",
      "   ‚úî Saved batch_acc_vs_time.png\n",
      "   ‚úî Saved epoch_train_loss_vs_epoch.png\n",
      "   ‚úî Saved epoch_train_acc_vs_epoch.png\n",
      "   ‚úî Saved epoch_val_loss_vs_epoch.png\n",
      "   ‚úî Saved epoch_val_acc_vs_epoch.png\n",
      "   ‚úî Saved epoch_train_loss_vs_time.png\n",
      "   ‚úî Saved epoch_train_acc_vs_time.png\n",
      "   ‚úî Saved epoch_val_loss_vs_time.png\n",
      "   ‚úî Saved epoch_val_acc_vs_time.png\n",
      "\n",
      "‚úÖ All available graphs saved in: training_runs\\2025-11-20_08-26-39_depthwisecnn(64,64)[3] bilstm(64,64) size with layer normalization\\graphs\n",
      "\n",
      " All datasets trained successfully!\n",
      "\n",
      "======================================================================\n",
      "Final Validation Accuracy Summary\n",
      "======================================================================\n",
      "Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls) | Val Acc: 0.1100 | Val Loss: 0.9618\n"
     ]
    }
   ],
   "source": [
    "from plot_graph import plot_run\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# üîß Training Config\n",
    "# ============================================================\n",
    "num_epochs = [4,0,0]\n",
    "lr_g = 0.001\n",
    "lr_p = 0.001\n",
    "\n",
    "# Store all dataset metrics\n",
    "all_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# üîÅ Training Loop for Each Dataset\n",
    "# ============================================================\n",
    "nn_model = {}\n",
    "for dataset_name, loaders in dataloader_dict.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"üöÄ Training model on {dataset_name.upper()} dataset\")\n",
    "    print(\"=\"*70)\n",
    "    for frac in  [1]:\n",
    "        print(f\"üß© Using {frac*100:.0f}% of training data\".center(50, '_'))\n",
    "        train_loader = loaders[\"train_loader\"]\n",
    "        val_loader = loaders[\"val_loader\"]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Initialize model, loss, optimizer\n",
    "        nn_model[dataset_name] = URLBinaryCNN(vocab_size=len(vocab), embed_dim=64, maxlen = 60).to(device)\n",
    "        global_params = []\n",
    "        persnalization_params = []\n",
    "        for name, param in nn_model[dataset_name].embeding_layer.named_parameters():\n",
    "            global_params.append(param)\n",
    "        for name, param in nn_model[dataset_name].shared_layer.named_parameters():\n",
    "            global_params.append(param)\n",
    "        for name, param in nn_model[dataset_name].personal_layer.named_parameters():\n",
    "            persnalization_params.append(param)\n",
    "        criterion = nn.BCELoss()\n",
    "        personal_optimizer = torch.optim.NAdam(global_params, lr=lr_p, weight_decay=lr_p/10)\n",
    "        global_optimizer = torch.optim.NAdam(persnalization_params, lr=lr_g, weight_decay=lr_g/10)\n",
    "        personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(personal_optimizer, mode='max', factor=0.5, patience=3)\n",
    "        global_scheduler = optim.lr_scheduler.ReduceLROnPlateau(global_optimizer, mode='max', factor=0.5, patience=3)\n",
    "        run_name='depthwisecnn(64,64)[3] bilstm(64,64) size with layer normalization'\n",
    "        trainer = Train(nn_model[dataset_name], criterion,run_name=run_name, train_loader=train_loader, val_loader=val_loader, personal_optimizer=personal_optimizer, global_optimizer=global_optimizer, scheduler_g=global_scheduler, scheduler_p=personal_scheduler, save=2)\n",
    "        # Lists to track performance\n",
    "        trainer.train(num_epochs,frac=frac,val_frac=frac, log=2)\n",
    "        trainer.test(loaders['test_loader'])\n",
    "        plot_run(trainer.run_folder)\n",
    "    \n",
    "\n",
    "    # Store all results for this dataset\n",
    "    all_results[dataset_name] = {\n",
    "        \"batch_train_losses\": trainer.batch_train_losses,\n",
    "        \"batch_train_accs\": trainer.batch_train_accs,\n",
    "        \"epoch_train_losses\": trainer.epoch_train_losses,\n",
    "        \"epoch_train_accs\": trainer.epoch_train_accs,\n",
    "        \"epoch_val_losses\": trainer.epoch_val_losses,\n",
    "        \"epoch_val_accs\": trainer.epoch_val_accs,\n",
    "        \"batch_times\": trainer.batch_time,\n",
    "        \"epoch_times\": trainer.epoch_time\n",
    "    }\n",
    "\n",
    "print(\"\\n All datasets trained successfully!\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary of All Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Final Validation Accuracy Summary\")\n",
    "print(\"=\"*70)\n",
    "for name, res in all_results.items():\n",
    "    print(f\"{name:<20} | Val Acc: {res[\"epoch_val_losses\"][-1]:.4f} | Val Loss: {res[\"epoch_val_accs\"][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "844a1b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_loader', 'val_loader', 'test_loader'])\n"
     ]
    }
   ],
   "source": [
    "print(loaders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69193bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All graphs saved in: training_runs\\only cnn with kernal 3 outdimention 64_2025-11-20_02-38-01\\graphs\n"
     ]
    }
   ],
   "source": [
    "plot_run(r\"training_runs\\only cnn with kernal 3 outdimention 64_2025-11-20_02-38-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cd12fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_datasets                                    | test_datasets                                                                                                                                       \n",
      "                                                  | Dataset 1 (Malicious URLs)                      | Dataset 2 (ndarvind/phiusiil-phishing)          | Dataset 3 (kmack/Phishing_urls)                 \n",
      "==================================================|=================================================|=================================================|=================================================|\n",
      "Dataset 1 (Malicious URLs)                        | 0.0773,0.9748                                   | 3.0455,0.5779                                   | 2.2636,0.5212                                   \n",
      "Dataset 2 (ndarvind/phiusiil-phishing)            | 1.2805,0.8101                                   | 0.1402,0.9974                                   | 3.9363,0.4883                                   \n",
      "Dataset 3 (kmack/Phishing_urls)                   | 0.3575,0.8447                                   | 2.9580,0.1979                                   | 0.2547,0.8941                                   \n"
     ]
    }
   ],
   "source": [
    "#cross dataset accuracy\n",
    "print(\"train_datasets\".ljust(50,' ')+\"| test_datasets\".ljust(150,' '))\n",
    "print(' '*50, end='')\n",
    "for test_datset_name in nn_model:\n",
    "    print(f\"| {test_datset_name}\".ljust(50,' '), end='')\n",
    "print()\n",
    "print('='+(('='*49)+'|')*4)\n",
    "for train_dataset_name in nn_model:\n",
    "    print(f'{train_dataset_name}'.ljust(50,' '), end='')\n",
    "    for test_dataset_name in nn_model.keys():\n",
    "        train_loader = dataloader_dict[test_dataset_name]['train_loader']\n",
    "        test_loader = dataloader_dict[test_dataset_name]['test_loader']\n",
    "        trainer = Train(nn_model[train_dataset_name], criterion, train_loader=train_loader, val_loader=test_loader)\n",
    "        avg_val_loss, val_acc = trainer.evaluate(log=0)   \n",
    "        print(f\"| {avg_val_loss:.4f},{val_acc:.4f}\".ljust(50,' '), end='')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6541caa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Dataset 1 (Malicious URLs)', 'Dataset 2 (ndarvind/phiusiil-phishing)', 'Dataset 3 (kmack/Phishing_urls)'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ad9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Extracting Train Features:   0%|          | 0/798 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (31440x128 and 7680x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc=\u001b[33m\"\u001b[39m\u001b[33müîç Extracting Train Features\u001b[39m\u001b[33m\"\u001b[39m, unit=\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     11\u001b[39m     x_batch = x_batch.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     feats = \u001b[43mnn_model\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     features.append(feats.cpu().numpy())\n\u001b[32m     14\u001b[39m     labels.append(y_batch.cpu().numpy())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mURLBinaryCNN.extract_features\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     60\u001b[39m x = \u001b[38;5;28mself\u001b[39m.shared_layer[\u001b[33m\"\u001b[39m\u001b[33mlayer_norm\u001b[39m\u001b[33m\"\u001b[39m](x)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m#x = x[:, -1, :]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m x = \u001b[38;5;28mself\u001b[39m.shared_layer[\u001b[33m\"\u001b[39m\u001b[33mdropout1\u001b[39m\u001b[33m\"\u001b[39m](\u001b[38;5;28mself\u001b[39m.shared_layer[\u001b[33m\"\u001b[39m\u001b[33mrelu1\u001b[39m\u001b[33m\"\u001b[39m](\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshared_layer\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfc1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (31440x128 and 7680x64)"
     ]
    }
   ],
   "source": [
    "nn_model[dataset_name]\n",
    "features, labels = [], []\n",
    "\n",
    "# üîπ Extract CNN features for training set\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=\"üîç Extracting Train Features\", unit=\"batch\"):\n",
    "        x_batch = x_batch.to(device, non_blocking=True)\n",
    "        feats = nn_model[dataset_name].extract_features(x_batch)\n",
    "        features.append(feats.cpu().numpy())\n",
    "        labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "X_train = np.concatenate(features, axis=0)\n",
    "y_train = np.concatenate(labels, axis=0)\n",
    "\n",
    "# Free memory before val extraction\n",
    "del features, labels, x_batch, y_batch, feats\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# üîπ Extract CNN features for validation set\n",
    "features, labels = [], []\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(val_loader, desc=\"üîç Extracting Val Features\", unit=\"batch\"):\n",
    "        x_batch = x_batch.to(device, non_blocking=True)\n",
    "        feats = nn_model[dataset_name].extract_features(x_batch)\n",
    "        features.append(feats.cpu().numpy())\n",
    "        labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "X_val = np.concatenate(features, axis=0)\n",
    "y_val = np.concatenate(labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de5dd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.66290\n",
      "[1]\tvalidation_0-logloss:0.64412\n",
      "[2]\tvalidation_0-logloss:0.62610\n",
      "[3]\tvalidation_0-logloss:0.60878\n",
      "[4]\tvalidation_0-logloss:0.59213\n",
      "[5]\tvalidation_0-logloss:0.57611\n",
      "[6]\tvalidation_0-logloss:0.56067\n",
      "[7]\tvalidation_0-logloss:0.54580\n",
      "[8]\tvalidation_0-logloss:0.53145\n",
      "[9]\tvalidation_0-logloss:0.51761\n",
      "[10]\tvalidation_0-logloss:0.50425\n",
      "[11]\tvalidation_0-logloss:0.49134\n",
      "[12]\tvalidation_0-logloss:0.47886\n",
      "[13]\tvalidation_0-logloss:0.46680\n",
      "[14]\tvalidation_0-logloss:0.45513\n",
      "[15]\tvalidation_0-logloss:0.44383\n",
      "[16]\tvalidation_0-logloss:0.43289\n",
      "[17]\tvalidation_0-logloss:0.42230\n",
      "[18]\tvalidation_0-logloss:0.41203\n",
      "[19]\tvalidation_0-logloss:0.40208\n",
      "[20]\tvalidation_0-logloss:0.39244\n",
      "[21]\tvalidation_0-logloss:0.38308\n",
      "[22]\tvalidation_0-logloss:0.37400\n",
      "[23]\tvalidation_0-logloss:0.36518\n",
      "[24]\tvalidation_0-logloss:0.35663\n",
      "[25]\tvalidation_0-logloss:0.34832\n",
      "[26]\tvalidation_0-logloss:0.34025\n",
      "[27]\tvalidation_0-logloss:0.33240\n",
      "[28]\tvalidation_0-logloss:0.32478\n",
      "[29]\tvalidation_0-logloss:0.31737\n",
      "[30]\tvalidation_0-logloss:0.31017\n",
      "[31]\tvalidation_0-logloss:0.30316\n",
      "[32]\tvalidation_0-logloss:0.29635\n",
      "[33]\tvalidation_0-logloss:0.28972\n",
      "[34]\tvalidation_0-logloss:0.28326\n",
      "[35]\tvalidation_0-logloss:0.27698\n",
      "[36]\tvalidation_0-logloss:0.27087\n",
      "[37]\tvalidation_0-logloss:0.26491\n",
      "[38]\tvalidation_0-logloss:0.25912\n",
      "[39]\tvalidation_0-logloss:0.25347\n",
      "[40]\tvalidation_0-logloss:0.24797\n",
      "[41]\tvalidation_0-logloss:0.24261\n",
      "[42]\tvalidation_0-logloss:0.23739\n",
      "[43]\tvalidation_0-logloss:0.23230\n",
      "[44]\tvalidation_0-logloss:0.22734\n",
      "[45]\tvalidation_0-logloss:0.22251\n",
      "[46]\tvalidation_0-logloss:0.21779\n",
      "[47]\tvalidation_0-logloss:0.21320\n",
      "[48]\tvalidation_0-logloss:0.20872\n",
      "[49]\tvalidation_0-logloss:0.20434\n",
      "[50]\tvalidation_0-logloss:0.20008\n",
      "[51]\tvalidation_0-logloss:0.19592\n",
      "[52]\tvalidation_0-logloss:0.19186\n",
      "[53]\tvalidation_0-logloss:0.18790\n",
      "[54]\tvalidation_0-logloss:0.18404\n",
      "[55]\tvalidation_0-logloss:0.18027\n",
      "[56]\tvalidation_0-logloss:0.17659\n",
      "[57]\tvalidation_0-logloss:0.17300\n",
      "[58]\tvalidation_0-logloss:0.16949\n",
      "[59]\tvalidation_0-logloss:0.16607\n",
      "[60]\tvalidation_0-logloss:0.16272\n",
      "[61]\tvalidation_0-logloss:0.15946\n",
      "[62]\tvalidation_0-logloss:0.15627\n",
      "[63]\tvalidation_0-logloss:0.15316\n",
      "[64]\tvalidation_0-logloss:0.15012\n",
      "[65]\tvalidation_0-logloss:0.14715\n",
      "[66]\tvalidation_0-logloss:0.14425\n",
      "[67]\tvalidation_0-logloss:0.14142\n",
      "[68]\tvalidation_0-logloss:0.13865\n",
      "[69]\tvalidation_0-logloss:0.13595\n",
      "[70]\tvalidation_0-logloss:0.13330\n",
      "[71]\tvalidation_0-logloss:0.13072\n",
      "[72]\tvalidation_0-logloss:0.12820\n",
      "[73]\tvalidation_0-logloss:0.12574\n",
      "[74]\tvalidation_0-logloss:0.12333\n",
      "[75]\tvalidation_0-logloss:0.12098\n",
      "[76]\tvalidation_0-logloss:0.11868\n",
      "[77]\tvalidation_0-logloss:0.11643\n",
      "[78]\tvalidation_0-logloss:0.11423\n",
      "[79]\tvalidation_0-logloss:0.11209\n",
      "[80]\tvalidation_0-logloss:0.10999\n",
      "[81]\tvalidation_0-logloss:0.10793\n",
      "[82]\tvalidation_0-logloss:0.10593\n",
      "[83]\tvalidation_0-logloss:0.10397\n",
      "[84]\tvalidation_0-logloss:0.10205\n",
      "[85]\tvalidation_0-logloss:0.10017\n",
      "[86]\tvalidation_0-logloss:0.09834\n",
      "[87]\tvalidation_0-logloss:0.09655\n",
      "[88]\tvalidation_0-logloss:0.09479\n",
      "[89]\tvalidation_0-logloss:0.09308\n",
      "[90]\tvalidation_0-logloss:0.09140\n",
      "[91]\tvalidation_0-logloss:0.08976\n",
      "[92]\tvalidation_0-logloss:0.08816\n",
      "[93]\tvalidation_0-logloss:0.08659\n",
      "[94]\tvalidation_0-logloss:0.08506\n",
      "[95]\tvalidation_0-logloss:0.08356\n",
      "[96]\tvalidation_0-logloss:0.08209\n",
      "[97]\tvalidation_0-logloss:0.08066\n",
      "[98]\tvalidation_0-logloss:0.07925\n",
      "[99]\tvalidation_0-logloss:0.07788\n",
      "[100]\tvalidation_0-logloss:0.07653\n",
      "[101]\tvalidation_0-logloss:0.07522\n",
      "[102]\tvalidation_0-logloss:0.07393\n",
      "[103]\tvalidation_0-logloss:0.07267\n",
      "[104]\tvalidation_0-logloss:0.07144\n",
      "[105]\tvalidation_0-logloss:0.07024\n",
      "[106]\tvalidation_0-logloss:0.06906\n",
      "[107]\tvalidation_0-logloss:0.06791\n",
      "[108]\tvalidation_0-logloss:0.06678\n",
      "[109]\tvalidation_0-logloss:0.06568\n",
      "[110]\tvalidation_0-logloss:0.06460\n",
      "[111]\tvalidation_0-logloss:0.06354\n",
      "[112]\tvalidation_0-logloss:0.06251\n",
      "[113]\tvalidation_0-logloss:0.06150\n",
      "[114]\tvalidation_0-logloss:0.06051\n",
      "[115]\tvalidation_0-logloss:0.05954\n",
      "[116]\tvalidation_0-logloss:0.05859\n",
      "[117]\tvalidation_0-logloss:0.05767\n",
      "[118]\tvalidation_0-logloss:0.05676\n",
      "[119]\tvalidation_0-logloss:0.05587\n",
      "[120]\tvalidation_0-logloss:0.05500\n",
      "[121]\tvalidation_0-logloss:0.05416\n",
      "[122]\tvalidation_0-logloss:0.05333\n",
      "[123]\tvalidation_0-logloss:0.05252\n",
      "[124]\tvalidation_0-logloss:0.05172\n",
      "[125]\tvalidation_0-logloss:0.05094\n",
      "[126]\tvalidation_0-logloss:0.05018\n",
      "[127]\tvalidation_0-logloss:0.04944\n",
      "[128]\tvalidation_0-logloss:0.04871\n",
      "[129]\tvalidation_0-logloss:0.04800\n",
      "[130]\tvalidation_0-logloss:0.04730\n",
      "[131]\tvalidation_0-logloss:0.04661\n",
      "[132]\tvalidation_0-logloss:0.04594\n",
      "[133]\tvalidation_0-logloss:0.04529\n",
      "[134]\tvalidation_0-logloss:0.04465\n",
      "[135]\tvalidation_0-logloss:0.04402\n",
      "[136]\tvalidation_0-logloss:0.04341\n",
      "[137]\tvalidation_0-logloss:0.04281\n",
      "[138]\tvalidation_0-logloss:0.04222\n",
      "[139]\tvalidation_0-logloss:0.04165\n",
      "[140]\tvalidation_0-logloss:0.04108\n",
      "[141]\tvalidation_0-logloss:0.04053\n",
      "[142]\tvalidation_0-logloss:0.03999\n",
      "[143]\tvalidation_0-logloss:0.03947\n",
      "[144]\tvalidation_0-logloss:0.03895\n",
      "[145]\tvalidation_0-logloss:0.03845\n",
      "[146]\tvalidation_0-logloss:0.03796\n",
      "[147]\tvalidation_0-logloss:0.03748\n",
      "[148]\tvalidation_0-logloss:0.03701\n",
      "[149]\tvalidation_0-logloss:0.03655\n",
      "[150]\tvalidation_0-logloss:0.03610\n",
      "[151]\tvalidation_0-logloss:0.03566\n",
      "[152]\tvalidation_0-logloss:0.03523\n",
      "[153]\tvalidation_0-logloss:0.03481\n",
      "[154]\tvalidation_0-logloss:0.03440\n",
      "[155]\tvalidation_0-logloss:0.03399\n",
      "[156]\tvalidation_0-logloss:0.03360\n",
      "[157]\tvalidation_0-logloss:0.03321\n",
      "[158]\tvalidation_0-logloss:0.03283\n",
      "[159]\tvalidation_0-logloss:0.03246\n",
      "[160]\tvalidation_0-logloss:0.03210\n",
      "[161]\tvalidation_0-logloss:0.03175\n",
      "[162]\tvalidation_0-logloss:0.03140\n",
      "[163]\tvalidation_0-logloss:0.03106\n",
      "[164]\tvalidation_0-logloss:0.03073\n",
      "[165]\tvalidation_0-logloss:0.03040\n",
      "[166]\tvalidation_0-logloss:0.03008\n",
      "[167]\tvalidation_0-logloss:0.02977\n",
      "[168]\tvalidation_0-logloss:0.02947\n",
      "[169]\tvalidation_0-logloss:0.02917\n",
      "[170]\tvalidation_0-logloss:0.02888\n",
      "[171]\tvalidation_0-logloss:0.02860\n",
      "[172]\tvalidation_0-logloss:0.02832\n",
      "[173]\tvalidation_0-logloss:0.02804\n",
      "[174]\tvalidation_0-logloss:0.02778\n",
      "[175]\tvalidation_0-logloss:0.02751\n",
      "[176]\tvalidation_0-logloss:0.02726\n",
      "[177]\tvalidation_0-logloss:0.02701\n",
      "[178]\tvalidation_0-logloss:0.02676\n",
      "[179]\tvalidation_0-logloss:0.02653\n",
      "[180]\tvalidation_0-logloss:0.02629\n",
      "[181]\tvalidation_0-logloss:0.02606\n",
      "[182]\tvalidation_0-logloss:0.02584\n",
      "[183]\tvalidation_0-logloss:0.02563\n",
      "[184]\tvalidation_0-logloss:0.02541\n",
      "[185]\tvalidation_0-logloss:0.02520\n",
      "[186]\tvalidation_0-logloss:0.02499\n",
      "[187]\tvalidation_0-logloss:0.02479\n",
      "[188]\tvalidation_0-logloss:0.02460\n",
      "[189]\tvalidation_0-logloss:0.02440\n",
      "[190]\tvalidation_0-logloss:0.02421\n",
      "[191]\tvalidation_0-logloss:0.02403\n",
      "[192]\tvalidation_0-logloss:0.02384\n",
      "[193]\tvalidation_0-logloss:0.02367\n",
      "[194]\tvalidation_0-logloss:0.02349\n",
      "[195]\tvalidation_0-logloss:0.02333\n",
      "[196]\tvalidation_0-logloss:0.02316\n",
      "[197]\tvalidation_0-logloss:0.02300\n",
      "[198]\tvalidation_0-logloss:0.02285\n",
      "[199]\tvalidation_0-logloss:0.02270\n",
      "[200]\tvalidation_0-logloss:0.02255\n",
      "[201]\tvalidation_0-logloss:0.02240\n",
      "[202]\tvalidation_0-logloss:0.02225\n",
      "[203]\tvalidation_0-logloss:0.02211\n",
      "[204]\tvalidation_0-logloss:0.02198\n",
      "[205]\tvalidation_0-logloss:0.02185\n",
      "[206]\tvalidation_0-logloss:0.02172\n",
      "[207]\tvalidation_0-logloss:0.02159\n",
      "[208]\tvalidation_0-logloss:0.02147\n",
      "[209]\tvalidation_0-logloss:0.02134\n",
      "[210]\tvalidation_0-logloss:0.02122\n",
      "[211]\tvalidation_0-logloss:0.02111\n",
      "[212]\tvalidation_0-logloss:0.02099\n",
      "[213]\tvalidation_0-logloss:0.02088\n",
      "[214]\tvalidation_0-logloss:0.02077\n",
      "[215]\tvalidation_0-logloss:0.02067\n",
      "[216]\tvalidation_0-logloss:0.02056\n",
      "[217]\tvalidation_0-logloss:0.02045\n",
      "[218]\tvalidation_0-logloss:0.02036\n",
      "[219]\tvalidation_0-logloss:0.02026\n",
      "[220]\tvalidation_0-logloss:0.02016\n",
      "[221]\tvalidation_0-logloss:0.02007\n",
      "[222]\tvalidation_0-logloss:0.01999\n",
      "[223]\tvalidation_0-logloss:0.01990\n",
      "[224]\tvalidation_0-logloss:0.01982\n",
      "[225]\tvalidation_0-logloss:0.01974\n",
      "[226]\tvalidation_0-logloss:0.01966\n",
      "[227]\tvalidation_0-logloss:0.01958\n",
      "[228]\tvalidation_0-logloss:0.01951\n",
      "[229]\tvalidation_0-logloss:0.01943\n",
      "[230]\tvalidation_0-logloss:0.01935\n",
      "[231]\tvalidation_0-logloss:0.01928\n",
      "[232]\tvalidation_0-logloss:0.01920\n",
      "[233]\tvalidation_0-logloss:0.01913\n",
      "[234]\tvalidation_0-logloss:0.01906\n",
      "[235]\tvalidation_0-logloss:0.01899\n",
      "[236]\tvalidation_0-logloss:0.01892\n",
      "[237]\tvalidation_0-logloss:0.01886\n",
      "[238]\tvalidation_0-logloss:0.01880\n",
      "[239]\tvalidation_0-logloss:0.01874\n",
      "[240]\tvalidation_0-logloss:0.01868\n",
      "[241]\tvalidation_0-logloss:0.01862\n",
      "[242]\tvalidation_0-logloss:0.01857\n",
      "[243]\tvalidation_0-logloss:0.01851\n",
      "[244]\tvalidation_0-logloss:0.01846\n",
      "[245]\tvalidation_0-logloss:0.01841\n",
      "[246]\tvalidation_0-logloss:0.01836\n",
      "[247]\tvalidation_0-logloss:0.01831\n",
      "[248]\tvalidation_0-logloss:0.01826\n",
      "[249]\tvalidation_0-logloss:0.01821\n",
      "[250]\tvalidation_0-logloss:0.01817\n",
      "[251]\tvalidation_0-logloss:0.01812\n",
      "[252]\tvalidation_0-logloss:0.01807\n",
      "[253]\tvalidation_0-logloss:0.01803\n",
      "[254]\tvalidation_0-logloss:0.01799\n",
      "[255]\tvalidation_0-logloss:0.01795\n",
      "[256]\tvalidation_0-logloss:0.01791\n",
      "[257]\tvalidation_0-logloss:0.01787\n",
      "[258]\tvalidation_0-logloss:0.01783\n",
      "[259]\tvalidation_0-logloss:0.01780\n",
      "[260]\tvalidation_0-logloss:0.01776\n",
      "[261]\tvalidation_0-logloss:0.01772\n",
      "[262]\tvalidation_0-logloss:0.01769\n",
      "[263]\tvalidation_0-logloss:0.01765\n",
      "[264]\tvalidation_0-logloss:0.01761\n",
      "[265]\tvalidation_0-logloss:0.01758\n",
      "[266]\tvalidation_0-logloss:0.01756\n",
      "[267]\tvalidation_0-logloss:0.01753\n",
      "[268]\tvalidation_0-logloss:0.01750\n",
      "[269]\tvalidation_0-logloss:0.01746\n",
      "[270]\tvalidation_0-logloss:0.01743\n",
      "[271]\tvalidation_0-logloss:0.01740\n",
      "[272]\tvalidation_0-logloss:0.01737\n",
      "[273]\tvalidation_0-logloss:0.01734\n",
      "[274]\tvalidation_0-logloss:0.01730\n",
      "[275]\tvalidation_0-logloss:0.01727\n",
      "[276]\tvalidation_0-logloss:0.01724\n",
      "[277]\tvalidation_0-logloss:0.01720\n",
      "[278]\tvalidation_0-logloss:0.01718\n",
      "[279]\tvalidation_0-logloss:0.01715\n",
      "[280]\tvalidation_0-logloss:0.01712\n",
      "[281]\tvalidation_0-logloss:0.01709\n",
      "[282]\tvalidation_0-logloss:0.01707\n",
      "[283]\tvalidation_0-logloss:0.01705\n",
      "[284]\tvalidation_0-logloss:0.01702\n",
      "[285]\tvalidation_0-logloss:0.01700\n",
      "[286]\tvalidation_0-logloss:0.01698\n",
      "[287]\tvalidation_0-logloss:0.01696\n",
      "[288]\tvalidation_0-logloss:0.01694\n",
      "[289]\tvalidation_0-logloss:0.01692\n",
      "[290]\tvalidation_0-logloss:0.01690\n",
      "[291]\tvalidation_0-logloss:0.01688\n",
      "[292]\tvalidation_0-logloss:0.01686\n",
      "[293]\tvalidation_0-logloss:0.01684\n",
      "[294]\tvalidation_0-logloss:0.01683\n",
      "[295]\tvalidation_0-logloss:0.01681\n",
      "[296]\tvalidation_0-logloss:0.01679\n",
      "[297]\tvalidation_0-logloss:0.01677\n",
      "[298]\tvalidation_0-logloss:0.01676\n",
      "[299]\tvalidation_0-logloss:0.01674\n",
      "[300]\tvalidation_0-logloss:0.01673\n",
      "[301]\tvalidation_0-logloss:0.01672\n",
      "[302]\tvalidation_0-logloss:0.01670\n",
      "[303]\tvalidation_0-logloss:0.01669\n",
      "[304]\tvalidation_0-logloss:0.01667\n",
      "[305]\tvalidation_0-logloss:0.01666\n",
      "[306]\tvalidation_0-logloss:0.01665\n",
      "[307]\tvalidation_0-logloss:0.01663\n",
      "[308]\tvalidation_0-logloss:0.01662\n",
      "[309]\tvalidation_0-logloss:0.01662\n",
      "[310]\tvalidation_0-logloss:0.01660\n",
      "[311]\tvalidation_0-logloss:0.01659\n",
      "[312]\tvalidation_0-logloss:0.01658\n",
      "[313]\tvalidation_0-logloss:0.01657\n",
      "[314]\tvalidation_0-logloss:0.01657\n",
      "[315]\tvalidation_0-logloss:0.01655\n",
      "[316]\tvalidation_0-logloss:0.01655\n",
      "[317]\tvalidation_0-logloss:0.01654\n",
      "[318]\tvalidation_0-logloss:0.01653\n",
      "[319]\tvalidation_0-logloss:0.01652\n",
      "[320]\tvalidation_0-logloss:0.01652\n",
      "[321]\tvalidation_0-logloss:0.01651\n",
      "[322]\tvalidation_0-logloss:0.01650\n",
      "[323]\tvalidation_0-logloss:0.01649\n",
      "[324]\tvalidation_0-logloss:0.01648\n",
      "[325]\tvalidation_0-logloss:0.01648\n",
      "[326]\tvalidation_0-logloss:0.01647\n",
      "[327]\tvalidation_0-logloss:0.01646\n",
      "[328]\tvalidation_0-logloss:0.01646\n",
      "[329]\tvalidation_0-logloss:0.01645\n",
      "[330]\tvalidation_0-logloss:0.01644\n",
      "[331]\tvalidation_0-logloss:0.01644\n",
      "[332]\tvalidation_0-logloss:0.01643\n",
      "[333]\tvalidation_0-logloss:0.01643\n",
      "[334]\tvalidation_0-logloss:0.01642\n",
      "[335]\tvalidation_0-logloss:0.01641\n",
      "[336]\tvalidation_0-logloss:0.01640\n",
      "[337]\tvalidation_0-logloss:0.01639\n",
      "[338]\tvalidation_0-logloss:0.01639\n",
      "[339]\tvalidation_0-logloss:0.01638\n",
      "[340]\tvalidation_0-logloss:0.01638\n",
      "[341]\tvalidation_0-logloss:0.01637\n",
      "[342]\tvalidation_0-logloss:0.01636\n",
      "[343]\tvalidation_0-logloss:0.01636\n",
      "[344]\tvalidation_0-logloss:0.01636\n",
      "[345]\tvalidation_0-logloss:0.01635\n",
      "[346]\tvalidation_0-logloss:0.01635\n",
      "[347]\tvalidation_0-logloss:0.01635\n",
      "[348]\tvalidation_0-logloss:0.01634\n",
      "[349]\tvalidation_0-logloss:0.01633\n",
      "[350]\tvalidation_0-logloss:0.01633\n",
      "[351]\tvalidation_0-logloss:0.01633\n",
      "[352]\tvalidation_0-logloss:0.01632\n",
      "[353]\tvalidation_0-logloss:0.01632\n",
      "[354]\tvalidation_0-logloss:0.01631\n",
      "[355]\tvalidation_0-logloss:0.01631\n",
      "[356]\tvalidation_0-logloss:0.01631\n",
      "[357]\tvalidation_0-logloss:0.01630\n",
      "[358]\tvalidation_0-logloss:0.01630\n",
      "[359]\tvalidation_0-logloss:0.01630\n",
      "[360]\tvalidation_0-logloss:0.01629\n",
      "[361]\tvalidation_0-logloss:0.01629\n",
      "[362]\tvalidation_0-logloss:0.01629\n",
      "[363]\tvalidation_0-logloss:0.01628\n",
      "[364]\tvalidation_0-logloss:0.01628\n",
      "[365]\tvalidation_0-logloss:0.01628\n",
      "[366]\tvalidation_0-logloss:0.01627\n",
      "[367]\tvalidation_0-logloss:0.01627\n",
      "[368]\tvalidation_0-logloss:0.01626\n",
      "[369]\tvalidation_0-logloss:0.01626\n",
      "[370]\tvalidation_0-logloss:0.01626\n",
      "[371]\tvalidation_0-logloss:0.01625\n",
      "[372]\tvalidation_0-logloss:0.01625\n",
      "[373]\tvalidation_0-logloss:0.01625\n",
      "[374]\tvalidation_0-logloss:0.01624\n",
      "[375]\tvalidation_0-logloss:0.01624\n",
      "[376]\tvalidation_0-logloss:0.01624\n",
      "[377]\tvalidation_0-logloss:0.01623\n",
      "[378]\tvalidation_0-logloss:0.01623\n",
      "[379]\tvalidation_0-logloss:0.01623\n",
      "[380]\tvalidation_0-logloss:0.01622\n",
      "[381]\tvalidation_0-logloss:0.01622\n",
      "[382]\tvalidation_0-logloss:0.01622\n",
      "[383]\tvalidation_0-logloss:0.01622\n",
      "[384]\tvalidation_0-logloss:0.01622\n",
      "[385]\tvalidation_0-logloss:0.01621\n",
      "[386]\tvalidation_0-logloss:0.01621\n",
      "[387]\tvalidation_0-logloss:0.01621\n",
      "[388]\tvalidation_0-logloss:0.01620\n",
      "[389]\tvalidation_0-logloss:0.01620\n",
      "[390]\tvalidation_0-logloss:0.01620\n",
      "[391]\tvalidation_0-logloss:0.01620\n",
      "[392]\tvalidation_0-logloss:0.01619\n",
      "[393]\tvalidation_0-logloss:0.01619\n",
      "[394]\tvalidation_0-logloss:0.01619\n",
      "[395]\tvalidation_0-logloss:0.01619\n",
      "[396]\tvalidation_0-logloss:0.01619\n",
      "[397]\tvalidation_0-logloss:0.01619\n",
      "[398]\tvalidation_0-logloss:0.01618\n",
      "[399]\tvalidation_0-logloss:0.01618\n",
      "[400]\tvalidation_0-logloss:0.01618\n",
      "[401]\tvalidation_0-logloss:0.01618\n",
      "[402]\tvalidation_0-logloss:0.01618\n",
      "[403]\tvalidation_0-logloss:0.01618\n",
      "[404]\tvalidation_0-logloss:0.01618\n",
      "[405]\tvalidation_0-logloss:0.01617\n",
      "[406]\tvalidation_0-logloss:0.01617\n",
      "[407]\tvalidation_0-logloss:0.01617\n",
      "[408]\tvalidation_0-logloss:0.01617\n",
      "[409]\tvalidation_0-logloss:0.01617\n",
      "[410]\tvalidation_0-logloss:0.01617\n",
      "[411]\tvalidation_0-logloss:0.01616\n",
      "[412]\tvalidation_0-logloss:0.01616\n",
      "[413]\tvalidation_0-logloss:0.01616\n",
      "[414]\tvalidation_0-logloss:0.01616\n",
      "[415]\tvalidation_0-logloss:0.01616\n",
      "[416]\tvalidation_0-logloss:0.01616\n",
      "[417]\tvalidation_0-logloss:0.01616\n",
      "[418]\tvalidation_0-logloss:0.01616\n",
      "[419]\tvalidation_0-logloss:0.01616\n",
      "[420]\tvalidation_0-logloss:0.01616\n",
      "[421]\tvalidation_0-logloss:0.01616\n",
      "[422]\tvalidation_0-logloss:0.01616\n",
      "[423]\tvalidation_0-logloss:0.01616\n",
      "[424]\tvalidation_0-logloss:0.01616\n",
      "[425]\tvalidation_0-logloss:0.01616\n",
      "[426]\tvalidation_0-logloss:0.01616\n",
      "[427]\tvalidation_0-logloss:0.01616\n",
      "[428]\tvalidation_0-logloss:0.01616\n",
      "[429]\tvalidation_0-logloss:0.01616\n",
      "[430]\tvalidation_0-logloss:0.01616\n",
      "[431]\tvalidation_0-logloss:0.01616\n",
      "[432]\tvalidation_0-logloss:0.01616\n",
      "[433]\tvalidation_0-logloss:0.01616\n",
      "[434]\tvalidation_0-logloss:0.01616\n",
      "[435]\tvalidation_0-logloss:0.01616\n",
      "[436]\tvalidation_0-logloss:0.01616\n",
      "[437]\tvalidation_0-logloss:0.01616\n",
      "[438]\tvalidation_0-logloss:0.01615\n",
      "[439]\tvalidation_0-logloss:0.01615\n",
      "[440]\tvalidation_0-logloss:0.01615\n",
      "[441]\tvalidation_0-logloss:0.01615\n",
      "[442]\tvalidation_0-logloss:0.01615\n",
      "[443]\tvalidation_0-logloss:0.01615\n",
      "[444]\tvalidation_0-logloss:0.01615\n",
      "[445]\tvalidation_0-logloss:0.01615\n",
      "[446]\tvalidation_0-logloss:0.01615\n",
      "[447]\tvalidation_0-logloss:0.01614\n",
      "[448]\tvalidation_0-logloss:0.01614\n",
      "[449]\tvalidation_0-logloss:0.01614\n",
      "[450]\tvalidation_0-logloss:0.01614\n",
      "[451]\tvalidation_0-logloss:0.01614\n",
      "[452]\tvalidation_0-logloss:0.01614\n",
      "[453]\tvalidation_0-logloss:0.01614\n",
      "[454]\tvalidation_0-logloss:0.01614\n",
      "[455]\tvalidation_0-logloss:0.01614\n",
      "[456]\tvalidation_0-logloss:0.01614\n",
      "[457]\tvalidation_0-logloss:0.01614\n",
      "[458]\tvalidation_0-logloss:0.01614\n",
      "[459]\tvalidation_0-logloss:0.01614\n",
      "[460]\tvalidation_0-logloss:0.01614\n",
      "[461]\tvalidation_0-logloss:0.01614\n",
      "[462]\tvalidation_0-logloss:0.01614\n",
      "[463]\tvalidation_0-logloss:0.01614\n",
      "[464]\tvalidation_0-logloss:0.01614\n",
      "[465]\tvalidation_0-logloss:0.01614\n",
      "[466]\tvalidation_0-logloss:0.01614\n",
      "[467]\tvalidation_0-logloss:0.01614\n",
      "[468]\tvalidation_0-logloss:0.01614\n",
      "[469]\tvalidation_0-logloss:0.01614\n",
      "[470]\tvalidation_0-logloss:0.01613\n",
      "[471]\tvalidation_0-logloss:0.01613\n",
      "[472]\tvalidation_0-logloss:0.01613\n",
      "[473]\tvalidation_0-logloss:0.01613\n",
      "[474]\tvalidation_0-logloss:0.01613\n",
      "[475]\tvalidation_0-logloss:0.01614\n",
      "[476]\tvalidation_0-logloss:0.01614\n",
      "[477]\tvalidation_0-logloss:0.01614\n",
      "[478]\tvalidation_0-logloss:0.01614\n",
      "[479]\tvalidation_0-logloss:0.01614\n",
      "[480]\tvalidation_0-logloss:0.01614\n",
      "[481]\tvalidation_0-logloss:0.01614\n",
      "[482]\tvalidation_0-logloss:0.01614\n",
      "[483]\tvalidation_0-logloss:0.01614\n",
      "[484]\tvalidation_0-logloss:0.01614\n",
      "[485]\tvalidation_0-logloss:0.01614\n",
      "[486]\tvalidation_0-logloss:0.01614\n",
      "[487]\tvalidation_0-logloss:0.01614\n",
      "[488]\tvalidation_0-logloss:0.01614\n",
      "[489]\tvalidation_0-logloss:0.01614\n",
      "[490]\tvalidation_0-logloss:0.01614\n",
      "[491]\tvalidation_0-logloss:0.01614\n",
      "[492]\tvalidation_0-logloss:0.01614\n",
      "[493]\tvalidation_0-logloss:0.01614\n",
      "[494]\tvalidation_0-logloss:0.01614\n",
      "[495]\tvalidation_0-logloss:0.01614\n",
      "[496]\tvalidation_0-logloss:0.01614\n",
      "[497]\tvalidation_0-logloss:0.01614\n",
      "[498]\tvalidation_0-logloss:0.01614\n",
      "[499]\tvalidation_0-logloss:0.01614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.02,\n",
    "    eval_metric=\"logloss\",\n",
    "    max_depth = 10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f792ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9968560139355058\n",
      "Precision: 0.9950535252860834\n",
      "Recall: 0.9994809047089358\n",
      "F1: 0.9972623011468739\n",
      "ROC AUC: 0.9964077822390681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "y_pred_prob = xgb_model.predict(X_val)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eb138a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=30, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=30, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=30, random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(\n",
    "    n_estimators=100,   \n",
    "    max_depth=30,     \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7355f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9119705508089438\n",
      "Precision: 0.8970665575877987\n",
      "Recall: 0.9306477524173259\n",
      "F1: 0.9135486558459913\n",
      "ROC AUC: 0.911979035046978\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = rfc_model.predict(X_val)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3b377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Path to dataset files: C:\\Users\\rrpra\\.cache\\kagglehub\\datasets\\cheedcheed\\top1m\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "f= open('tld_encoding_serise_dataset_1.bin','rb')\n",
    "tld_stats = pickle.load(file=f)\n",
    "f.close()\n",
    "print(type(tld_stats))\n",
    "\n",
    "import kagglehub\n",
    "import os\n",
    "# Download latest version\n",
    "folder_path = kagglehub.dataset_download(\"cheedcheed/top1m\")\n",
    "\n",
    "print(\"Path to dataset files:\", folder_path)\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.csv')]\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No CSV files found in the folder!\")\n",
    "\n",
    "# read the first CSV file\n",
    "file_path = os.path.join(folder_path, csv_files[0])\n",
    "alexa_top_1m_domain = pd.read_csv(file_path,header=None,names=['rank', 'domain'])\n",
    "alexa_domains_set = set(alexa_top_1m_domain['domain'].apply(str.lower))\n",
    "\n",
    "# --- Helper function: Shannon entropy ---\n",
    "def safe_parse(url: str):\n",
    "    \"\"\"Safely parse URLs, adding http:// if missing and handling bad IPv6 parts.\"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return urlparse(\"http://\")  \n",
    "\n",
    "    # Ensure scheme exists\n",
    "    if not re.match(r'^[a-zA-Z]+://', url):\n",
    "        url = 'http://' + url\n",
    "\n",
    "    # Clean invalid brackets that trigger IPv6 errors\n",
    "    url = re.sub(r'\\[.*?\\]', '', url)\n",
    "\n",
    "    try:\n",
    "        return urlparse(url)\n",
    "    except ValueError:\n",
    "        # fallback: strip more aggressively if still malformed\n",
    "        url = re.sub(r'[^a-zA-Z0-9:/._\\-?&=]', '', url)\n",
    "        return urlparse(url)\n",
    "def calculate_entropy(string):\n",
    "    \"\"\"Measures randomness of characters in the URL.\"\"\"\n",
    "    if not string:\n",
    "        return 0\n",
    "    freq = {char: string.count(char) for char in set(string)}\n",
    "    entropy = -sum((count / len(string)) * math.log2(count / len(string)) for count in freq.values())\n",
    "    return entropy\n",
    "\n",
    "# --- Main feature extraction function ---\n",
    "def extract_handcrafted_features(url):\n",
    "    features = {}\n",
    "    if not re.match(r'^[hH]+[tT]+[tT]+[pP]+[sS]+://', url):\n",
    "        url = 'http://' + url\n",
    "    parsed = safe_parse(url)\n",
    "    \n",
    "    # 1Ô∏è‚É£ Basic structural features\n",
    "    features['url_length'] = len(url)\n",
    "    features['hostname_length'] = len(parsed.netloc)\n",
    "    features['path_length'] = len(parsed.path)\n",
    "    features['num_dots'] = url.count('.')\n",
    "    features['num_hyphens'] = url.count('-')\n",
    "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['num_letters'] = sum(c.isalpha() for c in url)\n",
    "    features['num_params'] = url.count('?')\n",
    "    features['num_equals'] = url.count('=')\n",
    "    features['num_slashes'] = url.count('/')\n",
    "    features['num_at'] = url.count('@')\n",
    "\n",
    "    # 2Ô∏è‚É£ Lexical / composition cues\n",
    "    features['has_https'] = 1 if url.lower().startswith('https') else 0\n",
    "    features['has_ip'] = 1 if re.search(r'(\\d{1,3}\\.){3}\\d{1,3}', parsed.netloc) else 0\n",
    "    features['has_subdomain'] = 1 if parsed.netloc.count('.') > 1 else 0\n",
    "    features['has_suspicious_words'] = 1 if re.search(r'(login|secure|verify|update|free|bank|click)', url.lower()) else 0\n",
    "\n",
    "    # 3Ô∏è‚É£ Domain / TLD features\n",
    "    extracted = tldextract.extract(url)\n",
    "    main_domain = f\"{extracted.domain}.{extracted.suffix}\"\n",
    "    if ':' in main_domain:  # remove port\n",
    "        main_domain = main_domain.split(':')[0]\n",
    "    features['domain_length'] = len(main_domain)\n",
    "    features['in_alexa_top1m'] = 1 if main_domain in alexa_domains_set else 0\n",
    "    '''\n",
    "    if features['in_alexa_top1m'] == 0 and main_domain:  # only check if domain not in top1M\n",
    "        # find closest match in Alexa domains\n",
    "        best_match, score, _ = process.extractOne(main_domain, alexa_domains_set, scorer=fuzz.ratio)\n",
    "        features['closest_alexa_domain'] = best_match\n",
    "        features['closest_alexa_score'] = score  # 0-100\n",
    "    else:\n",
    "        features['closest_alexa_score'] = 1000  # high score to show that it is original url\n",
    "    '''\n",
    "    ext = tldextract.extract(url)\n",
    "    tld = ext.suffix    # \"com\", \"co.uk\", \"org\"\n",
    "    features['tld'] = tld if tld else 'unknown'\n",
    "    features['tld_phish_ratio'] = tld_stats['phish_ratio'].get(features['tld'], 0.5)\n",
    "    features['tld_total_frequency'] = tld_stats['total'].get(features['tld'], 1)\n",
    "\n",
    "    # 4Ô∏è‚É£ Ratios\n",
    "    features['digit_ratio'] = features['num_digits'] / (features['url_length'] + 1e-5)\n",
    "    features['special_char_ratio'] = (features['num_hyphens'] + features['num_dots'] + features['num_slashes']) / (features['url_length'] + 1e-5)\n",
    "\n",
    "    # 5Ô∏è‚É£ Entropy (measures randomness / obfuscation)\n",
    "    features['url_entropy'] = calculate_entropy(url)\n",
    "\n",
    "    # 6Ô∏è‚É£ Misplacement indicators\n",
    "    # '@' symbol used to hide real domain (like \"http://evil.com@legit.com\")\n",
    "    features['at_in_domain'] = 1 if '@' in parsed.netloc else 0\n",
    "    \n",
    "    # Double slashes '//' appearing after path (used to trick users)\n",
    "    features['double_slash_in_path'] = 1 if re.search(r'/.+//', parsed.path) else 0\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e68a20e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extracting Dataset 2 (ndarvind/phiusiil-phishing) train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188296/188296 [00:43<00:00, 4358.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extracting Dataset 2 (ndarvind/phiusiil-phishing) valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23537/23537 [00:04<00:00, 5001.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extracting Dataset 2 (ndarvind/phiusiil-phishing) test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23537/23537 [00:05<00:00, 4503.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "for i in encoded_data:\n",
    "\n",
    "    for split in encoded_data[i]:\n",
    "        print(\"feature extracting\", i, split)\n",
    "        encoded_data[i][split] = encoded_data[i][split].assign(**encoded_data[i][split].url.progress_apply(lambda url : pd.Series(extract_handcrafted_features(url))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09ed66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for Dataset 2 (ndarvind/phiusiil-phishing)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [02:01:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     10052\n",
      "           1       1.00      1.00      1.00     13485\n",
      "\n",
      "    accuracy                           1.00     23537\n",
      "   macro avg       1.00      1.00      1.00     23537\n",
      "weighted avg       1.00      1.00      1.00     23537\n",
      "\n",
      "\n",
      "üìó VALIDATION METRICS\n",
      "Accuracy : 0.9973233632153631\n",
      "Precision: 0.9954961606615476\n",
      "Recall   : 0.999851687059696\n",
      "F1-score : 0.997669170150579\n",
      "ROC AUC  : 0.9968916214844837\n"
     ]
    }
   ],
   "source": [
    "# Split features and labels\n",
    "independent_features = ['url_length', 'hostname_length', 'path_length',\n",
    "    'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params',\n",
    "    'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip',\n",
    "    'has_subdomain', 'has_suspicious_words', 'domain_length',\n",
    "    'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency',\n",
    "    'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain',\n",
    "    'double_slash_in_path']\n",
    "dependet_features  = 'label'\n",
    "model_dict = {}\n",
    "for i in encoded_data:\n",
    "    print(f\"train for {i}\")\n",
    "    X_train = encoded_data[i]['train'][independent_features]\n",
    "    y_train = encoded_data[i]['train'][dependet_features]\n",
    "    X_test = encoded_data[i]['valid'][independent_features]\n",
    "    y_test = encoded_data[i]['valid'][dependet_features]\n",
    "\n",
    "    # Create XGBoost classifier\n",
    "    model_dict[i] = xgb.XGBClassifier(\n",
    "        n_estimators=100,      # number of boosting rounds\n",
    "        learning_rate=0.01,     # step size shrinkage\n",
    "        max_depth=30,           # tree depth\n",
    "        eval_metric='logloss', # evaluation metric\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model_dict[i].fit(X_train, y_train)\n",
    "    # Predict\n",
    "    y_pred = model_dict[i] .predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"\\nüìó VALIDATION METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall   :\", recall_score(y_test, y_pred))\n",
    "    print(\"F1-score :\", f1_score(y_test, y_pred))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0676fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting NN for Dataset 2 (ndarvind/phiusiil-phishing): 100%|‚ñà| 368/368 [00:07\n",
      "Predicting NN for Dataset 2 (ndarvind/phiusiil-phishing): 100%|‚ñà| 46/46 [00:00<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò TRAIN METRICS\n",
      "Accuracy : 0.998231507838722\n",
      "Precision: 0.9970237820151399\n",
      "Recall   : 0.999898034853541\n",
      "F1-score : 0.9984588399183602\n",
      "ROC AUC  : 0.9991025245037448\n",
      "\n",
      "üìó VALIDATION METRICS\n",
      "Accuracy : 0.9977057398988826\n",
      "Precision: 0.9961581086073144\n",
      "Recall   : 0.999851687059696\n",
      "F1-score : 0.9980014803849001\n",
      "ROC AUC  : 0.9991928475450093\n"
     ]
    }
   ],
   "source": [
    "#logistic_regression(nn+xgboost)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "independent_features = ['url_length', 'hostname_length', 'path_length',\n",
    "    'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params',\n",
    "    'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip',\n",
    "    'has_subdomain', 'has_suspicious_words', 'domain_length',\n",
    "    'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency',\n",
    "    'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain',\n",
    "    'double_slash_in_path']\n",
    "dependent_features  = 'label'\n",
    "logistic_model = {}\n",
    "for name in encoded_data:\n",
    "    #print(model_dict[name])\n",
    "    #print(nn_model[name])\n",
    "    nn_model[name].eval()\n",
    "    with torch.no_grad():\n",
    "        model = nn_model[name]\n",
    "        #print(model)\n",
    "        x_ = encoded_data[name]['train']['encode']\n",
    "        x_np = np.stack(x_.values)\n",
    "        x_ = torch.tensor(x_np, dtype=torch.long).to(device)  # move once to GPU/CPU where model is\n",
    "        batch_size = 512  # adjust for your GPU memory\n",
    "        nn_preds_train = []\n",
    "\n",
    "        # üîπ Process manually in batches\n",
    "        for i in tqdm(range(0, len(x_), batch_size), desc=f\"Predicting NN for {name}\", ncols=80):\n",
    "            batch_x = x_[i:i + batch_size]\n",
    "            outputs = model(batch_x)\n",
    "            nn_preds_train.append(outputs)\n",
    "\n",
    "    # üîπ Combine all predictions\n",
    "    nn_preds_train = torch.cat(nn_preds_train, dim=0).cpu()\n",
    "\n",
    "    # XGBoost predictions\n",
    "    xgb_preds_train = model_dict[name].predict_proba(encoded_data[name]['train'][independent_features])[:, 1]\n",
    "\n",
    "    # Stack predictions as new features\n",
    "    meta_X = np.column_stack((nn_preds_train, xgb_preds_train))\n",
    "    meta_y = encoded_data[name]['train'][dependent_features]\n",
    "\n",
    "\n",
    "    meta_model= LogisticRegressionCV(\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    penalty=\"l2\",\n",
    "    scoring=\"roc_auc\",\n",
    "    solver=\"lbfgs\",\n",
    "    Cs=10,\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "    meta_model.fit(meta_X, meta_y)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_ = encoded_data[name]['valid']['encode']\n",
    "        x_np = np.stack(x_.values)\n",
    "        x_ = torch.tensor(x_np, dtype=torch.long).to(device)  # move once to GPU/CPU where model is\n",
    "        batch_size = 512  # adjust for your GPU memory\n",
    "        nn_preds_val = []\n",
    "\n",
    "        # üîπ Process manually in batches\n",
    "        for i in tqdm(range(0, len(x_), batch_size), desc=f\"Predicting NN for {name}\", ncols=80):\n",
    "            batch_x = x_[i:i + batch_size]\n",
    "            outputs = model(batch_x)\n",
    "            nn_preds_val.append(outputs)\n",
    "\n",
    "    # üîπ Combine all predictions\n",
    "    nn_preds_val = torch.cat(nn_preds_val, dim=0).cpu()\n",
    "    # XGBoost predictions\n",
    "    xgb_preds_val = model_dict[name].predict_proba(encoded_data[name]['valid'][independent_features])[:, 1]\n",
    "\n",
    "    # Stack predictions as new features\n",
    "    meta_X_val = np.column_stack((nn_preds_val, xgb_preds_val))\n",
    "    meta_y_val = encoded_data[name]['valid'][dependent_features]\n",
    "\n",
    "\n",
    "    y_pred_train = meta_model.predict(meta_X)\n",
    "    y_pred_prob_train = meta_model.predict_proba(meta_X)[:, 1]\n",
    "\n",
    "    print(\"\\nüìò TRAIN METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(meta_y, y_pred_train))\n",
    "    print(\"Precision:\", precision_score(meta_y, y_pred_train))\n",
    "    print(\"Recall   :\", recall_score(meta_y, y_pred_train))\n",
    "    print(\"F1-score :\", f1_score(meta_y, y_pred_train))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(meta_y, y_pred_prob_train))\n",
    "\n",
    "    # ===============================\n",
    "    # üîπ Validation Metrics\n",
    "    # ===============================\n",
    "    y_pred_val = meta_model.predict(meta_X_val)\n",
    "    y_pred_prob_val = meta_model.predict_proba(meta_X_val)[:, 1]\n",
    "\n",
    "    print(\"\\nüìó VALIDATION METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(meta_y_val, y_pred_val))\n",
    "    print(\"Precision:\", precision_score(meta_y_val, y_pred_val))\n",
    "    print(\"Recall   :\", recall_score(meta_y_val, y_pred_val))\n",
    "    print(\"F1-score :\", f1_score(meta_y_val, y_pred_val))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(meta_y_val, y_pred_prob_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "334cc474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting NN for Dataset 2 (ndarvind/phiusiil-phishing): 100%|‚ñà| 368/368 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting NN for Dataset 2 (ndarvind/phiusiil-phishing): 100%|‚ñà| 46/46 [00:00<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò TRAIN METRICS\n",
      "Accuracy : 0.998231507838722\n",
      "Precision: 0.9970789155011601\n",
      "Recall   : 0.999842417500927\n",
      "F1-score : 0.9984587543217361\n",
      "ROC AUC  : 0.9991044450185509\n",
      "\n",
      "üìó VALIDATION METRICS\n",
      "Accuracy : 0.9977057398988826\n",
      "Precision: 0.9962314342717801\n",
      "Recall   : 0.9997775305895439\n",
      "F1-score : 0.9980013324450366\n",
      "ROC AUC  : 0.9991988231459664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "independent_features = ['url_length', 'hostname_length', 'path_length',\n",
    "    'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params',\n",
    "    'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip',\n",
    "    'has_subdomain', 'has_suspicious_words', 'domain_length',\n",
    "    'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency',\n",
    "    'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain',\n",
    "    'double_slash_in_path']\n",
    "dependent_features  = 'label'\n",
    "for name in encoded_data:\n",
    "    #print(model_dict[name])\n",
    "    #print(nn_model[name])\n",
    "    nn_model[name].eval()\n",
    "    with torch.no_grad():\n",
    "        model = nn_model[name]\n",
    "        #print(model)\n",
    "        x_ = encoded_data[name]['train']['encode']\n",
    "        x_np = np.stack(x_.values)\n",
    "        x_ = torch.tensor(x_np, dtype=torch.long).to(device)  # move once to GPU/CPU where model is\n",
    "        batch_size = 512  # adjust for your GPU memory\n",
    "        nn_preds_train = []\n",
    "\n",
    "        # üîπ Process manually in batches\n",
    "        for i in tqdm(range(0, len(x_), batch_size), desc=f\"Predicting NN for {name}\", ncols=80):\n",
    "            batch_x = x_[i:i + batch_size]\n",
    "            outputs = model(batch_x)\n",
    "            nn_preds_train.append(outputs)\n",
    "\n",
    "    # üîπ Combine all predictions\n",
    "    nn_preds_train = torch.cat(nn_preds_train, dim=0).cpu()\n",
    "\n",
    "    # XGBoost predictions\n",
    "    xgb_preds_train = model_dict[name].predict_proba(encoded_data[name]['train'][independent_features])[:, 1]\n",
    "\n",
    "    # Stack predictions as new features\n",
    "    meta_X = np.column_stack((nn_preds_train, xgb_preds_train))\n",
    "    meta_y = encoded_data[name]['train'][dependent_features]\n",
    "\n",
    "\n",
    "    params = {\n",
    "    \"hidden_layer_sizes\": [(8,), (16,), (24,)],\n",
    "    \"alpha\": [1e-3, 1e-4, 1e-5],  # L2 regularization\n",
    "    \"learning_rate_init\": [1e-3],\n",
    "    \"early_stopping\": [True],\n",
    "    \"max_iter\": [500],\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(random_state=42)\n",
    "    meta_model = GridSearchCV(mlp, params, cv=StratifiedKFold(3), scoring=\"accuracy\", n_jobs=-1, verbose=3)\n",
    "    meta_model.fit(meta_X, meta_y)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_ = encoded_data[name]['valid']['encode']\n",
    "        x_np = np.stack(x_.values)\n",
    "        x_ = torch.tensor(x_np, dtype=torch.long).to(device)  # move once to GPU/CPU where model is\n",
    "        batch_size = 512  # adjust for your GPU memory\n",
    "        nn_preds_val = []\n",
    "\n",
    "        # üîπ Process manually in batches\n",
    "        for i in tqdm(range(0, len(x_), batch_size), desc=f\"Predicting NN for {name}\", ncols=80):\n",
    "            batch_x = x_[i:i + batch_size]\n",
    "            outputs = model(batch_x)\n",
    "            nn_preds_val.append(outputs)\n",
    "\n",
    "    # üîπ Combine all predictions\n",
    "    nn_preds_val = torch.cat(nn_preds_val, dim=0).cpu()\n",
    "    # XGBoost predictions\n",
    "    xgb_preds_val = model_dict[name].predict_proba(encoded_data[name]['valid'][independent_features])[:, 1]\n",
    "\n",
    "    # Stack predictions as new features\n",
    "    meta_X_val = np.column_stack((nn_preds_val, xgb_preds_val))\n",
    "    meta_y_val = encoded_data[name]['valid'][dependent_features]\n",
    "\n",
    "\n",
    "    y_pred_train = meta_model.predict(meta_X)\n",
    "    y_pred_prob_train = meta_model.predict_proba(meta_X)[:, 1]\n",
    "\n",
    "    print(\"\\nüìò TRAIN METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(meta_y, y_pred_train))\n",
    "    print(\"Precision:\", precision_score(meta_y, y_pred_train))\n",
    "    print(\"Recall   :\", recall_score(meta_y, y_pred_train))\n",
    "    print(\"F1-score :\", f1_score(meta_y, y_pred_train))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(meta_y, y_pred_prob_train))\n",
    "\n",
    "    # ===============================\n",
    "    # üîπ Validation Metrics\n",
    "    # ===============================\n",
    "    y_pred_val = meta_model.predict(meta_X_val)\n",
    "    y_pred_prob_val = meta_model.predict_proba(meta_X_val)[:, 1]\n",
    "\n",
    "    print(\"\\nüìó VALIDATION METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(meta_y_val, y_pred_val))\n",
    "    print(\"Precision:\", precision_score(meta_y_val, y_pred_val))\n",
    "    print(\"Recall   :\", recall_score(meta_y_val, y_pred_val))\n",
    "    print(\"F1-score :\", f1_score(meta_y_val, y_pred_val))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(meta_y_val, y_pred_prob_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb309388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting NN for Dataset 2 (ndarvind/phiusiil-phishing): 100%|‚ñà| 368/368 [00:07\n",
      "Predicting NN for Dataset 2 (ndarvind/phiusiil-phishing): 100%|‚ñà| 46/46 [00:00<0\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [02:02:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"bjective\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò TRAIN METRICS\n",
      "Accuracy : 0.998231507838722\n",
      "Precision: 0.9970789155011601\n",
      "Recall   : 0.999842417500927\n",
      "F1-score : 0.9984587543217361\n",
      "ROC AUC  : 0.9991044450185509\n",
      "\n",
      "üìó VALIDATION METRICS\n",
      "Accuracy : 0.9977057398988826\n",
      "Precision: 0.9962314342717801\n",
      "Recall   : 0.9997775305895439\n",
      "F1-score : 0.9980013324450366\n",
      "ROC AUC  : 0.9991988231459664\n"
     ]
    }
   ],
   "source": [
    "#xgboost(nn+xgboost)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "independent_features = ['url_length', 'hostname_length', 'path_length',\n",
    "    'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params',\n",
    "    'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip',\n",
    "    'has_subdomain', 'has_suspicious_words', 'domain_length',\n",
    "    'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency',\n",
    "    'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain',\n",
    "    'double_slash_in_path']\n",
    "dependent_features  = 'label'\n",
    "logistic_model = {}\n",
    "for name in encoded_data:\n",
    "    #print(model_dict[name])\n",
    "    #print(nn_model[name])\n",
    "    nn_model[name].eval()\n",
    "    with torch.no_grad():\n",
    "        model = nn_model[name]\n",
    "        #print(model)\n",
    "        x_ = encoded_data[name]['train']['encode']\n",
    "        x_np = np.stack(x_.values)\n",
    "        x_ = torch.tensor(x_np, dtype=torch.long).to(device)  # move once to GPU/CPU where model is\n",
    "        batch_size = 512  # adjust for your GPU memory\n",
    "        nn_preds_train = []\n",
    "\n",
    "        # üîπ Process manually in batches\n",
    "        for i in tqdm(range(0, len(x_), batch_size), desc=f\"Predicting NN for {name}\", ncols=80):\n",
    "            batch_x = x_[i:i + batch_size]\n",
    "            outputs = model(batch_x)\n",
    "            nn_preds_train.append(outputs)\n",
    "\n",
    "    # üîπ Combine all predictions\n",
    "    nn_preds_train = torch.cat(nn_preds_train, dim=0).cpu()\n",
    "\n",
    "    # XGBoost predictions\n",
    "    xgb_preds_train = model_dict[name].predict_proba(encoded_data[name]['train'][independent_features])[:, 1]\n",
    "\n",
    "    # Stack predictions as new features\n",
    "    meta_X = np.column_stack((nn_preds_train, xgb_preds_train))\n",
    "    meta_y = encoded_data[name]['train'][dependent_features]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_ = encoded_data[name]['valid']['encode']\n",
    "        x_np = np.stack(x_.values)\n",
    "        x_ = torch.tensor(x_np, dtype=torch.long).to(device)  # move once to GPU/CPU where model is\n",
    "        batch_size = 512  # adjust for your GPU memory\n",
    "        nn_preds_val = []\n",
    "\n",
    "        # üîπ Process manually in batches\n",
    "        for i in tqdm(range(0, len(x_), batch_size), desc=f\"Predicting NN for {name}\", ncols=80):\n",
    "            batch_x = x_[i:i + batch_size]\n",
    "            outputs = model(batch_x)\n",
    "            nn_preds_val.append(outputs)\n",
    "\n",
    "    # üîπ Combine all predictions\n",
    "    nn_preds_val = torch.cat(nn_preds_val, dim=0).cpu()\n",
    "    # XGBoost predictions\n",
    "    xgb_preds_val = model_dict[name].predict_proba(encoded_data[name]['valid'][independent_features])[:, 1]\n",
    "\n",
    "    # Stack predictions as new features\n",
    "    meta_X_val = np.column_stack((nn_preds_val, xgb_preds_val))\n",
    "    meta_y_val = encoded_data[name]['valid'][dependent_features]\n",
    "\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        bjective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        max_depth = 10,\n",
    "        random_state=42,\n",
    "        \n",
    "    )\n",
    "\n",
    "    xgb_model.fit(\n",
    "        meta_X, meta_y,\n",
    "        #eval_set=[(meta_X_val, meta_y_val)],\n",
    "    )\n",
    "\n",
    "\n",
    "    y_pred_train = meta_model.predict(meta_X)\n",
    "    y_pred_prob_train = meta_model.predict_proba(meta_X)[:, 1]\n",
    "\n",
    "    print(\"\\nüìò TRAIN METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(meta_y, y_pred_train))\n",
    "    print(\"Precision:\", precision_score(meta_y, y_pred_train))\n",
    "    print(\"Recall   :\", recall_score(meta_y, y_pred_train))\n",
    "    print(\"F1-score :\", f1_score(meta_y, y_pred_train))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(meta_y, y_pred_prob_train))\n",
    "\n",
    "    # ===============================\n",
    "    # üîπ Validation Metrics\n",
    "    # ===============================\n",
    "    y_pred_val = meta_model.predict(meta_X_val)\n",
    "    y_pred_prob_val = meta_model.predict_proba(meta_X_val)[:, 1]\n",
    "\n",
    "    print(\"\\nüìó VALIDATION METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(meta_y_val, y_pred_val))\n",
    "    print(\"Precision:\", precision_score(meta_y_val, y_pred_val))\n",
    "    print(\"Recall   :\", recall_score(meta_y_val, y_pred_val))\n",
    "    print(\"F1-score :\", f1_score(meta_y_val, y_pred_val))\n",
    "    print(\"ROC AUC  :\", roc_auc_score(meta_y_val, y_pred_prob_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a552e7",
   "metadata": {},
   "source": [
    "# Fedrated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04233875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________üß© Using 5% of training data____________\n",
      "Epoch 1/5 Training CNN + Embeding| Train Loss: 0.5441, Train Acc: 0.7316 | Val Loss: 0.5311, Val Acc: 0.7398\n",
      "Epoch 2/5 Training CNN + Embeding| Train Loss: 0.4938, Train Acc: 0.7921 | Val Loss: 0.4803, Val Acc: 0.8094\n",
      "Epoch 3/5 Training CNN + Embeding| Train Loss: 0.5178, Train Acc: 0.7539 | Val Loss: 0.5223, Val Acc: 0.7461\n",
      "Epoch 4/5 Training CNN + Embeding| Train Loss: 0.4943, Train Acc: 0.7724 | Val Loss: 0.4927, Val Acc: 0.7719\n",
      "Epoch 5/5 Training CNN + Embeding| Train Loss: 0.2988, Train Acc: 0.9098 | Val Loss: 0.3008, Val Acc: 0.9031\n"
     ]
    }
   ],
   "source": [
    "#train global model on little part(5%) of dataset\n",
    "dataset_name = 'Dataset 2 (ndarvind/phiusiil-phishing)'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_model = URLBinaryCNN(vocab_size=len(vocab)).to(device)\n",
    "loaders = dataloader_dict[dataset_name]\n",
    "train_loader = loaders[\"train_loader\"]\n",
    "val_loader = loaders[\"val_loader\"]\n",
    "lr  = 0.01\n",
    "print(f\"üß© Using {0.05*100:.0f}% of training data\".center(50, '_'))\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.NAdam(global_model.parameters(), lr=lr, weight_decay=lr/10)\n",
    "trainer = Train(global_model, criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "# Lists to track performance\n",
    "trainer.train(epochs_list=[5],frac=0.05,val_frac=0.05, log=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "26c919f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50460524e-04 3.88989434e-01 1.17394893e-02 3.28685992e-02\n",
      " 6.62520174e-02]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# using alpha to produce unidentical splits high alpha more identical\n",
    "num_clients = 5\n",
    "alpha = 0.5\n",
    "total_data = 0.5\n",
    "client_fractions = np.random.dirichlet([alpha] * num_clients) * total_data\n",
    "print(client_fractions)\n",
    "print(client_fractions.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0db4548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models = []\n",
    "for i in range(num_clients):\n",
    "    client_model = URLBinaryCNN(vocab_size=len(vocab)).to(device)                     # fresh instance\n",
    "    client_model.load_state_dict(global_model.state_dict())\n",
    "    client_models.append(client_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "265ed08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clints initial accuracy\n",
      "0.00031488906824961305 1.0\n",
      "0.016156392587112753 0.9976128472222222\n",
      "0.00047816982259973884 1.0\n",
      "0.014619543587156971 0.9977678571428571\n",
      "0.014312390919907816 0.9977678571428571\n"
     ]
    }
   ],
   "source": [
    "print('clints initial accuracy')\n",
    "start = 0\n",
    "for i, model in enumerate(client_models):\n",
    "    criterion = nn.BCELoss()\n",
    "    trainer = Train(model, criterion=criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "    avg_val_loss, val_acc = trainer.evaluate(frac=client_fractions[i], start=start, log=2)\n",
    "    start += client_fractions[i]\n",
    "    print(avg_val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "78eb1f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0997, Train Acc: 0.9922 | Val Loss: 0.0084, Val Acc: 0.9922\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0012, Train Acc: 1.0000 | Val Loss: 0.0079, Val Acc: 0.9922\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0177, Train Acc: 0.9973 | Val Loss: 0.0144, Val Acc: 0.9977\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.4952, Train Acc: 0.7842 | Val Loss: 0.4883, Val Acc: 0.8171\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0370, Train Acc: 0.9971 | Val Loss: 0.0294, Val Acc: 0.9948\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0056, Train Acc: 0.9996 | Val Loss: 0.0176, Val Acc: 0.9974\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0171, Train Acc: 0.9981 | Val Loss: 0.0152, Val Acc: 0.9978\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0196, Train Acc: 0.9973 | Val Loss: 0.0155, Val Acc: 0.9978\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0243, Train Acc: 0.9968 | Val Loss: 0.0138, Val Acc: 0.9982\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0186, Train Acc: 0.9974 | Val Loss: 0.0112, Val Acc: 0.9982\n"
     ]
    }
   ],
   "source": [
    "# trainig clints\n",
    "start = 0\n",
    "for i, model in enumerate(client_models):\n",
    "    criterion = nn.BCELoss()\n",
    "    trainer = Train(model, criterion=criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "    trainer.train(epochs_list=[2,0,0],frac=client_fractions[i], val_frac=client_fractions[i], start=start, log=2)\n",
    "    start += client_fractions[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "acbbdc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tansfering weights and averaging them\n",
    "import copy\n",
    "client_weights = [client_model.state_dict() for client_model in client_models]\n",
    "total_samples = sum(client_fractions)\n",
    "\n",
    "new_global_state = copy.deepcopy(global_model.state_dict())\n",
    "\n",
    "# set all params to zero before summing\n",
    "for key in new_global_state.keys():\n",
    "    new_global_state[key] = torch.zeros_like(new_global_state[key])\n",
    "\n",
    "# aggregate client updates\n",
    "for client_model, n_i in zip(client_models, client_fractions):\n",
    "    client_state = client_model.state_dict()\n",
    "    for key in new_global_state.keys():\n",
    "        new_global_state[key] += client_state[key] * (n_i / total_samples)\n",
    "\n",
    "# load averaged weights back into global model\n",
    "global_model.load_state_dict(new_global_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cee22a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458191404385226 0.6873604910714286\n"
     ]
    }
   ],
   "source": [
    "trainer = Train(global_model, criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "avg_val_loss, val_acc = trainer.evaluate(frac=0.3, start=0, log=2)\n",
    "print(avg_val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f6784cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def make_clients(num_clients=5, alpha=0.5, total_data=1):\n",
    "    import numpy as np\n",
    "    # using alpha to produce unidentical splits high alpha more identical\n",
    "    client_fractions = np.random.dirichlet([alpha] * num_clients) * total_data\n",
    "    client_models = []\n",
    "    for i in range(num_clients):\n",
    "        client_model = URLBinaryCNN(vocab_size=len(vocab)).to(device)                     # fresh instance\n",
    "        client_model.load_state_dict(global_model.state_dict())\n",
    "        client_models.append(client_model)\n",
    "    return client_model, client_fractions\n",
    "def train_client(client_models, client_fractions, start=0):\n",
    "    for i, _ in enumerate(client_models):\n",
    "        criterion = nn.BCELoss()\n",
    "        trainer = Train(client_models[i], criterion=criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "        trainer.train(epochs_list=[2,0,0],frac=client_fractions[i], val_frac=client_fractions[i], start=start, log=2)\n",
    "        start += client_fractions[i]\n",
    "def fed_avg(client_models, client_fractions):\n",
    "    total_samples = sum(client_fractions)\n",
    "    new_global_state = copy.deepcopy(global_model.state_dict())\n",
    "    # set all params to zero before summing\n",
    "    for key in new_global_state.keys():\n",
    "        new_global_state[key] = torch.zeros_like(new_global_state[key])\n",
    "    # aggregate client updates\n",
    "    for client_model, n_i in zip(client_models, client_fractions):\n",
    "        client_state = client_model.state_dict()\n",
    "        for key in new_global_state.keys():\n",
    "            new_global_state[key] += client_state[key] * (n_i / total_samples)\n",
    "    # load averaged weights back into global model\n",
    "    global_model.load_state_dict(new_global_state)\n",
    "def update_clients(client_models):\n",
    "    for client_model in client_models:\n",
    "        client_model.load_state_dict(global_model.state_dict())\n",
    "client_model, client_fractions = make_clients(5, total_data=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2dbc7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0146, Train Acc: 0.9978 | Val Loss: 0.0116, Val Acc: 0.9984\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0144, Train Acc: 0.9977 | Val Loss: 0.0105, Val Acc: 0.9984\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0250, Train Acc: 0.9971 | Val Loss: 0.0110, Val Acc: 0.9984\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0199, Train Acc: 0.9975 | Val Loss: 0.0114, Val Acc: 0.9984\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0172, Train Acc: 0.9980 | Val Loss: 0.0151, Val Acc: 0.9979\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0202, Train Acc: 0.9967 | Val Loss: 0.0130, Val Acc: 0.9979\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0178, Train Acc: 0.9980 | Val Loss: 0.0266, Val Acc: 0.9961\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0158, Train Acc: 0.9980 | Val Loss: 0.0261, Val Acc: 0.9961\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0147, Train Acc: 0.9980 | Val Loss: 0.0133, Val Acc: 0.9980\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0180, Train Acc: 0.9975 | Val Loss: 0.0107, Val Acc: 0.9984\n",
      "global model loss 0.03339810103144763 accuracy 0.9878627232142857\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0173, Train Acc: 0.9976 | Val Loss: 0.0127, Val Acc: 0.9980\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0235, Train Acc: 0.9971 | Val Loss: 0.0136, Val Acc: 0.9980\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0185, Train Acc: 0.9964 | Val Loss: 0.0124, Val Acc: 0.9984\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0219, Train Acc: 0.9962 | Val Loss: 0.0110, Val Acc: 0.9984\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0163, Train Acc: 0.9974 | Val Loss: 0.0124, Val Acc: 0.9979\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0120, Train Acc: 0.9985 | Val Loss: 0.0134, Val Acc: 0.9979\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0282, Train Acc: 0.9961 | Val Loss: 0.0261, Val Acc: 0.9961\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0141, Train Acc: 0.9971 | Val Loss: 0.0305, Val Acc: 0.9961\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0225, Train Acc: 0.9965 | Val Loss: 0.0114, Val Acc: 0.9980\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0129, Train Acc: 0.9976 | Val Loss: 0.0109, Val Acc: 0.9977\n",
      "global model loss 0.0195758557820227 accuracy 0.9972098214285714\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0188, Train Acc: 0.9976 | Val Loss: 0.0094, Val Acc: 0.9988\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0182, Train Acc: 0.9974 | Val Loss: 0.0103, Val Acc: 0.9984\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0230, Train Acc: 0.9969 | Val Loss: 0.0120, Val Acc: 0.9984\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0203, Train Acc: 0.9971 | Val Loss: 0.0125, Val Acc: 0.9984\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0296, Train Acc: 0.9976 | Val Loss: 0.0202, Val Acc: 0.9979\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0308, Train Acc: 0.9946 | Val Loss: 0.0169, Val Acc: 0.9979\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0111, Train Acc: 0.9990 | Val Loss: 0.0431, Val Acc: 0.9961\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0181, Train Acc: 0.9966 | Val Loss: 0.0277, Val Acc: 0.9922\n",
      "Epoch 1/2 Training CNN + Embeding| Train Loss: 0.0134, Train Acc: 0.9979 | Val Loss: 0.0092, Val Acc: 0.9984\n",
      "Epoch 2/2 Training CNN + Embeding| Train Loss: 0.0205, Train Acc: 0.9971 | Val Loss: 0.0104, Val Acc: 0.9984\n",
      "global model loss 0.015252613863724816 accuracy 0.9974888392857143\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    train_client(client_models, client_fractions, start=0.3)   \n",
    "    fed_avg(client_models, client_fractions)\n",
    "    update_clients(client_models)\n",
    "    trainer = Train(global_model, criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "    avg_val_loss, val_acc = trainer.evaluate(frac=0.3, start=0, log=2)\n",
    "    print(f'global model loss {avg_val_loss} accuracy {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc1727",
   "metadata": {},
   "source": [
    "## fedrated learning with persnalization\n",
    "# meta learing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f56025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset 1 (Malicious URLs)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b684c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________üß© Using 10% of training data___________\n",
      "Epoch 1/10 Training global+personal| Train Loss: 0.2040, Train Acc: 0.9251 | Val Loss: 0.1872, Val Acc: 0.9379\n",
      "Epoch 2/10 Training global+personal| Train Loss: 0.1480, Train Acc: 0.9555 | Val Loss: 0.1321, Val Acc: 0.9584\n",
      "Epoch 3/10 Training global+personal| Train Loss: 0.1322, Train Acc: 0.9610 | Val Loss: 0.1214, Val Acc: 0.9627\n",
      "Epoch 4/10 Training global+personal| Train Loss: 0.1494, Train Acc: 0.9509 | Val Loss: 0.1381, Val Acc: 0.9523\n",
      "Epoch 5/10 Training global+personal| Train Loss: 0.1142, Train Acc: 0.9641 | Val Loss: 0.1058, Val Acc: 0.9641\n",
      "Epoch 6/10 Training global+personal| Train Loss: 0.1112, Train Acc: 0.9649 | Val Loss: 0.0984, Val Acc: 0.9662\n",
      "Epoch 7/10 Training global+personal| Train Loss: 0.1138, Train Acc: 0.9626 | Val Loss: 0.1057, Val Acc: 0.9618\n",
      "Epoch 8/10 Training global+personal| Train Loss: 0.1051, Train Acc: 0.9674 | Val Loss: 0.0973, Val Acc: 0.9681\n",
      "Epoch 9/10 Training global+personal| Train Loss: 0.1018, Train Acc: 0.9683 | Val Loss: 0.0934, Val Acc: 0.9691\n",
      "Epoch 10/10 Training global+personal| Train Loss: 0.0949, Train Acc: 0.9707 | Val Loss: 0.0836, Val Acc: 0.9710\n"
     ]
    }
   ],
   "source": [
    "#train global model on little part(5%) of dataset\n",
    "dataset_name = list(dataloader_dict.keys())[0]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_model = URLBinaryCNN(vocab_size=len(vocab), maxlen=60).to(device)\n",
    "loaders = dataloader_dict[dataset_name]\n",
    "train_loader = loaders[\"train_loader\"]\n",
    "val_loader = loaders[\"val_loader\"]\n",
    "lr_p=0.001\n",
    "lr_g=0.001\n",
    "frac = 0.1\n",
    "print(f\"üß© Using {frac*100:.0f}% of training data\".center(50, '_'))\n",
    "\n",
    "global_params = []\n",
    "persnalization_params = []\n",
    "for name, param in global_model.embeding_layer.named_parameters():\n",
    "    global_params.append(param)\n",
    "for name, param in global_model.shared_layer.named_parameters():\n",
    "    global_params.append(param)\n",
    "for name, param in global_model.personal_layer.named_parameters():\n",
    "    persnalization_params.append(param)\n",
    "criterion = nn.BCELoss()\n",
    "personal_optimizer = torch.optim.NAdam(global_params, lr=lr_p, weight_decay=lr_p/10)\n",
    "global_optimizer = torch.optim.NAdam(persnalization_params, lr=lr_g, weight_decay=lr_g/10)\n",
    "personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(personal_optimizer, mode='max', factor=0.5, patience=3)\n",
    "global_scheduler = optim.lr_scheduler.ReduceLROnPlateau(global_optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "trainer = Train(global_model, criterion, train_loader=train_loader, val_loader=val_loader, personal_optimizer=personal_optimizer, global_optimizer=global_optimizer, scheduler_g=global_scheduler, scheduler_p=personal_scheduler)\n",
    "        \n",
    "# Lists to track performance\n",
    "trainer.train(epochs_list=[10,0,0],frac=frac,val_frac=frac, log=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b821ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def make_clients(num_clients=5, alpha=0.5, total_data=1):\n",
    "    import numpy as np\n",
    "    # using alpha to produce unidentical splits high alpha more identical\n",
    "    client_fractions = np.random.dirichlet([alpha] * num_clients) * total_data\n",
    "    client_models = []\n",
    "    for i in range(num_clients):\n",
    "        client_model = URLBinaryCNN(vocab_size=len(vocab), maxlen=60).to(device)                     # fresh instance\n",
    "        client_model.load_state_dict(global_model.state_dict())\n",
    "        client_models.append(client_model)\n",
    "    return client_models, client_fractions\n",
    "def quick_fine_tune(model, frac, start=0):\n",
    "    criterion = nn.BCELoss()\n",
    "    global_params = []\n",
    "    persnalization_params = []\n",
    "    for name, param in global_model.embeding_layer.named_parameters():\n",
    "        global_params.append(param)\n",
    "    for name, param in global_model.shared_layer.named_parameters():\n",
    "        global_params.append(param)\n",
    "    for name, param in global_model.personal_layer.named_parameters():\n",
    "        persnalization_params.append(param)\n",
    "    criterion = nn.BCELoss()\n",
    "    lr_p=0.001\n",
    "    personal_optimizer = torch.optim.NAdam(global_params, lr=lr_p, weight_decay=lr_p/10)\n",
    "    personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(personal_optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    trainer = Train(model, criterion=criterion, train_loader=train_loader, personal_optimizer=personal_optimizer, scheduler_p=personal_scheduler)\n",
    "    trainer.train(epochs_list=[0,0,2],frac=frac, start=start, log=0)\n",
    "def train_client(client_models, client_fractions, start=0, epoch=4):\n",
    "    print(\"training model: \",end='')\n",
    "    for i, _ in enumerate(client_models):\n",
    "        print(i, end=', ')\n",
    "        criterion = nn.BCELoss()\n",
    "        global_params = []\n",
    "        persnalization_params = []\n",
    "        for name, param in global_model.embeding_layer.named_parameters():\n",
    "            global_params.append(param)\n",
    "        for name, param in global_model.shared_layer.named_parameters():\n",
    "            global_params.append(param)\n",
    "        for name, param in global_model.personal_layer.named_parameters():\n",
    "            persnalization_params.append(param)\n",
    "        criterion = nn.BCELoss()\n",
    "        lr_p=0.001\n",
    "        lr_g=0.0001\n",
    "        personal_optimizer = torch.optim.NAdam(global_params, lr=lr_p, weight_decay=lr_p/10)\n",
    "        global_optimizer = torch.optim.NAdam(persnalization_params, lr=lr_g, weight_decay=lr_g/10)\n",
    "        personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(personal_optimizer, mode='max', factor=0.5, patience=3)\n",
    "        global_scheduler = optim.lr_scheduler.ReduceLROnPlateau(global_optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "        trainer = Train(client_models[i], criterion=criterion, train_loader=train_loader, val_loader=val_loader, personal_optimizer=personal_optimizer, global_optimizer=global_optimizer, scheduler_g=global_scheduler, scheduler_p=personal_scheduler)\n",
    "        trainer.train(epochs_list=[epoch,0,0],frac=client_fractions[i], val_frac=client_fractions[i], start=start, log=0)\n",
    "        start += client_fractions[i]\n",
    "    print()\n",
    "def fed_meta_persnalization_learing(global_model, client_models, client_fractions, meta_lr=0.1):\n",
    "    total_samples = sum(client_fractions)\n",
    "    weights = [n_i / total_samples for n_i in client_fractions]\n",
    "    global_state = {\n",
    "        **global_model.embeding_layer.state_dict(),\n",
    "        **global_model.shared_layer.state_dict()\n",
    "    }\n",
    "\n",
    "    avg_state = copy.deepcopy(global_state)\n",
    "    for key in avg_state.keys():\n",
    "        avg_state[key] = torch.zeros_like(avg_state[key])\n",
    "        for client_model, w in zip(client_models, weights):\n",
    "            client_state = {\n",
    "                **client_model.embeding_layer.state_dict(),\n",
    "                **client_model.shared_layer.state_dict()\n",
    "            }\n",
    "            avg_state[key] += client_state[key] * w\n",
    "\n",
    "    new_state = {}\n",
    "    for key in global_state.keys():\n",
    "        new_state[key] = (1-meta_lr) * global_state[key] + meta_lr * (avg_state[key] - global_state[key])\n",
    "\n",
    "    # 5Ô∏è‚É£ Load updated parameters into global model\n",
    "    global_model.embeding_layer.load_state_dict({\n",
    "        k: v for k, v in new_state.items() if k in global_model.embeding_layer.state_dict()\n",
    "    })\n",
    "    global_model.shared_layer.load_state_dict({\n",
    "        k: v for k, v in new_state.items() if k in global_model.shared_layer.state_dict()\n",
    "    })\n",
    "\n",
    "    quick_fine_tune(global_model, 0.1, 0)\n",
    "def update_clients(client_models, client_fractions, global_model):\n",
    "    start=0.1\n",
    "    for i, client in enumerate(client_models):\n",
    "        client.embeding_layer.load_state_dict(global_model.embeding_layer.state_dict())\n",
    "        client.shared_layer.load_state_dict(global_model.shared_layer.state_dict())\n",
    "        quick_fine_tune(client, client_fractions[i], start)\n",
    "        start+=client_fractions[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1268aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10497028 0.4931363  0.01821473 0.00252451 0.28115418]\n",
      "clints initial accuracy\n",
      "starting from batch 10 ending to batch 21 total validation batch size 21\n",
      "0.08814320984211835 0.9718945176960444 0.10497028132288955\n",
      "starting from batch 20 ending to batch 70 total validation batch size 70\n",
      "0.0830533716827631 0.9720229007633587 0.493136299220213\n",
      "starting from batch 69 ending to batch 72 total validation batch size 72\n",
      "0.0913119191924731 0.9688295165394402 0.018214726368543974\n",
      "starting from batch 71 ending to batch 72 total validation batch size 72\n",
      "0.07564617693424225 0.9770992366412213 0.0025245089054052312\n",
      "starting from batch 71 ending to batch 101 total validation batch size 101\n",
      "0.08442574667446635 0.9711583294478119 0.2811541841829483\n"
     ]
    }
   ],
   "source": [
    "client_models, client_fractions = make_clients(5, total_data=0.9) \n",
    "print(client_fractions)\n",
    "print('clints initial accuracy')\n",
    "start = 0.1\n",
    "for i, model in enumerate(client_models):\n",
    "    criterion = nn.BCELoss()\n",
    "    trainer = Train(model, criterion=criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "    avg_val_loss, val_acc = trainer.evaluate(frac=client_fractions[i], start=start, log=3)\n",
    "    start += client_fractions[i]\n",
    "    print(avg_val_loss, val_acc, client_fractions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f929cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: 0, 1, 2, 3, 4, \n",
      "global model loss 0.1033929017457095 accuracy 0.9661693268563497\n",
      "training model: 0, 1, 2, 3, 4, \n",
      "global model loss 0.1379835937510837 accuracy 0.9585357390700903\n"
     ]
    }
   ],
   "source": [
    "trainer = Train(global_model, criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "for i in range(2):\n",
    "    train_client(client_models, client_fractions, start=0.1)   \n",
    "    fed_meta_persnalization_learing(global_model, client_models, client_fractions)\n",
    "    update_clients(client_models,client_fractions, global_model)\n",
    "    avg_val_loss, val_acc = trainer.evaluate(frac=0.1, start=0, log=0)\n",
    "    print(f'global model loss {avg_val_loss} accuracy {val_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
