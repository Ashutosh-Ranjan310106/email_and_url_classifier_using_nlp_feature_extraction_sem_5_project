{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2ae588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                                url\n",
      "0     2                        https://blog.sockpuppet.us/\n",
      "1     2                  https://blog.apiki.com/seguranca/\n",
      "2     1  http://autoecole-lauriston.com/a/T0RVd056QXlNe...\n",
      "3     1  http://chinpay.site/index.html?hgcFSE@E$Z*DFcG...\n",
      "4     2  http://www.firstfivenebraska.org/blog/article/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\email_and_url_classifier_using_nlp_feature_extraction_sem_5_project\\three_datasets.py:70: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df4['label'][df4['label'] == 1] = 0\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\email_and_url_classifier_using_nlp_feature_extraction_sem_5_project\\three_datasets.py:71: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df4['label'][df4['label'] == 2] = 1\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\email_and_url_classifier_using_nlp_feature_extraction_sem_5_project\\three_datasets.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df['label'].apply(lambda x: 1 if x in phishing_labels else 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset 1 (Malicious URLs) cleaned: 522214 samples (Phishing=94111, Benign=428103)\n",
      "\n",
      "📂 Dataset 1 (Malicious URLs) split → Train: 417732, Valid: 52217, Test: 52217\n",
      "\n",
      "📂 Dataset 1 (Malicious URLs) split → Train: 188296, Valid: 23537, Test: 23537\n",
      "\n",
      "📂 Dataset 1 (Malicious URLs) split → Train: 528097, Valid: 66012, Test: 66013\n",
      "\n",
      "📂 Dataset 1 (Malicious URLs) split → Train: 639999, Valid: 80000, Test: 80000\n",
      "✅ Seed fixed to 42\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Subset\n",
    "from urllib.parse import urlparse\n",
    "from three_datasets import all_dataset\n",
    "import random\n",
    "tqdm.pandas()\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"✅ Seed fixed to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3c3080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "You are using a model of type canine to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.layer_norm.weight', 'encoder.block.10.layer.1.DenseReluDense.wi.weight', 'encoder.block.10.layer.1.DenseReluDense.wo.weight', 'encoder.block.10.layer.1.layer_norm.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.layer_norm.weight', 'encoder.block.11.layer.1.DenseReluDense.wi.weight', 'encoder.block.11.layer.1.DenseReluDense.wo.weight', 'encoder.block.11.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.layer_norm.weight', 'encoder.block.6.layer.1.DenseReluDense.wi.weight', 'encoder.block.6.layer.1.DenseReluDense.wo.weight', 'encoder.block.6.layer.1.layer_norm.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.layer_norm.weight', 'encoder.block.7.layer.1.DenseReluDense.wi.weight', 'encoder.block.7.layer.1.DenseReluDense.wo.weight', 'encoder.block.7.layer.1.layer_norm.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.layer_norm.weight', 'encoder.block.8.layer.1.DenseReluDense.wi.weight', 'encoder.block.8.layer.1.DenseReluDense.wo.weight', 'encoder.block.8.layer.1.layer_norm.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.layer_norm.weight', 'encoder.block.9.layer.1.DenseReluDense.wi.weight', 'encoder.block.9.layer.1.DenseReluDense.wo.weight', 'encoder.block.9.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,  T5EncoderModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"google/canine-s\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5EncoderModel.from_pretrained(model_name)  \n",
    "model.eval()\n",
    "def get_byt5_embedding(url):\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(url, return_tensors=\"pt\", truncation=True, padding=True, max_length=50)\n",
    "    \n",
    "    # Get encoder output (not generate)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # outputs.last_hidden_state: [batch_size, seq_len, hidden_dim]\n",
    "         \n",
    "        # Mean pooling across sequence\n",
    "        emb = outputs.last_hidden_state.mean(dim=1).reshape(-1)\n",
    "    return emb.cpu().numpy()\n",
    "\n",
    "# Example\n",
    "#url = \"http://paypal-login-secure-update.com\"\n",
    "#vector = get_byt5_embedding(url)\n",
    "#print(\"Embedding shape:\", vector.shape)  # e.g. (512,) or (768,) depending on model size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load once globally (so it doesn't reload every call)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"google/canine-s\"  # or \"google/canine-c\" (larger, slower)\n",
    "\n",
    "# Load model + tokenizer only once\n",
    "tokenizer_canine = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model_canine = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model_canine.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_canine_embedding(url, max_length=50, pooling=\"mean\"):\n",
    "    \"\"\"\n",
    "    Returns a fixed-length CANINE embedding for a single URL string.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL text to encode.\n",
    "        max_length (int): Maximum length of character sequence (truncate/pad to this).\n",
    "        pooling (str): 'mean' or 'max' for pooling token embeddings into one vector.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 1D embedding vector (shape [hidden_dim], e.g. [768]).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Tokenize\n",
    "    encoded = tokenizer_canine(\n",
    "        url,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model_canine(**encoded)\n",
    "    hidden = outputs.last_hidden_state  # [1, seq_len, hidden_dim]\n",
    "    mask = encoded[\"attention_mask\"].unsqueeze(-1).type_as(hidden)  # [1, seq_len, 1]\n",
    "\n",
    "    # Pooling\n",
    "    if pooling == \"mean\":\n",
    "        summed = (hidden * mask).sum(dim=1)\n",
    "        denom = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled = summed / denom  # [1, hidden_dim]\n",
    "    elif pooling == \"max\":\n",
    "        hidden = hidden.masked_fill(mask == 0, -1e9)\n",
    "        pooled = hidden.max(dim=1).values  # [1, hidden_dim]\n",
    "    else:\n",
    "        raise ValueError(\"Pooling must be 'mean' or 'max'\")\n",
    "\n",
    "    return pooled.squeeze(0).cpu().numpy()  # (hidden_dim,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357bf0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔠 Encoding structured URLs for dataset_0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417732/417732 [01:15<00:00, 5503.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ train: Encoded 417732 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52217/52217 [00:09<00:00, 5476.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ valid: Encoded 52217 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52217/52217 [00:09<00:00, 5555.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ test: Encoded 52217 URLs\n",
      "\n",
      "✅ All datasets encoded with proper start/end markers and padding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Character Encoding Setup\n",
    "# ============================================================\n",
    "\n",
    "# Allowed printable ASCII chars\n",
    "ascii_chars = [chr(i) for i in range(32, 127)]\n",
    "\n",
    "# Special control tokens\n",
    "special_tokens = [\n",
    "    '<PAD>', '<UNK>',\n",
    "]\n",
    "\n",
    "# Build vocab and mapping\n",
    "vocab = special_tokens + ascii_chars\n",
    "char2idx = {ch: i for i, ch in enumerate(vocab)}\n",
    "\n",
    "\n",
    "\n",
    "def encode(text, max_len=100):\n",
    "    indices = torch.full((max_len,), char2idx[\"<PAD>\"], dtype=torch.long)\n",
    "    text = text.lower()[:max_len]\n",
    "    for i, c in enumerate(text):\n",
    "        indices[i] = char2idx.get(c, char2idx[\"<UNK>\"])\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoded_data = {}\n",
    "frac = 1\n",
    "gen = all_dataset()\n",
    "\n",
    "\n",
    "\n",
    "for i, splits in zip([f'dataset_{i}' for i in range(4)], gen):\n",
    "    encoded_data[i] = {}\n",
    "    print(f\"\\n🔠 Encoding structured URLs for {i}...\")\n",
    "\n",
    "    for split_name, df in zip(['train', 'valid', 'test'], splits):\n",
    "        df = df.sample(frac=frac, random_state=42)\n",
    "        df[\"encode\"] = df[\"url\"].progress_apply(encode)\n",
    "        encoded_data[i][split_name] = df\n",
    "        print(f\"  ✅ {split_name}: Encoded {len(df)} URLs\")\n",
    "    next(gen)\n",
    "    next(gen)\n",
    "    next(gen)\n",
    "\n",
    "print(\"\\n✅ All datasets encoded with proper start/end markers and padding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eeebb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Creating DataLoaders for dataset_0...\n",
      "✅ DataLoaders ready for dataset_0 (Train/Val/Test)\n",
      "\n",
      "🚀 All DataLoaders are ready in `dataloader_dict`!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# ============================================================\n",
    "# Convert to TensorDataset and DataLoader\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "\n",
    "dataloader_dict = {}\n",
    "\n",
    "def make_tensor_dataset(df):\n",
    "    url_tensor = torch.stack(list(df[\"encode\"]))\n",
    "    labels_tensor = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "    return TensorDataset(url_tensor, labels_tensor)\n",
    "\n",
    "for name, splits in encoded_data.items():\n",
    "    dataloader_dict[name] = {}\n",
    "    print(f\"\\n📦 Creating DataLoaders for {name}...\")\n",
    "    \n",
    "    train_set = make_tensor_dataset(splits[\"train\"])\n",
    "    val_set = make_tensor_dataset(splits[\"valid\"])\n",
    "    test_set = make_tensor_dataset(splits[\"test\"])\n",
    "    \n",
    "    dataloader_dict[name][\"train_loader\"] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    dataloader_dict[name][\"val_loader\"] = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    dataloader_dict[name][\"test_loader\"] = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    print(f\"✅ DataLoaders ready for {name} (Train/Val/Test)\")\n",
    "\n",
    "print(\"\\n🚀 All DataLoaders are ready in `dataloader_dict`!\")\n",
    "\n",
    "# Example Access:\n",
    "# dataloader_dict[\"dataset1\"][\"train_loader\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9ea480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 TinyByT5 Encoder (Reduced depth for short sequences)\n",
    "# =====================================================\n",
    "class TinyByT5Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size=256,\n",
    "                 d_model=128,\n",
    "                 num_layers=2,\n",
    "                 num_heads=2,\n",
    "                 dim_ff=256,\n",
    "                 max_len=100,\n",
    "                 n_out=128,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 🔹 Byte embedding layer (0–255)\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # 🔹 Positional embeddings\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        # 🔹 Transformer encoder layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # 🔹 Final normalization\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.projection = nn.Linear(in_features=d_model, out_features=n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len) — byte indices [0–255]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        #positions = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        #x = self.embedding(x) + self.pos_embedding(positions)\n",
    "\n",
    "        #x = self.encoder(x)\n",
    "        x = self.embedding(x)\n",
    "        x = self.projection(self.final_norm(x))\n",
    "\n",
    "        return x  # (B, L, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6ac0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==========================\n",
    "# 🔹 Tiny Transformer Encoder\n",
    "# ==========================\n",
    "class TinyURLTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, num_heads=2, num_layers=2, ff_dim=128, max_len=100, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, embed_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.projection = nn.Linear(embed_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        #x = self.embedding(x) + self.pos_embedding[:, :x.size(1), :]  # (B, L, E)\n",
    "        #x = self.transformer(x)                                       # (B, L, E)\n",
    "        return self.embedding(x) #self.projection(x)                                     # (B, L, out_dim)\n",
    "\n",
    "class URLBinaryCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, maxlen=100):\n",
    "        super(URLBinaryCNN, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "        self.transformer = TinyByT5Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            max_len=maxlen,\n",
    "            d_model=512,\n",
    "            n_out=embed_dim\n",
    "        )\n",
    "        # 🔹 1st Conv block\n",
    "        self.conv1_3x3 = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.convreduce1_1x1 = nn.Conv1d(in_channels=embed_dim, out_channels=1, kernel_size=1, padding=0)\n",
    "        self.conv1_5x5 = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.conv1_7 = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=7, padding=3)\n",
    "        self.conv1_1x1 = nn.Conv1d(in_channels=128*3, out_channels=128, kernel_size=1, padding=0)\n",
    "        self.layer_norm1 = nn.LayerNorm(normalized_shape=[128, maxlen])\n",
    "\n",
    "\n",
    "         # 🔹 2st Conv block\n",
    "        self.conv2_3x3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.convreduce2_1x1 = nn.Conv1d(in_channels=128, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.conv2_5x5 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.conv2_1x1 = nn.Conv1d(in_channels=64*2, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.layer_norm2 = nn.LayerNorm(normalized_shape=[64, maxlen])\n",
    "        \n",
    "\n",
    "         # 🔹 3st Conv block\n",
    "        self.conv3_3x3 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.convreduce3_1x1 = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=1, padding=0)\n",
    "        self.conv3_5x5 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.conv3_7 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=7, padding=3)\n",
    "        self.conv3_1x1 = nn.Conv1d(in_channels=32*3, out_channels=32, kernel_size=1, padding=0)\n",
    "        self.layer_norm3 = nn.LayerNorm(normalized_shape=[32, maxlen])\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, num_layers=1, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.aap = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # 🔹 Fully connected layers\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # (batch, seq_len)\n",
    "        x = self.transformer(x)           # (B, L, E)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)            # (B, E, L)\n",
    "\n",
    "\n",
    "\n",
    "        # 🔹 Block 1\n",
    "        x3 = F.relu(self.conv1_3x3(x))\n",
    "\n",
    "        #xr = F.relu(self.convreduce1_1x1(x))\n",
    "        x5 = F.relu(self.conv1_5x5(x))\n",
    "        x7 = F.relu(self.conv1_7(x))\n",
    "\n",
    "        x = torch.cat([x3, x5, x7], dim=1)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv1_1x1(x))\n",
    "\n",
    "        #x = self.layer_norm1(x)\n",
    "\n",
    "\n",
    "        '''\n",
    "        # 🔹 Block 2\n",
    "        x3 = F.relu(self.conv2_3x3(x))\n",
    "        xr = F.relu(self.convreduce2_1x1(x))\n",
    "        x5 = F.relu(self.conv2_5x5(xr))\n",
    "        x = torch.cat([x3, x5], dim=1)\n",
    "        x = F.relu(self.conv2_1x1(x))\n",
    "        x = self.layer_norm2(x)\n",
    "        '''\n",
    "        # 🔹 Block 3\n",
    "        #x = F.relu(self.conv3_3x3(x))\n",
    "        #xr = F.relu(self.convreduce3_1x1(x))\n",
    "        #x5 = F.relu(self.conv3_5x5(x))\n",
    "        #x7 = F.relu(self.conv3_7(x))\n",
    "        #x = torch.cat([x3, x5, x7], dim=1)\n",
    "        #x = F.relu(self.conv3_1x1(x))\n",
    "        #x = self.layer_norm3(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        # 🔹 Global Average Pooling + FC\n",
    "        #x = self.aap(x)                   # (batch, channels, 1)\n",
    "        x = self.flatten(x)               # (batch, channels)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        \"\"\"Return deep features before final FC layers.\"\"\"\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x3 = F.relu(self.conv1_3x3(x))\n",
    "        x5 = F.relu(self.conv1_5x5(x))\n",
    "        x7 = F.relu(self.conv1_7(x))\n",
    "        x = torch.cat([x3, x5, x7], dim=1)\n",
    "        x = F.relu(self.conv1_1x1(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]          # shape: [batch, 32]\n",
    "        x = self.flatten(x) \n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64290975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 criterion, \n",
    "                 transformer_optimizer=None,\n",
    "                 main_optimizer = None, \n",
    "                 scheduler_t=None,\n",
    "                 scheduler_c=None,\n",
    "                 train_loader=None, \n",
    "                 val_loader=None,   \n",
    "                 device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        \n",
    "        \"\"\"\n",
    "        optimizer_groups: dict with keys like {\"transformer\": optimizer1, \"cnn\": optimizer2}\n",
    "        schedulers: dict with keys matching optimizer_groups (optional)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.transformer_params = []\n",
    "        self.cnn_params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith(\"transformer.\"):\n",
    "                self.transformer_params.append(param)\n",
    "            else:\n",
    "                self.cnn_params.append(param)\n",
    "\n",
    "\n",
    "\n",
    "        self.transformer_optimizer = optim.Adam(self.transformer_params, lr=1e-4) if transformer_optimizer is None  else transformer_optimizer\n",
    "        self.main_optimizer = optim.Adam(self.cnn_params, lr=1e-3) if main_optimizer is None else main_optimizer\n",
    "        self.scheduler_t = optim.lr_scheduler.ReduceLROnPlateau(self.transformer_optimizer, mode='min', factor=0.5, patience=2) if scheduler_t is None  else scheduler_t\n",
    "        self.scheduler_c = optim.lr_scheduler.ReduceLROnPlateau(self.main_optimizer, mode='min', factor=0.5, patience=2) if scheduler_c is None  else scheduler_c\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses, self.val_losses = [], []\n",
    "        self.train_accs, self.val_accs = [], []\n",
    "\n",
    "\n",
    "    def freeze_module(self, module):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_module(self, module):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def train(self, epochs_list=[3,3,4], early_stopping=True, frac=1.0, val_frac=1.0, alt_cycle = 2,  log=False):\n",
    "        for phase, epochs in enumerate(epochs_list):\n",
    "            for epoch in range(epochs):\n",
    "                phase=3\n",
    "                if phase == 0:\n",
    "                    # 🧠 Train Transformer — freeze CNN/LSTM layers\n",
    "                    self.unfreeze_module(self.model.transformer)\n",
    "                    for name, module in self.model.named_children():\n",
    "                        if name != \"transformer\":\n",
    "                            self.freeze_module(module)\n",
    "                        else:\n",
    "                            self.unfreeze_module(module)\n",
    "                    active_optims = [self.transformer_optimizer]\n",
    "                    active_scheds = [self.scheduler_t]\n",
    "                    phase_name = \"Transformer\"\n",
    "                elif phase == 1:\n",
    "                    # 🎯 Train CNN/LSTM/FC — freeze Transformer\n",
    "                    self.freeze_module(self.model.transformer)\n",
    "                    for name, module in self.model.named_children():\n",
    "                        if name == \"transformer\":\n",
    "                            self.freeze_module(module)\n",
    "                        else:\n",
    "                            self.unfreeze_module(module)\n",
    "                    active_optims = [self.main_optimizer]\n",
    "                    active_scheds = [self.scheduler_c]\n",
    "                    phase_name = \"CNN\"\n",
    "                else:\n",
    "                    self.freeze_module(self.model.transformer)\n",
    "                    for name, module in self.model.named_children():\n",
    "                        self.unfreeze_module(module)\n",
    "                    active_optims = [self.transformer_optimizer, self.main_optimizer]\n",
    "                    active_scheds = [self.scheduler_t, self.scheduler_c]\n",
    "                    phase_name = \"CNN + transformer\"\n",
    "\n",
    "\n",
    "\n",
    "                self.model.train()\n",
    "                train_loss, correct_train, total_train = 0, 0, 0\n",
    "                max_batches = int(len(self.train_loader) * frac)\n",
    "                \n",
    "                for batch_idx, (batch_x, batch_y) in enumerate(self.train_loader):\n",
    "                    if batch_idx >= max_batches:\n",
    "                        break\n",
    "                    \n",
    "                    batch_x, batch_y = batch_x.to(self.device, non_blocking=True), batch_y.to(self.device, non_blocking=True).float().unsqueeze(1)\n",
    "                    \n",
    "                    for opt in active_optims:\n",
    "                        opt.zero_grad()\n",
    "\n",
    "                    outputs = self.model(batch_x)\n",
    "                    loss = self.criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "\n",
    "                    for opt in active_optims:\n",
    "                        opt.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # === Metrics ===\n",
    "                    batch_loss = loss.item()\n",
    "                    preds = (outputs >= 0.5).float()\n",
    "                    batch_acc = (preds == batch_y).float().mean().item()\n",
    "\n",
    "                    train_loss += batch_loss * batch_x.size(0)\n",
    "                    correct_train += (preds == batch_y).sum().item()\n",
    "                    total_train += batch_x.size(0)\n",
    "\n",
    "                    if log and (batch_idx + 1) % 20 == 0:\n",
    "                        print(f\"\\rEpoch {epoch+1}/{epochs}: Training {phase_name} | \"\n",
    "                            f\"Batch {batch_idx+1}/{max_batches} | \"\n",
    "                            f\"Loss: {batch_loss:.4f}, Acc: {batch_acc:.4f}\", end='')\n",
    "\n",
    "                avg_train_loss = train_loss / total_train\n",
    "                train_acc = correct_train / total_train\n",
    "                self.train_losses.append(avg_train_loss)\n",
    "                self.train_accs.append(train_acc)\n",
    "\n",
    "                # === Validation ===\n",
    "                if self.val_loader is not None:\n",
    "                    avg_val_loss, val_acc = self.evaluate(val_frac)\n",
    "                    self.val_losses.append(avg_val_loss)\n",
    "                    self.val_accs.append(val_acc)\n",
    "\n",
    "                    if log:\n",
    "                        print(f\"\\rEpoch {epoch+1}/{epochs} Training {phase_name}| \"\n",
    "                            f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "                            f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "                elif log:\n",
    "                    print(f\"\\rEpoch {epoch+1}/{epochs} Training {phase_name}| \"\n",
    "                        f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "                for sched in active_scheds:\n",
    "                    sched.step(avg_val_loss)\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self, frac=1.0):\n",
    "        self.model.eval()\n",
    "        val_loss, correct_val, total_val = 0, 0, 0\n",
    "        max_batches = max(int(len(self.val_loader) * frac), 1)\n",
    "        print(f'\\r total validation batch size {max_batches}'.ljust(100), end='')\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (batch_x, batch_y) in enumerate(self.val_loader):\n",
    "                if batch_idx >= max_batches:\n",
    "                    break\n",
    "                batch_x, batch_y = batch_x.to(self.device, non_blocking=True), batch_y.to(self.device, non_blocking=True).float().unsqueeze(1)\n",
    "                outputs = self.model(batch_x)\n",
    "                loss = self.criterion(outputs, batch_y)\n",
    "                avg_batch_loss = loss.item()\n",
    "                val_loss += avg_batch_loss * batch_x.size(0)\n",
    "                preds = (outputs >= 0.5).float()\n",
    "                correct_val += (preds == batch_y).sum().item()\n",
    "                total_val += batch_x.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = correct_val / total_val\n",
    "        return avg_val_loss, val_acc\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14896532",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 Training model on DATASET_0 dataset\n",
      "======================================================================\n",
      "__________🧩 Using 100% of training data___________\n",
      "Epoch 1/3 Training CNN + transformer| Train Loss: 0.1497, Train Acc: 0.9480 | Val Loss: 0.0757, Val Acc: 0.9779\n",
      "Epoch 2/3 Training CNN + transformer| Train Loss: 0.0657, Train Acc: 0.9795 | Val Loss: 0.0545, Val Acc: 0.9816\n",
      "Epoch 3/3 Training CNN + transformer| Train Loss: 0.0547, Train Acc: 0.9825 | Val Loss: 0.0547, Val Acc: 0.9817\n",
      "Epoch 1/3 Training CNN + transformer| Train Loss: 0.0486, Train Acc: 0.9843 | Val Loss: 0.0551, Val Acc: 0.9815\n",
      "Epoch 2/3 Training CNN + transformer| Train Loss: 0.0443, Train Acc: 0.9855 | Val Loss: 0.0512, Val Acc: 0.9824\n",
      "Epoch 3/3 Training CNN + transformer| Train Loss: 0.0418, Train Acc: 0.9863 | Val Loss: 0.0481, Val Acc: 0.9853\n",
      "Epoch 1/4 Training CNN + transformer| Train Loss: 0.0398, Train Acc: 0.9870 | Val Loss: 0.0468, Val Acc: 0.9850\n",
      "Epoch 2/4 Training CNN + transformer| Train Loss: 0.0378, Train Acc: 0.9873 | Val Loss: 0.0474, Val Acc: 0.9858\n",
      "Epoch 3/4 Training CNN + transformer| Train Loss: 0.0366, Train Acc: 0.9877 | Val Loss: 0.0499, Val Acc: 0.9843\n",
      "Epoch 4/4 Training CNN + transformer| Train Loss: 0.0357, Train Acc: 0.9881 | Val Loss: 0.0509, Val Acc: 0.9851\n",
      "\n",
      "✅ All datasets trained successfully!\n",
      "\n",
      "======================================================================\n",
      "📈 Final Validation Accuracy Summary\n",
      "======================================================================\n",
      "dataset_0            | Val Acc: 0.9851 | Val Loss: 0.0509\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from lion_pytorch import Lion\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# 🔧 Training Config\n",
    "# ============================================================\n",
    "num_epochs = [3,3,4]\n",
    "lr = 0.001\n",
    "\n",
    "# Store all dataset metrics\n",
    "all_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# 🔁 Training Loop for Each Dataset\n",
    "# ============================================================\n",
    "for dataset_name, loaders in {'dataset_0':dataloader_dict['dataset_0']}.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"🚀 Training model on {dataset_name.upper()} dataset\")\n",
    "    print(\"=\"*70)\n",
    "    for frac in  [1.0]:\n",
    "        print(f\"🧩 Using {frac*100:.0f}% of training data\".center(50, '_'))\n",
    "        train_loader = loaders[\"train_loader\"]\n",
    "        val_loader = loaders[\"val_loader\"]\n",
    "\n",
    "        # Initialize model, loss, optimizer\n",
    "        model = URLBinaryCNN(vocab_size=len(vocab)).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lr/10)\n",
    "        trainer = Train(model, criterion, train_loader=train_loader, val_loader=val_loader)\n",
    "        # Lists to track performance\n",
    "        trainer.train(num_epochs,lr,frac=frac,val_frac=frac, log=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Store all results for this dataset\n",
    "    all_results[dataset_name] = {\n",
    "        \"train_losses\": trainer.train_losses,\n",
    "        \"val_losses\": trainer.val_losses,\n",
    "        \"train_accs\": trainer.train_accs,\n",
    "        \"val_accs\": trainer.val_accs,\n",
    "        \"final_val_acc\": trainer.val_accs[-1],\n",
    "        \"final_val_loss\": trainer.val_losses[-1]\n",
    "    }\n",
    "\n",
    "print(\"\\n✅ All datasets trained successfully!\")\n",
    "\n",
    "# ============================================================\n",
    "# 📊 Summary of All Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📈 Final Validation Accuracy Summary\")\n",
    "print(\"=\"*70)\n",
    "for name, res in all_results.items():\n",
    "    print(f\"{name:<20} | Val Acc: {res['final_val_acc']:.4f} | Val Loss: {res['final_val_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4785fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"url_cnn_lstm.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64236ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbost model + cnn based dl model\n",
    "def extract_features(self, x):\n",
    "        \"\"\"Return deep features before final FC layers.\"\"\"\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x3 = F.relu(self.conv1_3x3(x))\n",
    "        x5 = F.relu(self.conv1_5x5(x))\n",
    "        x7 = F.relu(self.conv1_7(x))\n",
    "        x = torch.cat([x3, x5, x7], dim=1)\n",
    "        x = F.relu(self.conv1_1x1(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]          # shape: [batch, 32]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f2ad9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Extracting Train Features: 100%|██████████| 3264/3264 [00:35<00:00, 92.98batch/s] \n",
      "🔍 Extracting Val Features: 100%|██████████| 408/408 [00:06<00:00, 61.01batch/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "features, labels = [], []\n",
    "\n",
    "# 🔹 Extract CNN features for training set\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=\"🔍 Extracting Train Features\", unit=\"batch\"):\n",
    "        x_batch = x_batch.to(device, non_blocking=True)\n",
    "        feats = model.extract_features(x_batch)\n",
    "        features.append(feats.cpu().numpy())\n",
    "        labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "X_train = np.concatenate(features, axis=0)\n",
    "y_train = np.concatenate(labels, axis=0)\n",
    "\n",
    "# Free memory before val extraction\n",
    "del features, labels, x_batch, y_batch, feats\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 🔹 Extract CNN features for validation set\n",
    "features, labels = [], []\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(val_loader, desc=\"🔍 Extracting Val Features\", unit=\"batch\"):\n",
    "        x_batch = x_batch.to(device, non_blocking=True)\n",
    "        feats = model.extract_features(x_batch)\n",
    "        features.append(feats.cpu().numpy())\n",
    "        labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "X_val = np.concatenate(features, axis=0)\n",
    "y_val = np.concatenate(labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de5dd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.42642\n",
      "[1]\tvalidation_0-logloss:0.39052\n",
      "[2]\tvalidation_0-logloss:0.36064\n",
      "[3]\tvalidation_0-logloss:0.33507\n",
      "[4]\tvalidation_0-logloss:0.31273\n",
      "[5]\tvalidation_0-logloss:0.29294\n",
      "[6]\tvalidation_0-logloss:0.27524\n",
      "[7]\tvalidation_0-logloss:0.25927\n",
      "[8]\tvalidation_0-logloss:0.24476\n",
      "[9]\tvalidation_0-logloss:0.23152\n",
      "[10]\tvalidation_0-logloss:0.21936\n",
      "[11]\tvalidation_0-logloss:0.20820\n",
      "[12]\tvalidation_0-logloss:0.19788\n",
      "[13]\tvalidation_0-logloss:0.18834\n",
      "[14]\tvalidation_0-logloss:0.17947\n",
      "[15]\tvalidation_0-logloss:0.17123\n",
      "[16]\tvalidation_0-logloss:0.16358\n",
      "[17]\tvalidation_0-logloss:0.15645\n",
      "[18]\tvalidation_0-logloss:0.14980\n",
      "[19]\tvalidation_0-logloss:0.14356\n",
      "[20]\tvalidation_0-logloss:0.13774\n",
      "[21]\tvalidation_0-logloss:0.13229\n",
      "[22]\tvalidation_0-logloss:0.12717\n",
      "[23]\tvalidation_0-logloss:0.12237\n",
      "[24]\tvalidation_0-logloss:0.11787\n",
      "[25]\tvalidation_0-logloss:0.11363\n",
      "[26]\tvalidation_0-logloss:0.10966\n",
      "[27]\tvalidation_0-logloss:0.10592\n",
      "[28]\tvalidation_0-logloss:0.10240\n",
      "[29]\tvalidation_0-logloss:0.09909\n",
      "[30]\tvalidation_0-logloss:0.09599\n",
      "[31]\tvalidation_0-logloss:0.09305\n",
      "[32]\tvalidation_0-logloss:0.09029\n",
      "[33]\tvalidation_0-logloss:0.08769\n",
      "[34]\tvalidation_0-logloss:0.08526\n",
      "[35]\tvalidation_0-logloss:0.08296\n",
      "[36]\tvalidation_0-logloss:0.08080\n",
      "[37]\tvalidation_0-logloss:0.07876\n",
      "[38]\tvalidation_0-logloss:0.07683\n",
      "[39]\tvalidation_0-logloss:0.07501\n",
      "[40]\tvalidation_0-logloss:0.07328\n",
      "[41]\tvalidation_0-logloss:0.07166\n",
      "[42]\tvalidation_0-logloss:0.07013\n",
      "[43]\tvalidation_0-logloss:0.06870\n",
      "[44]\tvalidation_0-logloss:0.06735\n",
      "[45]\tvalidation_0-logloss:0.06607\n",
      "[46]\tvalidation_0-logloss:0.06487\n",
      "[47]\tvalidation_0-logloss:0.06373\n",
      "[48]\tvalidation_0-logloss:0.06266\n",
      "[49]\tvalidation_0-logloss:0.06165\n",
      "[50]\tvalidation_0-logloss:0.06071\n",
      "[51]\tvalidation_0-logloss:0.05983\n",
      "[52]\tvalidation_0-logloss:0.05899\n",
      "[53]\tvalidation_0-logloss:0.05820\n",
      "[54]\tvalidation_0-logloss:0.05745\n",
      "[55]\tvalidation_0-logloss:0.05675\n",
      "[56]\tvalidation_0-logloss:0.05610\n",
      "[57]\tvalidation_0-logloss:0.05548\n",
      "[58]\tvalidation_0-logloss:0.05490\n",
      "[59]\tvalidation_0-logloss:0.05435\n",
      "[60]\tvalidation_0-logloss:0.05384\n",
      "[61]\tvalidation_0-logloss:0.05335\n",
      "[62]\tvalidation_0-logloss:0.05289\n",
      "[63]\tvalidation_0-logloss:0.05247\n",
      "[64]\tvalidation_0-logloss:0.05207\n",
      "[65]\tvalidation_0-logloss:0.05170\n",
      "[66]\tvalidation_0-logloss:0.05134\n",
      "[67]\tvalidation_0-logloss:0.05101\n",
      "[68]\tvalidation_0-logloss:0.05070\n",
      "[69]\tvalidation_0-logloss:0.05041\n",
      "[70]\tvalidation_0-logloss:0.05014\n",
      "[71]\tvalidation_0-logloss:0.04988\n",
      "[72]\tvalidation_0-logloss:0.04965\n",
      "[73]\tvalidation_0-logloss:0.04942\n",
      "[74]\tvalidation_0-logloss:0.04922\n",
      "[75]\tvalidation_0-logloss:0.04904\n",
      "[76]\tvalidation_0-logloss:0.04886\n",
      "[77]\tvalidation_0-logloss:0.04869\n",
      "[78]\tvalidation_0-logloss:0.04855\n",
      "[79]\tvalidation_0-logloss:0.04841\n",
      "[80]\tvalidation_0-logloss:0.04828\n",
      "[81]\tvalidation_0-logloss:0.04815\n",
      "[82]\tvalidation_0-logloss:0.04804\n",
      "[83]\tvalidation_0-logloss:0.04794\n",
      "[84]\tvalidation_0-logloss:0.04784\n",
      "[85]\tvalidation_0-logloss:0.04775\n",
      "[86]\tvalidation_0-logloss:0.04767\n",
      "[87]\tvalidation_0-logloss:0.04759\n",
      "[88]\tvalidation_0-logloss:0.04752\n",
      "[89]\tvalidation_0-logloss:0.04745\n",
      "[90]\tvalidation_0-logloss:0.04740\n",
      "[91]\tvalidation_0-logloss:0.04734\n",
      "[92]\tvalidation_0-logloss:0.04729\n",
      "[93]\tvalidation_0-logloss:0.04725\n",
      "[94]\tvalidation_0-logloss:0.04721\n",
      "[95]\tvalidation_0-logloss:0.04719\n",
      "[96]\tvalidation_0-logloss:0.04717\n",
      "[97]\tvalidation_0-logloss:0.04716\n",
      "[98]\tvalidation_0-logloss:0.04714\n",
      "[99]\tvalidation_0-logloss:0.04713\n",
      "[100]\tvalidation_0-logloss:0.04712\n",
      "[101]\tvalidation_0-logloss:0.04711\n",
      "[102]\tvalidation_0-logloss:0.04710\n",
      "[103]\tvalidation_0-logloss:0.04711\n",
      "[104]\tvalidation_0-logloss:0.04710\n",
      "[105]\tvalidation_0-logloss:0.04710\n",
      "[106]\tvalidation_0-logloss:0.04710\n",
      "[107]\tvalidation_0-logloss:0.04711\n",
      "[108]\tvalidation_0-logloss:0.04710\n",
      "[109]\tvalidation_0-logloss:0.04711\n",
      "[110]\tvalidation_0-logloss:0.04712\n",
      "[111]\tvalidation_0-logloss:0.04715\n",
      "[112]\tvalidation_0-logloss:0.04716\n",
      "[113]\tvalidation_0-logloss:0.04717\n",
      "[114]\tvalidation_0-logloss:0.04719\n",
      "[115]\tvalidation_0-logloss:0.04720\n",
      "[116]\tvalidation_0-logloss:0.04721\n",
      "[117]\tvalidation_0-logloss:0.04722\n",
      "[118]\tvalidation_0-logloss:0.04724\n",
      "[119]\tvalidation_0-logloss:0.04725\n",
      "[120]\tvalidation_0-logloss:0.04727\n",
      "[121]\tvalidation_0-logloss:0.04729\n",
      "[122]\tvalidation_0-logloss:0.04731\n",
      "[123]\tvalidation_0-logloss:0.04731\n",
      "[124]\tvalidation_0-logloss:0.04733\n",
      "[125]\tvalidation_0-logloss:0.04735\n",
      "[126]\tvalidation_0-logloss:0.04737\n",
      "[127]\tvalidation_0-logloss:0.04739\n",
      "[128]\tvalidation_0-logloss:0.04741\n",
      "[129]\tvalidation_0-logloss:0.04743\n",
      "[130]\tvalidation_0-logloss:0.04744\n",
      "[131]\tvalidation_0-logloss:0.04746\n",
      "[132]\tvalidation_0-logloss:0.04748\n",
      "[133]\tvalidation_0-logloss:0.04751\n",
      "[134]\tvalidation_0-logloss:0.04753\n",
      "[135]\tvalidation_0-logloss:0.04755\n",
      "[136]\tvalidation_0-logloss:0.04758\n",
      "[137]\tvalidation_0-logloss:0.04759\n",
      "[138]\tvalidation_0-logloss:0.04762\n",
      "[139]\tvalidation_0-logloss:0.04764\n",
      "[140]\tvalidation_0-logloss:0.04766\n",
      "[141]\tvalidation_0-logloss:0.04769\n",
      "[142]\tvalidation_0-logloss:0.04770\n",
      "[143]\tvalidation_0-logloss:0.04774\n",
      "[144]\tvalidation_0-logloss:0.04776\n",
      "[145]\tvalidation_0-logloss:0.04778\n",
      "[146]\tvalidation_0-logloss:0.04780\n",
      "[147]\tvalidation_0-logloss:0.04782\n",
      "[148]\tvalidation_0-logloss:0.04784\n",
      "[149]\tvalidation_0-logloss:0.04786\n",
      "[150]\tvalidation_0-logloss:0.04786\n",
      "[151]\tvalidation_0-logloss:0.04787\n",
      "[152]\tvalidation_0-logloss:0.04789\n",
      "[153]\tvalidation_0-logloss:0.04791\n",
      "[154]\tvalidation_0-logloss:0.04793\n",
      "[155]\tvalidation_0-logloss:0.04795\n",
      "[156]\tvalidation_0-logloss:0.04797\n",
      "[157]\tvalidation_0-logloss:0.04798\n",
      "[158]\tvalidation_0-logloss:0.04801\n",
      "[159]\tvalidation_0-logloss:0.04802\n",
      "[160]\tvalidation_0-logloss:0.04803\n",
      "[161]\tvalidation_0-logloss:0.04805\n",
      "[162]\tvalidation_0-logloss:0.04806\n",
      "[163]\tvalidation_0-logloss:0.04809\n",
      "[164]\tvalidation_0-logloss:0.04809\n",
      "[165]\tvalidation_0-logloss:0.04810\n",
      "[166]\tvalidation_0-logloss:0.04812\n",
      "[167]\tvalidation_0-logloss:0.04814\n",
      "[168]\tvalidation_0-logloss:0.04814\n",
      "[169]\tvalidation_0-logloss:0.04818\n",
      "[170]\tvalidation_0-logloss:0.04819\n",
      "[171]\tvalidation_0-logloss:0.04821\n",
      "[172]\tvalidation_0-logloss:0.04822\n",
      "[173]\tvalidation_0-logloss:0.04824\n",
      "[174]\tvalidation_0-logloss:0.04823\n",
      "[175]\tvalidation_0-logloss:0.04824\n",
      "[176]\tvalidation_0-logloss:0.04825\n",
      "[177]\tvalidation_0-logloss:0.04826\n",
      "[178]\tvalidation_0-logloss:0.04829\n",
      "[179]\tvalidation_0-logloss:0.04830\n",
      "[180]\tvalidation_0-logloss:0.04833\n",
      "[181]\tvalidation_0-logloss:0.04834\n",
      "[182]\tvalidation_0-logloss:0.04835\n",
      "[183]\tvalidation_0-logloss:0.04836\n",
      "[184]\tvalidation_0-logloss:0.04838\n",
      "[185]\tvalidation_0-logloss:0.04839\n",
      "[186]\tvalidation_0-logloss:0.04839\n",
      "[187]\tvalidation_0-logloss:0.04841\n",
      "[188]\tvalidation_0-logloss:0.04842\n",
      "[189]\tvalidation_0-logloss:0.04842\n",
      "[190]\tvalidation_0-logloss:0.04844\n",
      "[191]\tvalidation_0-logloss:0.04845\n",
      "[192]\tvalidation_0-logloss:0.04845\n",
      "[193]\tvalidation_0-logloss:0.04847\n",
      "[194]\tvalidation_0-logloss:0.04848\n",
      "[195]\tvalidation_0-logloss:0.04850\n",
      "[196]\tvalidation_0-logloss:0.04851\n",
      "[197]\tvalidation_0-logloss:0.04853\n",
      "[198]\tvalidation_0-logloss:0.04854\n",
      "[199]\tvalidation_0-logloss:0.04853\n",
      "[200]\tvalidation_0-logloss:0.04854\n",
      "[201]\tvalidation_0-logloss:0.04855\n",
      "[202]\tvalidation_0-logloss:0.04858\n",
      "[203]\tvalidation_0-logloss:0.04858\n",
      "[204]\tvalidation_0-logloss:0.04857\n",
      "[205]\tvalidation_0-logloss:0.04856\n",
      "[206]\tvalidation_0-logloss:0.04860\n",
      "[207]\tvalidation_0-logloss:0.04859\n",
      "[208]\tvalidation_0-logloss:0.04859\n",
      "[209]\tvalidation_0-logloss:0.04859\n",
      "[210]\tvalidation_0-logloss:0.04859\n",
      "[211]\tvalidation_0-logloss:0.04859\n",
      "[212]\tvalidation_0-logloss:0.04860\n",
      "[213]\tvalidation_0-logloss:0.04861\n",
      "[214]\tvalidation_0-logloss:0.04862\n",
      "[215]\tvalidation_0-logloss:0.04864\n",
      "[216]\tvalidation_0-logloss:0.04865\n",
      "[217]\tvalidation_0-logloss:0.04865\n",
      "[218]\tvalidation_0-logloss:0.04866\n",
      "[219]\tvalidation_0-logloss:0.04866\n",
      "[220]\tvalidation_0-logloss:0.04866\n",
      "[221]\tvalidation_0-logloss:0.04866\n",
      "[222]\tvalidation_0-logloss:0.04868\n",
      "[223]\tvalidation_0-logloss:0.04869\n",
      "[224]\tvalidation_0-logloss:0.04870\n",
      "[225]\tvalidation_0-logloss:0.04871\n",
      "[226]\tvalidation_0-logloss:0.04871\n",
      "[227]\tvalidation_0-logloss:0.04871\n",
      "[228]\tvalidation_0-logloss:0.04874\n",
      "[229]\tvalidation_0-logloss:0.04875\n",
      "[230]\tvalidation_0-logloss:0.04876\n",
      "[231]\tvalidation_0-logloss:0.04875\n",
      "[232]\tvalidation_0-logloss:0.04874\n",
      "[233]\tvalidation_0-logloss:0.04873\n",
      "[234]\tvalidation_0-logloss:0.04874\n",
      "[235]\tvalidation_0-logloss:0.04874\n",
      "[236]\tvalidation_0-logloss:0.04875\n",
      "[237]\tvalidation_0-logloss:0.04875\n",
      "[238]\tvalidation_0-logloss:0.04873\n",
      "[239]\tvalidation_0-logloss:0.04873\n",
      "[240]\tvalidation_0-logloss:0.04875\n",
      "[241]\tvalidation_0-logloss:0.04875\n",
      "[242]\tvalidation_0-logloss:0.04877\n",
      "[243]\tvalidation_0-logloss:0.04877\n",
      "[244]\tvalidation_0-logloss:0.04880\n",
      "[245]\tvalidation_0-logloss:0.04880\n",
      "[246]\tvalidation_0-logloss:0.04881\n",
      "[247]\tvalidation_0-logloss:0.04881\n",
      "[248]\tvalidation_0-logloss:0.04881\n",
      "[249]\tvalidation_0-logloss:0.04879\n",
      "[250]\tvalidation_0-logloss:0.04879\n",
      "[251]\tvalidation_0-logloss:0.04881\n",
      "[252]\tvalidation_0-logloss:0.04880\n",
      "[253]\tvalidation_0-logloss:0.04880\n",
      "[254]\tvalidation_0-logloss:0.04879\n",
      "[255]\tvalidation_0-logloss:0.04881\n",
      "[256]\tvalidation_0-logloss:0.04882\n",
      "[257]\tvalidation_0-logloss:0.04883\n",
      "[258]\tvalidation_0-logloss:0.04885\n",
      "[259]\tvalidation_0-logloss:0.04885\n",
      "[260]\tvalidation_0-logloss:0.04886\n",
      "[261]\tvalidation_0-logloss:0.04887\n",
      "[262]\tvalidation_0-logloss:0.04887\n",
      "[263]\tvalidation_0-logloss:0.04886\n",
      "[264]\tvalidation_0-logloss:0.04887\n",
      "[265]\tvalidation_0-logloss:0.04886\n",
      "[266]\tvalidation_0-logloss:0.04886\n",
      "[267]\tvalidation_0-logloss:0.04887\n",
      "[268]\tvalidation_0-logloss:0.04887\n",
      "[269]\tvalidation_0-logloss:0.04887\n",
      "[270]\tvalidation_0-logloss:0.04888\n",
      "[271]\tvalidation_0-logloss:0.04890\n",
      "[272]\tvalidation_0-logloss:0.04889\n",
      "[273]\tvalidation_0-logloss:0.04890\n",
      "[274]\tvalidation_0-logloss:0.04890\n",
      "[275]\tvalidation_0-logloss:0.04891\n",
      "[276]\tvalidation_0-logloss:0.04892\n",
      "[277]\tvalidation_0-logloss:0.04892\n",
      "[278]\tvalidation_0-logloss:0.04893\n",
      "[279]\tvalidation_0-logloss:0.04893\n",
      "[280]\tvalidation_0-logloss:0.04894\n",
      "[281]\tvalidation_0-logloss:0.04895\n",
      "[282]\tvalidation_0-logloss:0.04895\n",
      "[283]\tvalidation_0-logloss:0.04895\n",
      "[284]\tvalidation_0-logloss:0.04896\n",
      "[285]\tvalidation_0-logloss:0.04895\n",
      "[286]\tvalidation_0-logloss:0.04896\n",
      "[287]\tvalidation_0-logloss:0.04896\n",
      "[288]\tvalidation_0-logloss:0.04898\n",
      "[289]\tvalidation_0-logloss:0.04897\n",
      "[290]\tvalidation_0-logloss:0.04895\n",
      "[291]\tvalidation_0-logloss:0.04895\n",
      "[292]\tvalidation_0-logloss:0.04896\n",
      "[293]\tvalidation_0-logloss:0.04897\n",
      "[294]\tvalidation_0-logloss:0.04896\n",
      "[295]\tvalidation_0-logloss:0.04897\n",
      "[296]\tvalidation_0-logloss:0.04897\n",
      "[297]\tvalidation_0-logloss:0.04896\n",
      "[298]\tvalidation_0-logloss:0.04898\n",
      "[299]\tvalidation_0-logloss:0.04898\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792ec80",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type, a tuple of types, or a union",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m y_pred = (y_pred_prob > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#print(\"Accuracy:\", accuracy_score(y_val, y_pred))\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrecision:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRecall:\u001b[39m\u001b[33m\"\u001b[39m, recall_score(y_val, y_pred))\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mF1:\u001b[39m\u001b[33m\"\u001b[39m, f1_score(y_val, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2247\u001b[39m, in \u001b[36mprecision_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   2079\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   2080\u001b[39m     {\n\u001b[32m   2081\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   2106\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2107\u001b[39m ):\n\u001b[32m   2108\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[32m   2109\u001b[39m \n\u001b[32m   2110\u001b[39m \u001b[33;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2245\u001b[39m \u001b[33;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[32m   2246\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m     p, _, _, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2252\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2254\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1830\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1661\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1662\u001b[39m \n\u001b[32m   1663\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1827\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1828\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1829\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1830\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1832\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1833\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1596\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33maverage has to be one of \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[32m   1595\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1597\u001b[39m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[32m   1598\u001b[39m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[32m   1599\u001b[39m present_labels = _tolist(unique_labels(y_true, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:472\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_consistent_length\u001b[39m(*arrays):\n\u001b[32m    455\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m    457\u001b[39m \u001b[33;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     lengths = [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    473\u001b[39m     uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:388\u001b[39m, in \u001b[36m_num_samples\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(x.fit):\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# Don't get num_samples from an ensembles length!\u001b[39;00m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_use_interchange_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x.__dataframe__().num_rows()\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__len__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:325\u001b[39m, in \u001b[36m_use_interchange_protocol\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_use_interchange_protocol\u001b[39m(X):\n\u001b[32m    319\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Use interchange protocol for non-pandas dataframes that follow the protocol.\u001b[39;00m\n\u001b[32m    320\u001b[39m \n\u001b[32m    321\u001b[39m \u001b[33;03m    Note: at this point we chose not to use the interchange API on pandas dataframe\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03m    to ensure strict behavioral backward compatibility with older versions of\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[33;03m    scikit-learn.\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_is_pandas_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33m__dataframe__\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2349\u001b[39m, in \u001b[36m_is_pandas_df\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m   2347\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m   2348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: isinstance() arg 2 must be a type, a tuple of types, or a union"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "y_pred_prob = xgb_model.predict(X_val)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb138a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "from sklearn\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,   # number of trees\n",
    "    max_depth=30,     # tree depth (None = auto)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89562163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding xgboost with cnn with handcrafted features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42e3b377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Path to dataset files: C:\\Users\\rrpra\\.cache\\kagglehub\\datasets\\cheedcheed\\top1m\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "f= open('tld_encoding_serise.bin','rb')\n",
    "tld_stats = pickle.load(file=f)\n",
    "f.close()\n",
    "print(type(tld_stats))\n",
    "\n",
    "import kagglehub\n",
    "import os\n",
    "# Download latest version\n",
    "folder_path = kagglehub.dataset_download(\"cheedcheed/top1m\")\n",
    "\n",
    "print(\"Path to dataset files:\", folder_path)\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.csv')]\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No CSV files found in the folder!\")\n",
    "\n",
    "# read the first CSV file\n",
    "file_path = os.path.join(folder_path, csv_files[0])\n",
    "alexa_top_1m_domain = pd.read_csv(file_path,header=None,names=['rank', 'domain'])\n",
    "alexa_domains_set = set(alexa_top_1m_domain['domain'].apply(str.lower))\n",
    "\n",
    "# --- Helper function: Shannon entropy ---\n",
    "def safe_parse(url: str):\n",
    "    \"\"\"Safely parse URLs, adding http:// if missing and handling bad IPv6 parts.\"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return urlparse(\"http://\")  \n",
    "\n",
    "    # Ensure scheme exists\n",
    "    if not re.match(r'^[a-zA-Z]+://', url):\n",
    "        url = 'http://' + url\n",
    "\n",
    "    # Clean invalid brackets that trigger IPv6 errors\n",
    "    url = re.sub(r'\\[.*?\\]', '', url)\n",
    "\n",
    "    try:\n",
    "        return urlparse(url)\n",
    "    except ValueError:\n",
    "        # fallback: strip more aggressively if still malformed\n",
    "        url = re.sub(r'[^a-zA-Z0-9:/._\\-?&=]', '', url)\n",
    "        return urlparse(url)\n",
    "def calculate_entropy(string):\n",
    "    \"\"\"Measures randomness of characters in the URL.\"\"\"\n",
    "    if not string:\n",
    "        return 0\n",
    "    freq = {char: string.count(char) for char in set(string)}\n",
    "    entropy = -sum((count / len(string)) * math.log2(count / len(string)) for count in freq.values())\n",
    "    return entropy\n",
    "\n",
    "# --- Main feature extraction function ---\n",
    "def extract_handcrafted_features(url):\n",
    "    features = {}\n",
    "    if not re.match(r'^[hH]+[tT]+[tT]+[pP]+[sS]+://', url):\n",
    "        url = 'http://' + url\n",
    "    parsed = safe_parse(url)\n",
    "    \n",
    "    # 1️⃣ Basic structural features\n",
    "    features['url_length'] = len(url)\n",
    "    features['hostname_length'] = len(parsed.netloc)\n",
    "    features['path_length'] = len(parsed.path)\n",
    "    features['num_dots'] = url.count('.')\n",
    "    features['num_hyphens'] = url.count('-')\n",
    "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['num_letters'] = sum(c.isalpha() for c in url)\n",
    "    features['num_params'] = url.count('?')\n",
    "    features['num_equals'] = url.count('=')\n",
    "    features['num_slashes'] = url.count('/')\n",
    "    features['num_at'] = url.count('@')\n",
    "\n",
    "    # 2️⃣ Lexical / composition cues\n",
    "    features['has_https'] = 1 if url.lower().startswith('https') else 0\n",
    "    features['has_ip'] = 1 if re.search(r'(\\d{1,3}\\.){3}\\d{1,3}', parsed.netloc) else 0\n",
    "    features['has_subdomain'] = 1 if parsed.netloc.count('.') > 1 else 0\n",
    "    features['has_suspicious_words'] = 1 if re.search(r'(login|secure|verify|update|free|bank|click)', url.lower()) else 0\n",
    "\n",
    "    # 3️⃣ Domain / TLD features\n",
    "    extracted = tldextract.extract(url)\n",
    "    main_domain = f\"{extracted.domain}.{extracted.suffix}\"\n",
    "    if ':' in main_domain:  # remove port\n",
    "        main_domain = main_domain.split(':')[0]\n",
    "    features['domain_length'] = len(main_domain)\n",
    "    features['in_alexa_top1m'] = 1 if main_domain in alexa_domains_set else 0\n",
    "    '''\n",
    "    if features['in_alexa_top1m'] == 0 and main_domain:  # only check if domain not in top1M\n",
    "        # find closest match in Alexa domains\n",
    "        best_match, score, _ = process.extractOne(main_domain, alexa_domains_set, scorer=fuzz.ratio)\n",
    "        features['closest_alexa_domain'] = best_match\n",
    "        features['closest_alexa_score'] = score  # 0-100\n",
    "    else:\n",
    "        features['closest_alexa_score'] = 1000  # high score to show that it is original url\n",
    "    '''\n",
    "    ext = tldextract.extract(url)\n",
    "    tld = ext.suffix    # \"com\", \"co.uk\", \"org\"\n",
    "    features['tld'] = tld if tld else 'unknown'\n",
    "    features['tld_phish_ratio'] = tld_stats['phish_ratio'][features['tld']]  if tld_stats['phish_ratio'][features['tld']]  else 0.5\n",
    "    features['tld_total_frequency'] = tld_stats['total'][features['tld']] if tld_stats['total'][features['tld']] else 1\n",
    "\n",
    "    # 4️⃣ Ratios\n",
    "    features['digit_ratio'] = features['num_digits'] / (features['url_length'] + 1e-5)\n",
    "    features['special_char_ratio'] = (features['num_hyphens'] + features['num_dots'] + features['num_slashes']) / (features['url_length'] + 1e-5)\n",
    "\n",
    "    # 5️⃣ Entropy (measures randomness / obfuscation)\n",
    "    features['url_entropy'] = calculate_entropy(url)\n",
    "\n",
    "    # 6️⃣ Misplacement indicators\n",
    "    # '@' symbol used to hide real domain (like \"http://evil.com@legit.com\")\n",
    "    features['at_in_domain'] = 1 if '@' in parsed.netloc else 0\n",
    "    \n",
    "    # Double slashes '//' appearing after path (used to trick users)\n",
    "    features['double_slash_in_path'] = 1 if re.search(r'/.+//', parsed.path) else 0\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4248e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Creating DataLoaders for dataset_0...\n",
      "{'train':                                                       url  label  \\\n",
      "230159  nps.gov/badl/parknews/sylvatic-plague-detected...      0   \n",
      "377597  finance.yahoo.com/news/Medline-Selects-GT-Nexu...      0   \n",
      "157325                       en.wikipedia.org/wiki/Blumer      0   \n",
      "318564           manfridayfilms.co.uk/s-Steve_Robinson_CV      0   \n",
      "159250  dukebasketballreport.com/forums/showthread.php...      0   \n",
      "...                                                   ...    ...   \n",
      "132127                  shopping.yahoo.com/gamepad--shop/      0   \n",
      "304497                      mog.com/artists/mn6489/common      0   \n",
      "241619                           mobile.disney.go.com/wap      0   \n",
      "211667                                           gmam.ca/      0   \n",
      "302464  amazon.com/Forest-Pipes-Disney-Concert-Organ/d...      0   \n",
      "\n",
      "                                                   encode  \n",
      "230159  [tensor(80), tensor(82), tensor(85), tensor(16...  \n",
      "377597  [tensor(72), tensor(75), tensor(80), tensor(67...  \n",
      "157325  [tensor(71), tensor(80), tensor(16), tensor(89...  \n",
      "318564  [tensor(79), tensor(67), tensor(80), tensor(72...  \n",
      "159250  [tensor(70), tensor(87), tensor(77), tensor(71...  \n",
      "...                                                   ...  \n",
      "132127  [tensor(85), tensor(74), tensor(81), tensor(82...  \n",
      "304497  [tensor(79), tensor(81), tensor(73), tensor(16...  \n",
      "241619  [tensor(79), tensor(81), tensor(68), tensor(75...  \n",
      "211667  [tensor(73), tensor(79), tensor(67), tensor(79...  \n",
      "302464  [tensor(67), tensor(79), tensor(67), tensor(92...  \n",
      "\n",
      "[417732 rows x 3 columns], 'valid':                                                       url  label  \\\n",
      "507184                         www.araelium.com/querious/      1   \n",
      "403472                 en.wikipedia.org/wiki/Emmett_Vogan      0   \n",
      "91781                               acomicbookorange.com/      0   \n",
      "245232  ontheforecheck.com/2009/7/14/948828/nashville-...      0   \n",
      "182266  http://motthegioi.vn/tags/IHBob25nIHRo4buneSBi...      0   \n",
      "...                                                   ...    ...   \n",
      "19101               en.wikipedia.org/wiki/Ren%C3%A9_Audet      0   \n",
      "281334   facebook.com/people/Carla-Marie-Mader/1063862785      0   \n",
      "459811  www.paypal.com.v8ozcehdfyxm1cx2wn.bxbwrzsp2vz7...      0   \n",
      "234516  tripsage.com/p/1/7053741/christopher-s-bond-br...      0   \n",
      "130446                            usidentify.com/l/deleon      0   \n",
      "\n",
      "                                                   encode  \n",
      "507184  [tensor(89), tensor(89), tensor(89), tensor(16...  \n",
      "403472  [tensor(71), tensor(80), tensor(16), tensor(89...  \n",
      "91781   [tensor(67), tensor(69), tensor(81), tensor(79...  \n",
      "245232  [tensor(81), tensor(80), tensor(86), tensor(74...  \n",
      "182266  [tensor(74), tensor(86), tensor(86), tensor(82...  \n",
      "...                                                   ...  \n",
      "19101   [tensor(71), tensor(80), tensor(16), tensor(89...  \n",
      "281334  [tensor(72), tensor(67), tensor(69), tensor(71...  \n",
      "459811  [tensor(89), tensor(89), tensor(89), tensor(16...  \n",
      "234516  [tensor(86), tensor(84), tensor(75), tensor(82...  \n",
      "130446  [tensor(87), tensor(85), tensor(75), tensor(70...  \n",
      "\n",
      "[52217 rows x 3 columns], 'test':                                                       url  label  \\\n",
      "337922            moneymanagement.com.au/tag/Bruce-Pellow      0   \n",
      "144690   tributes.com/show/Gerald-Thomas-Jackson-89294088      0   \n",
      "429417                               moedashabo.rel7.com/      0   \n",
      "22188           cheappremiumtickets.com/sitemap_venue.cfm      0   \n",
      "467048  '9d345009-a-62cb3a1a-s-sites.googlegroups.com/...      0   \n",
      "...                                                   ...    ...   \n",
      "195862                      cherieroberts.deviantart.com/      0   \n",
      "482003                      www.aatcc.org/media/index.htm      1   \n",
      "257117  amazon.com/Silent-Films-1877-1996-Critical-Mov...      0   \n",
      "487063  www.utoronto.ca/webdocs/HTMLdocs/NewHTML/htmli...      1   \n",
      "145038                     riverbendinnorthbrunswick.com/      0   \n",
      "\n",
      "                                                   encode  \n",
      "337922  [tensor(79), tensor(81), tensor(80), tensor(71...  \n",
      "144690  [tensor(86), tensor(84), tensor(75), tensor(68...  \n",
      "429417  [tensor(79), tensor(81), tensor(71), tensor(70...  \n",
      "22188   [tensor(69), tensor(74), tensor(71), tensor(67...  \n",
      "467048  [tensor(9), tensor(27), tensor(70), tensor(21)...  \n",
      "...                                                   ...  \n",
      "195862  [tensor(69), tensor(74), tensor(71), tensor(84...  \n",
      "482003  [tensor(89), tensor(89), tensor(89), tensor(16...  \n",
      "257117  [tensor(67), tensor(79), tensor(67), tensor(92...  \n",
      "487063  [tensor(89), tensor(89), tensor(89), tensor(16...  \n",
      "145038  [tensor(84), tensor(75), tensor(88), tensor(71...  \n",
      "\n",
      "[52217 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "manual_feature_dict = {}\n",
    "\n",
    "for name, splits in encoded_data.items():\n",
    "    manual_feature_dict[name] = {}\n",
    "    print(f\"\\n📦 Creating DataLoaders for {name}...\")\n",
    "    print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb3e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Extracting handcrafted features for dataset_0...\n",
      "🔍 Extracting Train Features...\n",
      "<class 'int'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m manual_feature_dict[name][\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(manual_feature_dict[name][\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m manual_feature_dict[name][\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#manual_feature_dict[name][\"train\"] = manual_feature_dict[name][\"train\"].assign(**train_df[\"url\"].progress_apply(lambda url : extract_handcrafted_features(url)))\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#manual_feature_dict[name][\"train\"][\"label\"] = train_df[\"label\"]\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# --- Test ---\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🔍 Extracting Test Features...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "manual_feature_dict = {}\n",
    "\n",
    "for name, splits in encoded_data.items():\n",
    "    manual_feature_dict[name] = {}\n",
    "    print(f\"\\n📦 Extracting handcrafted features for {name}...\")\n",
    "\n",
    "    # --- Train ---\n",
    "    print(\"🔍 Extracting Train Features...\")\n",
    "    train_df = splits[\"train\"]\n",
    "    manual_feature_dict[name][\"train\"] = 0\n",
    "    print(type(manual_feature_dict[name][\"train\"]))\n",
    "    manual_feature_dict[name][\"train\"] = pd.DataFrame({})\n",
    "    \n",
    "    manual_feature_dict[name][\"train\"] = manual_feature_dict[name][\"train\"].assign(**train_df[\"url\"].progress_apply(lambda url : extract_handcrafted_features(url)))\n",
    "    manual_feature_dict[name][\"train\"][\"label\"] = train_df[\"label\"]\n",
    "\n",
    "    # --- Test ---\n",
    "    print(\"🔍 Extracting Test Features...\")\n",
    "    test_df = splits[\"test\"]\n",
    "    test_feats = test_df[\"url\"].progress_apply(extract_handcrafted_features)\n",
    "    manual_feature_dict[name][\"test\"] = manual_feature_dict[name][\"test\"].assign(**test_df[\"url\"].progress_apply(lambda url : extract_handcrafted_features(url)))\n",
    "    manual_feature_dict[name][\"test\"][\"label\"] = test_df[\"label\"]\n",
    "\n",
    "    # ✅ Print shapes safely\n",
    "    train_shape = manual_feature_dict[name][\"train\"].shape\n",
    "    test_shape = manual_feature_dict[name][\"test\"].shape\n",
    "    print(f\"✅ Done: {name} | Train: {train_shape}, Test: {test_shape}\")\n",
    "\n",
    "print(\"\\n🏁 All manual features extracted successfully with progress bars!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training XGBoost on dataset_0 ...\n",
      "RangeIndex(start=0, stop=417732, step=1)\n",
      "⚠️ Missing columns in dataset_0: ['url_length', 'hostname_length', 'path_length', 'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params', 'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip', 'has_subdomain', 'has_suspicious_words', 'domain_length', 'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency', 'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain', 'double_slash_in_path', 'url_length', 'hostname_length', 'path_length', 'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params', 'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip', 'has_subdomain', 'has_suspicious_words', 'domain_length', 'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency', 'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain', 'double_slash_in_path']\n",
      "\n",
      "🏁 All datasets completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 🚀 XGBoost Training on Multiple Datasets\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define handcrafted features\n",
    "independent_features = [\n",
    "    'url_length', 'hostname_length', 'path_length',\n",
    "    'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params',\n",
    "    'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip',\n",
    "    'has_subdomain', 'has_suspicious_words', 'domain_length',\n",
    "    'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency',\n",
    "    'digit_ratio', 'special_char_ratio', 'url_entropy', \n",
    "    'at_in_domain', 'double_slash_in_path'\n",
    "]\n",
    "dependent_feature = 'label'\n",
    "\n",
    "# Dictionary to store results\n",
    "xgb_results = {}\n",
    "\n",
    "# Loop through each dataset\n",
    "for name, splits in manual_feature_dict.items():\n",
    "       print(f\"\\n📊 Training XGBoost on {name} ...\")\n",
    "\n",
    "       # Prepare train/test DataFrames\n",
    "       train_df = pd.DataFrame(splits['train'])\n",
    "       test_df = pd.DataFrame(splits['test'])\n",
    "       print(train_df.columns)\n",
    "       # Ensure all required columns exist\n",
    "       missing_train = [col for col in independent_features if col not in train_df.columns]\n",
    "       missing_test = [col for col in independent_features if col not in test_df.columns]\n",
    "       if missing_train or missing_test:\n",
    "              print(f\"⚠️ Missing columns in {name}:\", missing_train + missing_test)\n",
    "              continue\n",
    "\n",
    "       # Extract X and y\n",
    "       X_train = train_df[independent_features]\n",
    "       y_train = train_df[dependent_feature]\n",
    "\n",
    "       X_test = test_df[independent_features]\n",
    "       y_test = test_df[dependent_feature]\n",
    "\n",
    "       # Convert to numpy (optional, for XGBoost performance)\n",
    "       X_train = X_train.values\n",
    "       X_test = X_test.values\n",
    "       y_train = y_train.values\n",
    "       y_test = y_test.values\n",
    "\n",
    "       # Train XGBoost model\n",
    "       model = XGBClassifier(\n",
    "              n_estimators=300,\n",
    "              learning_rate=0.1,\n",
    "              max_depth=6,\n",
    "              subsample=0.8,\n",
    "              colsample_bytree=0.8,\n",
    "              random_state=42,\n",
    "              eval_metric='logloss',\n",
    "              n_jobs=-1\n",
    "       )\n",
    "\n",
    "       # Use tqdm progress bar for large datasets\n",
    "       with tqdm(total=1, desc=f\"🚀 Training {name}\") as pbar:\n",
    "              model.fit(X_train, y_train)\n",
    "              pbar.update(1)\n",
    "\n",
    "       # Predictions\n",
    "       y_pred = model.predict(X_test)\n",
    "       y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "       # Evaluation metrics\n",
    "       acc = accuracy_score(y_test, y_pred)\n",
    "       prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "       rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "       f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "       roc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "       # Store results\n",
    "       xgb_results[name] = {\n",
    "              \"Accuracy\": acc,\n",
    "              \"Precision\": prec,\n",
    "              \"Recall\": rec,\n",
    "              \"F1\": f1,\n",
    "              \"ROC AUC\": roc\n",
    "       }\n",
    "\n",
    "       print(f\"\\n✅ Results for {name}:\")\n",
    "       print(f\"Accuracy:  {acc:.4f}\")\n",
    "       print(f\"Precision: {prec:.4f}\")\n",
    "       print(f\"Recall:    {rec:.4f}\")\n",
    "       print(f\"F1-score:  {f1:.4f}\")\n",
    "       print(f\"ROC-AUC:   {roc:.4f}\")\n",
    "\n",
    "print(\"\\n🏁 All datasets completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost classifier\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,      # number of boosting rounds\n",
    "    learning_rate=0.01,     # step size shrinkage\n",
    "    max_depth=30,           # tree depth\n",
    "    eval_metric='logloss', # evaluation metric\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,   # number of trees\n",
    "    max_depth=30,     # tree depth (None = auto)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c4a76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 Training model on DATASET_0 dataset\n",
      "======================================================================\n",
      "___________🧩 Using 50% of training data___________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataLoader is not an Optimizer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m criterion = nn.BCELoss()\n\u001b[32m     16\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lr/\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m trainer = \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Lists to track performance\u001b[39;00m\n\u001b[32m     19\u001b[39m trainer.train(num_epochs,lr,frac=frac,val_frac=frac, log=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mTrain.__init__\u001b[39m\u001b[34m(self, model, criterion, transformer_optimizer, main_optimizer, scheduler_t, scheduler_c, train_loader, val_loader, device)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mself\u001b[39m.main_optimizer = optim.Adam(\u001b[38;5;28mself\u001b[39m.cnn_params, lr=\u001b[32m1e-3\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m main_optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m main_optimizer\n\u001b[32m     37\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler_t = optim.lr_scheduler.ReduceLROnPlateau(\u001b[38;5;28mself\u001b[39m.transformer_optimizer, mode=\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduler_t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;28;01melse\u001b[39;00m scheduler_t\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler_c = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmain_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m scheduler_c \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;28;01melse\u001b[39;00m scheduler_c\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m.device = device\n\u001b[32m     40\u001b[39m \u001b[38;5;28mself\u001b[39m.train_loader = train_loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:1307\u001b[39m, in \u001b[36mReduceLROnPlateau.__init__\u001b[39m\u001b[34m(self, optimizer, mode, factor, patience, threshold, threshold_mode, cooldown, min_lr, eps)\u001b[39m\n\u001b[32m   1305\u001b[39m \u001b[38;5;66;03m# Attach optimizer\u001b[39;00m\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, Optimizer):\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(optimizer).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not an Optimizer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1308\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = optimizer\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(min_lr, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[31mTypeError\u001b[39m: DataLoader is not an Optimizer"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 🔁 Training Loop for Each Dataset\n",
    "# ============================================================\n",
    "for dataset_name, loaders in {'dataset_0':dataloader_dict['dataset_0']}.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"🚀 Training model on {dataset_name.upper()} dataset\")\n",
    "    print(\"=\"*70)\n",
    "    for frac in  [0.5, 1.0]:\n",
    "        print(f\"🧩 Using {frac*100:.0f}% of training data\".center(50, '_'))\n",
    "        train_loader = loaders[\"train_loader\"]\n",
    "        val_loader = loaders[\"val_loader\"]\n",
    "\n",
    "        # Initialize model, loss, optimizer\n",
    "        model = URLBinaryCNN(vocab_size=len(vocab)).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lr/10)\n",
    "        trainer = Train(model, criterion, optimizer, train_loader, val_loader)\n",
    "        # Lists to track performance\n",
    "        trainer.train(num_epochs,lr,frac=frac,val_frac=frac, log=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Store all results for this dataset\n",
    "    all_results[dataset_name] = {\n",
    "        \"train_losses\": trainer.train_losses,\n",
    "        \"val_losses\": trainer.val_losses,\n",
    "        \"train_accs\": trainer.train_accs,\n",
    "        \"val_accs\": trainer.val_accs,\n",
    "        \"final_val_acc\": trainer.val_accs[-1],\n",
    "        \"final_val_loss\": trainer.val_losses[-1]\n",
    "    }\n",
    "\n",
    "print(\"\\n✅ All datasets trained successfully!\")\n",
    "\n",
    "# ============================================================\n",
    "# 📊 Summary of All Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📈 Final Validation Accuracy Summary\")\n",
    "print(\"=\"*70)\n",
    "for name, res in all_results.items():\n",
    "    print(f\"{name:<20} | Val Acc: {res['final_val_acc']:.4f} | Val Loss: {res['final_val_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e6e11",
   "metadata": {},
   "source": [
    "\n",
    "======================================================================  \n",
    "🚀 Training model on DATASET_2 dataset\n",
    "======================================================================  \n",
    "___________🧩 Using 10% of training data___________  \n",
    "Epoch 1/6 | Train Loss: 0.6624, Train Acc: 0.6061 | Val Loss: 0.5799, Val Acc: 0.7219                \n",
    "Epoch 2/6 | Train Loss: 0.5179, Train Acc: 0.7594 | Val Loss: 0.5534, Val Acc: 0.7312                \n",
    "Epoch 3/6 | Train Loss: 0.4341, Train Acc: 0.8096 | Val Loss: 0.4320, Val Acc: 0.8120                \n",
    "Epoch 4/6 | Train Loss: 0.3945, Train Acc: 0.8308 | Val Loss: 0.4003, Val Acc: 0.8252              \n",
    "Epoch 5/6 | Train Loss: 0.3716, Train Acc: 0.8404 | Val Loss: 0.3567, Val Acc: 0.8496              \n",
    "Epoch 6/6 | Train Loss: 0.3588, Train Acc: 0.8458 | Val Loss: 0.3478, Val Acc: 0.8523              \n",
    "___________🧩 Using 50% of training data___________  \n",
    "Epoch 1/6 | Train Loss: 0.5106, Train Acc: 0.7353 | Val Loss: 0.5287, Val Acc: 0.6781              \n",
    "Epoch 2/6 | Train Loss: 0.3578, Train Acc: 0.8452 | Val Loss: 0.5693, Val Acc: 0.6529              \n",
    "Epoch 3/6 | Train Loss: 0.3324, Train Acc: 0.8569 | Val Loss: 0.5073, Val Acc: 0.7133              \n",
    "Epoch 4/6 | Train Loss: 0.3191, Train Acc: 0.8620 | Val Loss: 0.5989, Val Acc: 0.6296              \n",
    "Epoch 5/6 | Train Loss: 0.3086, Train Acc: 0.8663 | Val Loss: 0.4869, Val Acc: 0.7649              \n",
    "Epoch 6/6 | Train Loss: 0.3027, Train Acc: 0.8693 | Val Loss: 0.4661, Val Acc: 0.7953              \n",
    "__________🧩 Using 100% of training data___________  \n",
    "Epoch 1/6 | Train Loss: 0.4213, Train Acc: 0.8050 | Val Loss: 0.3473, Val Acc: 0.8572              \n",
    "Epoch 2/6 | Train Loss: 0.3203, Train Acc: 0.8626 | Val Loss: 0.3535, Val Acc: 0.8393              \n",
    "Epoch 3/6 | Train Loss: 0.3016, Train Acc: 0.8692 | Val Loss: 0.4240, Val Acc: 0.7920              \n",
    "Epoch 4/6 | Train Loss: 0.2923, Train Acc: 0.8723 | Val Loss: 0.3619, Val Acc: 0.8312              \n",
    "Epoch 5/6 | Train Loss: 0.2845, Train Acc: 0.8753 | Val Loss: 0.3901, Val Acc: 0.8187              \n",
    "Epoch 6/6 | Train Loss: 0.2788, Train Acc: 0.8772 | Val Loss: 0.3979, Val Acc: 0.8223              \n",
    "\n",
    "✅ All datasets trained successfully!  \n",
    "\n",
    "======================================================================  \n",
    "📈 Final Validation Accuracy Summary  \n",
    "======================================================================  \n",
    "dataset_2            | Val Acc: 0.8223 | Val Loss: 0.3979  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf37342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698c545f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_url_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m all_labels = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_url_tensor\u001b[49m), \u001b[32m64\u001b[39m):  \u001b[38;5;66;03m# batch size 64\u001b[39;00m\n\u001b[32m      7\u001b[39m         batch_x = test_url_tensor[i:i+\u001b[32m64\u001b[39m].to(device)\n\u001b[32m      8\u001b[39m         batch_y = test_labels_tensor[i:i+\u001b[32m64\u001b[39m].to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_url_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_url_tensor), 64):  # batch size 64\n",
    "        batch_x = test_url_tensor[i:i+64].to(device)\n",
    "        batch_y = test_labels_tensor[i:i+64].to(device)\n",
    "        \n",
    "        outputs = model(batch_x)\n",
    "        preds = (outputs >= 0.5).long().squeeze(1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "        \n",
    "        # Conv blocks\n",
    "        self.conv1 = nn.Conv1d(embed_dim, 256, kernel_size=8, padding=4)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(256, 128, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        # BiLSTM\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=64, num_layers=1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64*2, 128)  # 64*2 because bidirectional\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)  # binary output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, embed_dim, seq_len) for Conv1d\n",
    "        \n",
    "        # Conv block 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Prepare for LSTM: (batch_size, seq_len, features)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # BiLSTM\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out: (batch_size, seq_len, 2*hidden_size)\n",
    "        \n",
    "        # Take the last timestep\n",
    "        x = lstm_out[:, -1, :]  # (batch_size, 128)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae29a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 Training CNN-BiLSTM on DATASET1 dataset\n",
      "======================================================================\n",
      "[dataset1] Epoch 1/3 | Batch 102/102 | Loss: 0.2697, Acc: 0.8942\n",
      "[dataset1] Epoch 1/3 | Train Loss: 0.4063, Train Acc: 0.8384 | Val Loss: 0.2719, Val Acc: 0.8974\n",
      "[dataset1] Epoch 2/3 | Batch 102/102 | Loss: 0.1222, Acc: 0.9658\n",
      "[dataset1] Epoch 2/3 | Train Loss: 0.1782, Train Acc: 0.9378 | Val Loss: 0.1227, Val Acc: 0.9609\n",
      "[dataset1] Epoch 3/3 | Batch 102/102 | Loss: 0.0869, Acc: 0.9730\n",
      "[dataset1] Epoch 3/3 | Train Loss: 0.1033, Train Acc: 0.9677 | Val Loss: 0.0860, Val Acc: 0.9731\n",
      "\n",
      "======================================================================\n",
      "🚀 Training CNN-BiLSTM on DATASET2 dataset\n",
      "======================================================================\n",
      "[dataset2] Epoch 1/3 | Batch 47/47 | Loss: 0.0809, Acc: 0.9864\n",
      "[dataset2] Epoch 1/3 | Train Loss: 0.3467, Train Acc: 0.8455 | Val Loss: 0.0146, Val Acc: 0.9977\n",
      "[dataset2] Epoch 2/3 | Batch 47/47 | Loss: 0.0022, Acc: 1.0000\n",
      "[dataset2] Epoch 2/3 | Train Loss: 0.0140, Train Acc: 0.9977 | Val Loss: 0.0102, Val Acc: 0.9981\n",
      "[dataset2] Epoch 3/3 | Batch 47/47 | Loss: 0.0022, Acc: 1.0000\n",
      "[dataset2] Epoch 3/3 | Train Loss: 0.0122, Train Acc: 0.9980 | Val Loss: 0.0098, Val Acc: 0.9984\n",
      "\n",
      "======================================================================\n",
      "🚀 Training CNN-BiLSTM on DATASET3 dataset\n",
      "======================================================================\n",
      "[dataset3] Epoch 1/3 | Batch 139/139 | Loss: 0.3497, Acc: 0.8435\n",
      "[dataset3] Epoch 1/3 | Train Loss: 0.4518, Train Acc: 0.7863 | Val Loss: 0.3366, Val Acc: 0.8566\n",
      "[dataset3] Epoch 2/3 | Batch 139/139 | Loss: 0.2770, Acc: 0.8722\n",
      "[dataset3] Epoch 2/3 | Train Loss: 0.3166, Train Acc: 0.8633 | Val Loss: 0.2849, Val Acc: 0.8739\n",
      "[dataset3] Epoch 3/3 | Batch 139/139 | Loss: 0.2620, Acc: 0.8855\n",
      "[dataset3] Epoch 3/3 | Train Loss: 0.2841, Train Acc: 0.8752 | Val Loss: 0.2699, Val Acc: 0.8801\n",
      "\n",
      "✅ All datasets trained successfully!\n",
      "\n",
      "======================================================================\n",
      "📈 Final Validation Summary (CNN-BiLSTM)\n",
      "======================================================================\n",
      "dataset1             | Val Acc: 0.9731 | Val Loss: 0.0860\n",
      "dataset2             | Val Acc: 0.9984 | Val Loss: 0.0098\n",
      "dataset3             | Val Acc: 0.8801 | Val Loss: 0.2699\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# 🔧 Training Config\n",
    "# ============================================================\n",
    "num_epochs = 3\n",
    "lr = 0.001\n",
    "batch_print_interval = 1\n",
    "\n",
    "# Dictionary to store all dataset results\n",
    "all_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# 🔁 Loop Over Each Dataset\n",
    "# ============================================================\n",
    "for dataset_name, loaders in dataloader_dict.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"🚀 Training CNN-BiLSTM on {dataset_name.upper()} dataset\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    train_loader = loaders[\"train_loader\"]\n",
    "    val_loader = loaders[\"val_loader\"]\n",
    "\n",
    "    model = CNN_BiLSTM(vocab_size=len(vocab)).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Track metrics\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for batch_idx, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device).float().unsqueeze(1)\n",
    "            batch_y = torch.clamp(batch_y, 0, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "            acc = (preds == batch_y).float().mean().item()\n",
    "\n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            correct_train += (preds == batch_y).sum().item()\n",
    "            total_train += batch_x.size(0)\n",
    "\n",
    "            if (batch_idx + 1) % batch_print_interval == 0:\n",
    "                sys.stdout.write(f\"\\r[{dataset_name}] Epoch {epoch+1}/{num_epochs} | \"\n",
    "                                 f\"Batch {batch_idx+1}/{len(train_loader)} | \"\n",
    "                                 f\"Loss: {loss.item():.4f}, Acc: {acc:.4f}\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = correct_train / total_train\n",
    "        print()  # newline\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device).float().unsqueeze(1)\n",
    "                batch_y = torch.clamp(batch_y, 0, 1)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "                preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "                correct_val += (preds == batch_y).sum().item()\n",
    "                total_val += batch_x.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = correct_val / total_val\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"[{dataset_name}] Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # === Save results for this dataset ===\n",
    "    all_results[dataset_name] = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"train_accs\": train_accs,\n",
    "        \"val_accs\": val_accs,\n",
    "        \"final_val_acc\": val_accs[-1],\n",
    "        \"final_val_loss\": val_losses[-1]\n",
    "    }\n",
    "\n",
    "print(\"\\n✅ All datasets trained successfully!\")\n",
    "\n",
    "# ============================================================\n",
    "# 📊 Summary of Final Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📈 Final Validation Summary (CNN-BiLSTM)\")\n",
    "print(\"=\"*70)\n",
    "for name, res in all_results.items():\n",
    "    print(f\"{name:<20} | Val Acc: {res['final_val_acc']:.4f} | Val Loss: {res['final_val_loss']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
