{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd065c7b",
   "metadata": {},
   "source": [
    "UsingIP                    2  \n",
    "LongURL                    3  \n",
    "ShortURL                   2  \n",
    "Symbol@                    2  \n",
    "Redirecting//              2  \n",
    "PrefixSuffix-              2  \n",
    "SubDomains                 3  \n",
    "HTTPS                      3  \n",
    "DomainRegLen               2  \n",
    "Favicon                    2  \n",
    "NonStdPort                 2  \n",
    "HTTPSDomainURL             2  \n",
    "RequestURL                 2  \n",
    "AnchorURL                  3  \n",
    "LinksInScriptTags          3  \n",
    "ServerFormHandler          3  \n",
    "InfoEmail                  2  \n",
    "AbnormalURL                2  \n",
    "WebsiteForwarding          2  \n",
    "StatusBarCust              2  \n",
    "DisableRightClick          2  \n",
    "UsingPopupWindow           2  \n",
    "IframeRedirection          2  \n",
    "AgeofDomain                2  \n",
    "DNSRecording               2  \n",
    "WebsiteTraffic             3  \n",
    "PageRank                   2  \n",
    "GoogleIndex                2  \n",
    "LinksPointingToPage        3  \n",
    "StatsReport                2  \n",
    "class                      2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15af09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first df\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(r'Dataset\\url_train_df.csv')\n",
    "val_df = pd.read_csv(r'Dataset\\url_validation_df.csv')\n",
    "test_df = pd.read_csv(r'Dataset\\url_test_df.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5787917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second df\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(r'Dataset\\second_url_train_df.csv')\n",
    "val_df = pd.read_csv(r'Dataset\\second_url_validation_df.csv')\n",
    "test_df = pd.read_csv(r'Dataset\\second_url_test_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447f6aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     DataType  Non-Null Count  Missing Values  Unique Values  \\\n",
      "url                    object          455833               0         449369   \n",
      "type                   object          455833               0              4   \n",
      "label                    bool          455833               0              2   \n",
      "url_length              int64          455833               0            509   \n",
      "hostname_length         int64          455833               0            237   \n",
      "path_length             int64          455833               0            384   \n",
      "num_dots                int64          455833               0             34   \n",
      "num_hyphens             int64          455833               0             48   \n",
      "num_digits              int64          455833               0            208   \n",
      "num_letters             int64          455833               0            401   \n",
      "num_params              int64          455833               0             16   \n",
      "num_equals              int64          455833               0             29   \n",
      "num_slashes             int64          455833               0             31   \n",
      "num_at                  int64          455833               0              7   \n",
      "has_https               int64          455833               0              2   \n",
      "has_ip                  int64          455833               0              2   \n",
      "has_subdomain           int64          455833               0              2   \n",
      "has_suspicious_words    int64          455833               0              2   \n",
      "domain_length           int64          455833               0             72   \n",
      "in_alexa_top1m          int64          455833               0              2   \n",
      "tld                    object          455833               0            746   \n",
      "tld_phish_ratio       float64          455833               0            234   \n",
      "tld_total_frequency     int64          455833               0            190   \n",
      "digit_ratio           float64          455833               0          11942   \n",
      "special_char_ratio    float64          455833               0           5964   \n",
      "url_entropy           float64          455833               0         168465   \n",
      "at_in_domain            int64          455833               0              2   \n",
      "double_slash_in_path    int64          455833               0              2   \n",
      "\n",
      "                                                 First Value  \\\n",
      "url                   http://37.49.226.178/deusbins/deus.sh4   \n",
      "type                                                 malware   \n",
      "label                                                   True   \n",
      "url_length                                                45   \n",
      "hostname_length                                            5   \n",
      "path_length                                               33   \n",
      "num_dots                                                   4   \n",
      "num_hyphens                                                0   \n",
      "num_digits                                                11   \n",
      "num_letters                                               22   \n",
      "num_params                                                 0   \n",
      "num_equals                                                 0   \n",
      "num_slashes                                                6   \n",
      "num_at                                                     0   \n",
      "has_https                                                  0   \n",
      "has_ip                                                     0   \n",
      "has_subdomain                                              0   \n",
      "has_suspicious_words                                       0   \n",
      "domain_length                                              5   \n",
      "in_alexa_top1m                                             0   \n",
      "tld                                                  unknown   \n",
      "tld_phish_ratio                                     0.997217   \n",
      "tld_total_frequency                                    12217   \n",
      "digit_ratio                                         0.244444   \n",
      "special_char_ratio                                  0.222222   \n",
      "url_entropy                                         4.152638   \n",
      "at_in_domain                                               0   \n",
      "double_slash_in_path                                       0   \n",
      "\n",
      "                                                          Sample Values  \\\n",
      "url                   [http://37.49.226.178/deusbins/deus.sh4, medic...   \n",
      "type                            [malware, benign, phishing, defacement]   \n",
      "label                                                     [True, False]   \n",
      "url_length                                        [45, 61, 33, 56, 128]   \n",
      "hostname_length                                      [5, 40, 14, 18, 8]   \n",
      "path_length                                       [33, 14, 12, 44, 103]   \n",
      "num_dots                                               [4, 2, 3, 1, 10]   \n",
      "num_hyphens                                            [0, 1, 5, 2, 10]   \n",
      "num_digits                                             [11, 0, 3, 7, 5]   \n",
      "num_letters                                       [22, 53, 26, 40, 102]   \n",
      "num_params                                             [0, 1, 2, 11, 3]   \n",
      "num_equals                                              [0, 4, 1, 3, 9]   \n",
      "num_slashes                                             [6, 3, 4, 8, 5]   \n",
      "num_at                                                  [0, 1, 4, 2, 3]   \n",
      "has_https                                                        [0, 1]   \n",
      "has_ip                                                           [0, 1]   \n",
      "has_subdomain                                                    [0, 1]   \n",
      "has_suspicious_words                                             [0, 1]   \n",
      "domain_length                                        [5, 21, 10, 18, 8]   \n",
      "in_alexa_top1m                                                   [0, 1]   \n",
      "tld                                      [unknown, com, ca, co.uk, net]   \n",
      "tld_phish_ratio       [0.9972169927150693, 0.2236253353376213, 0.107...   \n",
      "tld_total_frequency                 [12217, 398479, 9456, 10036, 28255]   \n",
      "digit_ratio           [0.2444443901234688, 0.0, 0.0535714190051037, ...   \n",
      "special_char_ratio    [0.2222221728395171, 0.0983606396130098, 0.181...   \n",
      "url_entropy           [4.152638373963222, 4.152942715040354, 3.92258...   \n",
      "at_in_domain                                                     [0, 1]   \n",
      "double_slash_in_path                                             [0, 1]   \n",
      "\n",
      "                                                     Top 5 Value Counts  \n",
      "url                   {'http://style.org.hc360.com/css/detail/mysite...  \n",
      "type                  {'benign': 299607, 'defacement': 67658, 'phish...  \n",
      "label                                     {False: 299607, True: 156226}  \n",
      "url_length            {38: 13363, 40: 9334, 41: 8993, 34: 8429, 42: ...  \n",
      "hostname_length       {5: 120876, 16: 30993, 11: 27145, 12: 27004, 1...  \n",
      "path_length           {1: 36867, 0: 15894, 13: 10312, 27: 9697, 29: ...  \n",
      "num_dots              {2: 164947, 1: 153453, 3: 90865, 4: 28205, 5: ...  \n",
      "num_hyphens           {0: 263803, 1: 72900, 2: 30830, 3: 18943, 4: 1...  \n",
      "num_digits            {0: 194189, 4: 29168, 2: 25958, 1: 25276, 6: 2...  \n",
      "num_letters           {30: 11779, 29: 11371, 31: 11101, 28: 10696, 3...  \n",
      "num_params                 {0: 357572, 1: 94633, 2: 3540, 3: 43, 4: 16}  \n",
      "num_equals            {0: 357556, 1: 38380, 2: 16210, 4: 15032, 3: 1...  \n",
      "num_slashes           {5: 115447, 4: 98137, 3: 95154, 6: 56267, 7: 3...  \n",
      "num_at                           {0: 454900, 1: 903, 2: 21, 3: 4, 4: 3}  \n",
      "has_https                                         {0: 444957, 1: 10876}  \n",
      "has_ip                                               {0: 455777, 1: 56}  \n",
      "has_subdomain                                    {0: 327428, 1: 128405}  \n",
      "has_suspicious_words                              {0: 428412, 1: 27421}  \n",
      "domain_length         {5: 121398, 12: 41894, 13: 35522, 11: 33666, 1...  \n",
      "in_alexa_top1m                                   {0: 262631, 1: 193202}  \n",
      "tld                   {'com': 234799, 'unknown': 120920, 'org': 3188...  \n",
      "tld_phish_ratio       {0.2236253353376213: 234799, 0.997216992715069...  \n",
      "tld_total_frequency   {398479: 234799, 12217: 120920, 50844: 31889, ...  \n",
      "digit_ratio           {0.0: 194189, 0.0263157825484782: 2288, 0.0526...  \n",
      "special_char_ratio    {0.1052631301939131: 5625, 0.1764705363321951:...  \n",
      "url_entropy           {4.07674143017386: 931, 4.017917900762096: 796...  \n",
      "at_in_domain                                          {0: 455829, 1: 4}  \n",
      "double_slash_in_path                                {0: 455473, 1: 360}  \n"
     ]
    }
   ],
   "source": [
    "def summarize_dataframe(df):\n",
    "    summary = pd.DataFrame({\n",
    "        \"DataType\": df.dtypes,\n",
    "        \"Non-Null Count\": df.count(),\n",
    "        \"Missing Values\": df.isnull().sum(),\n",
    "        \"Unique Values\": df.nunique(),\n",
    "        \"First Value\": df.iloc[0],\n",
    "        \"Sample Values\": df.apply(lambda x: x.unique()[:5])\n",
    "    })\n",
    "    \n",
    "    # Optional: Add top 5 value counts per column as a dictionary\n",
    "    value_counts = {}\n",
    "    for col in df.columns:\n",
    "        value_counts[col] = df[col].value_counts().head(5).to_dict()\n",
    "    \n",
    "    summary[\"Top 5 Value Counts\"] = pd.Series(value_counts)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "summary_table = summarize_dataframe(train_df)\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e95615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b5f8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not available\n",
    "# pip install xgboost scikit-learn pandas\n",
    "\n",
    "# Split features and labels\n",
    "independent_features = ['url_length', 'hostname_length', 'path_length',\n",
    "       'num_dots', 'num_hyphens', 'num_digits', 'num_letters', 'num_params',\n",
    "       'num_equals', 'num_slashes', 'num_at', 'has_https', 'has_ip',\n",
    "       'has_subdomain', 'has_suspicious_words', 'domain_length',\n",
    "       'in_alexa_top1m', 'tld_phish_ratio', 'tld_total_frequency',\n",
    "       'digit_ratio', 'special_char_ratio', 'url_entropy', 'at_in_domain',\n",
    "       'double_slash_in_path']\n",
    "dependet_features  = 'label'\n",
    "X_train = train_df[independent_features]\n",
    "y_train = train_df[dependet_features]\n",
    "\n",
    "X_test = test_df[independent_features]\n",
    "y_test = test_df[dependet_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "469a4001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning:\n",
      "\n",
      "[13:41:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9694866321657274\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.99      0.98     42840\n",
      "        True       0.97      0.94      0.95     22279\n",
      "\n",
      "    accuracy                           0.97     65119\n",
      "   macro avg       0.97      0.96      0.97     65119\n",
      "weighted avg       0.97      0.97      0.97     65119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create XGBoost classifier\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,      # number of boosting rounds\n",
    "    learning_rate=0.01,     # step size shrinkage\n",
    "    max_depth=30,           # tree depth\n",
    "    eval_metric='logloss', # evaluation metric\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5369913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.973018627435925\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.98      0.98     42840\n",
      "        True       0.97      0.95      0.96     22279\n",
      "\n",
      "    accuracy                           0.97     65119\n",
      "   macro avg       0.97      0.97      0.97     65119\n",
      "weighted avg       0.97      0.97      0.97     65119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,   # number of trees\n",
    "    max_depth=30,     # tree depth (None = auto)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ff663",
   "metadata": {},
   "source": [
    "- **use Z-score normalization in coloumns so that isgood for neral networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac240c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10a8a5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing url_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1481858.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing hostname_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1614382.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing path_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1577467.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1518719.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_hyphens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1647535.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_digits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1623741.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_letters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1649346.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1489887.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_equals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1677336.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_slashes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1582607.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1475381.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_https\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1617881.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_ip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1572479.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_subdomain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1578152.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_suspicious_words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1625887.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing domain_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1487256.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing in_alexa_top1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1632972.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing tld_phish_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1547247.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing tld_total_frequency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1532419.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing digit_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1421060.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing special_char_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1528423.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing url_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1568059.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing at_in_domain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1592117.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing double_slash_in_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455833/455833 [00:00<00:00, 1565430.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing url_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1421546.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing hostname_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1288830.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing path_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1501186.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1419906.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_hyphens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1545860.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_digits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1368628.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_letters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1244226.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1492466.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_equals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1171045.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_slashes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1141256.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1463642.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_https\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1382616.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_ip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1414208.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_subdomain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1445937.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_suspicious_words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1341589.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing domain_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1470989.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing in_alexa_top1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1345257.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing tld_phish_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1397185.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing tld_total_frequency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1472869.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing digit_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1466172.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing special_char_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1469896.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing url_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1383127.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing at_in_domain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1424690.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing double_slash_in_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65119/65119 [00:00<00:00, 1427072.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing url_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1478717.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing hostname_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1341497.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing path_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1218040.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1457892.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_hyphens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1522138.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_digits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1516282.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_letters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1219204.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1437308.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_equals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1434349.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_slashes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1511947.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing num_at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1520071.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_https\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1468359.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_ip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1509023.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_subdomain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1456721.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing has_suspicious_words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1475203.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing domain_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1424400.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing in_alexa_top1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1508169.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing tld_phish_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1495354.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing tld_total_frequency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1084380.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing digit_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1253351.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing special_char_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1435853.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing url_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1507399.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing at_in_domain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1544858.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing double_slash_in_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130239/130239 [00:00<00:00, 1504853.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "for df in [train_df, test_df, val_df]:\n",
    "    for cols in independent_features:\n",
    "        if cols == 'label':\n",
    "            continue\n",
    "        print(f\"normalizing {cols}\")\n",
    "        mean = df[cols].mean()\n",
    "        std = df[cols].std()\n",
    "        df[cols] = df[cols].progress_apply(lambda x: (x-mean)/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d64b6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train = train_df[independent_features]\n",
    "y_train = train_df[dependet_features]\n",
    "X_val = val_df[independent_features]\n",
    "y_val = val_df[dependet_features]\n",
    "\n",
    "X_test = test_df[independent_features]\n",
    "y_test = test_df[dependet_features]\n",
    "\n",
    "\n",
    "\n",
    "# Convert features to float tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "X_test_tensor  = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert labels to long tensors (for classification)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).squeeze()\n",
    "y_val_tensor   = torch.tensor(y_val.values, dtype=torch.long).squeeze()\n",
    "y_test_tensor  = torch.tensor(y_test.values, dtype=torch.long).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a05a8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move tensors to device\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_val_tensor   = X_val_tensor.to(device)\n",
    "y_val_tensor   = y_val_tensor.to(device)\n",
    "X_test_tensor  = X_test_tensor.to(device)\n",
    "y_test_tensor  = y_test_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff5e4e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500] | Train Loss: 0.0916 | Train Acc: 96.70% | Val Loss: 0.0971 | Val Acc: 96.53%\n",
      "Epoch [20/500] | Train Loss: 0.0837 | Train Acc: 96.97% | Val Loss: 0.0878 | Val Acc: 96.92%\n",
      "Epoch [30/500] | Train Loss: 0.0804 | Train Acc: 97.11% | Val Loss: 0.0867 | Val Acc: 96.89%\n",
      "Epoch [40/500] | Train Loss: 0.0770 | Train Acc: 97.22% | Val Loss: 0.0866 | Val Acc: 96.98%\n",
      "Epoch [50/500] | Train Loss: 0.0755 | Train Acc: 97.25% | Val Loss: 0.0882 | Val Acc: 96.83%\n",
      "Epoch [60/500] | Train Loss: 0.0754 | Train Acc: 97.27% | Val Loss: 0.0821 | Val Acc: 97.11%\n",
      "Epoch [70/500] | Train Loss: 0.0743 | Train Acc: 97.31% | Val Loss: 0.0854 | Val Acc: 97.02%\n",
      "Epoch [80/500] | Train Loss: 0.0711 | Train Acc: 97.42% | Val Loss: 0.0852 | Val Acc: 97.09%\n",
      "Epoch [90/500] | Train Loss: 0.0703 | Train Acc: 97.45% | Val Loss: 0.0859 | Val Acc: 97.15%\n",
      "Epoch [100/500] | Train Loss: 0.0718 | Train Acc: 97.35% | Val Loss: 0.0890 | Val Acc: 97.11%\n",
      "Epoch [110/500] | Train Loss: 0.0718 | Train Acc: 97.39% | Val Loss: 0.0836 | Val Acc: 97.03%\n",
      "Epoch [120/500] | Train Loss: 0.0710 | Train Acc: 97.39% | Val Loss: 0.0887 | Val Acc: 96.95%\n",
      "Epoch [130/500] | Train Loss: 0.0718 | Train Acc: 97.41% | Val Loss: 0.0848 | Val Acc: 97.10%\n",
      "Epoch [140/500] | Train Loss: 0.0708 | Train Acc: 97.38% | Val Loss: 0.0863 | Val Acc: 97.03%\n",
      "Epoch [150/500] | Train Loss: 0.0683 | Train Acc: 97.47% | Val Loss: 0.0853 | Val Acc: 97.07%\n",
      "Epoch [160/500] | Train Loss: 0.0727 | Train Acc: 97.33% | Val Loss: 0.0871 | Val Acc: 97.05%\n",
      "Epoch [170/500] | Train Loss: 0.0731 | Train Acc: 97.31% | Val Loss: 0.0874 | Val Acc: 97.07%\n",
      "Epoch [180/500] | Train Loss: 0.0691 | Train Acc: 97.43% | Val Loss: 0.0844 | Val Acc: 97.16%\n",
      "Epoch [190/500] | Train Loss: 0.0693 | Train Acc: 97.42% | Val Loss: 0.0862 | Val Acc: 97.17%\n",
      "Epoch [200/500] | Train Loss: 0.0693 | Train Acc: 97.41% | Val Loss: 0.0848 | Val Acc: 97.21%\n",
      "Epoch [210/500] | Train Loss: 0.0713 | Train Acc: 97.35% | Val Loss: 0.1060 | Val Acc: 96.91%\n",
      "Epoch [220/500] | Train Loss: 0.0728 | Train Acc: 97.31% | Val Loss: 0.0926 | Val Acc: 97.17%\n",
      "Epoch [230/500] | Train Loss: 0.0675 | Train Acc: 97.49% | Val Loss: 0.0848 | Val Acc: 97.18%\n",
      "Epoch [240/500] | Train Loss: 0.0719 | Train Acc: 97.33% | Val Loss: 0.0847 | Val Acc: 97.02%\n",
      "Epoch [250/500] | Train Loss: 0.0681 | Train Acc: 97.46% | Val Loss: 0.0886 | Val Acc: 96.93%\n",
      "Epoch [260/500] | Train Loss: 0.0683 | Train Acc: 97.46% | Val Loss: 0.0982 | Val Acc: 96.80%\n",
      "Epoch [270/500] | Train Loss: 0.0736 | Train Acc: 97.31% | Val Loss: 0.0903 | Val Acc: 97.08%\n",
      "Epoch [280/500] | Train Loss: 0.0743 | Train Acc: 97.26% | Val Loss: 0.0868 | Val Acc: 97.08%\n",
      "Epoch [290/500] | Train Loss: 0.0716 | Train Acc: 97.33% | Val Loss: 0.0877 | Val Acc: 97.06%\n",
      "Epoch [300/500] | Train Loss: 0.0737 | Train Acc: 97.41% | Val Loss: 0.1024 | Val Acc: 96.61%\n",
      "Epoch [310/500] | Train Loss: 0.0723 | Train Acc: 97.48% | Val Loss: 0.1041 | Val Acc: 97.16%\n",
      "Epoch [320/500] | Train Loss: 0.0732 | Train Acc: 97.44% | Val Loss: 0.0917 | Val Acc: 97.08%\n",
      "Epoch [330/500] | Train Loss: 0.0702 | Train Acc: 97.57% | Val Loss: 0.0884 | Val Acc: 97.16%\n",
      "Epoch [340/500] | Train Loss: 0.0706 | Train Acc: 97.60% | Val Loss: 0.0903 | Val Acc: 97.15%\n",
      "Epoch [350/500] | Train Loss: 0.0696 | Train Acc: 97.57% | Val Loss: 0.0910 | Val Acc: 97.23%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    104\u001b[39m val_total = \u001b[32m0\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_val_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_val_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make sure your labels are LongTensor and zero-indexed\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).squeeze()\n",
    "y_val_tensor   = torch.tensor(y_val.values, dtype=torch.long).squeeze()\n",
    "y_test_tensor  = torch.tensor(y_test.values, dtype=torch.long).squeeze()\n",
    "\n",
    "# Convert features to float tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "X_test_tensor  = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "batch_size = 512  # you can tune this (128–2048 typical)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(y_train_tensor.unique())\n",
    "\n",
    "# Simple FNN for classification\n",
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.input = nn.Linear(input_size, hidden_size[0])\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hiddenlayers = nn.ModuleList()\n",
    "        for i in range(len(hidden_layers)-1):\n",
    "            self.hiddenlayers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        for hidden in self.hiddenlayers:\n",
    "            x = hidden(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.output(x)  # raw logits\n",
    "        return x\n",
    "\n",
    "input_size = len(independent_features)\n",
    "hidden_size = [128, 64, 32,16,8]\n",
    "output_size = num_classes  # must match number of classes\n",
    "\n",
    "model = SimpleFNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "Val_loss = []\n",
    "Val_accuracy = []\n",
    "Train_accuracy = []\n",
    "Train_loss = []\n",
    "epochs = 500\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Move tensors to device\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_val_tensor   = X_val_tensor.to(device)\n",
    "y_val_tensor   = y_val_tensor.to(device)\n",
    "X_test_tensor  = X_test_tensor.to(device)\n",
    "y_test_tensor  = y_test_tensor.to(device)\n",
    "Val_loss = []\n",
    "Val_accuracy = []\n",
    "Train_accuracy = []\n",
    "Train_loss = []\n",
    "epochs = 500\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    Train_loss.append(epoch_loss)\n",
    "    Train_accuracy.append(epoch_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            val_outputs = model(X_val_batch)\n",
    "            loss = criterion(val_outputs, y_val_batch)\n",
    "            val_loss += loss.item() * X_val_batch.size(0)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_correct += (val_predicted == y_val_batch).sum().item()\n",
    "            val_total += y_val_batch.size(0)\n",
    "\n",
    "    val_epoch_loss = val_loss / val_total\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    Val_loss.append(val_epoch_loss)\n",
    "    Val_accuracy.append(val_epoch_acc)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | \"\n",
    "              f\"Train Loss: {epoch_loss:.4f} | \"\n",
    "              f\"Train Acc: {epoch_acc*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_epoch_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_epoch_acc*100:.2f}%\")\n",
    "\n",
    "# Sample predictions on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.to(device))\n",
    "    test_preds = torch.argmax(test_outputs, dim=1)\n",
    "    print(\"Sample predictions:\", test_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97215b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355
         ],
         "y": [
          0.16664332914398197,
          0.12399293117473892,
          0.112156462825879,
          0.10524100557030479,
          0.10111396154889453,
          0.09817734677298753,
          0.095729900093661,
          0.09638053443010347,
          0.09317701642840417,
          0.09156758006167998,
          0.09055183462928816,
          0.08949109180672088,
          0.0884956072245663,
          0.08867001800143935,
          0.08658154013216607,
          0.08675391331531415,
          0.08651336021052936,
          0.08535474807849619,
          0.08484864596792334,
          0.08368108239149238,
          0.0839879966100461,
          0.08429313306273613,
          0.08275995678903508,
          0.08189649507958285,
          0.08321791539704088,
          0.08157428496314463,
          0.08074894477393176,
          0.08021102855740568,
          0.07970880691225483,
          0.08040263547282255,
          0.08009108580227509,
          0.07973098647689174,
          0.08062925415426603,
          0.07902350185224123,
          0.07979777868117424,
          0.08075685948904789,
          0.07862372496841394,
          0.08103377712006084,
          0.07863957764150806,
          0.07696719579559712,
          0.07753194151849556,
          0.07646769259767197,
          0.07670361377626696,
          0.07668683517618188,
          0.07616431101848144,
          0.07733610238315992,
          0.07703396596232917,
          0.07623181725439311,
          0.07610371571789502,
          0.07548738049044634,
          0.07786658596017927,
          0.07650908103084557,
          0.07665395819030531,
          0.07682768293135918,
          0.07557743243232544,
          0.07507825326780937,
          0.07549328535378545,
          0.07488122667105866,
          0.0750405753848487,
          0.0754180900464693,
          0.07341506077764162,
          0.0731133972570113,
          0.07362895534314828,
          0.07367325100136857,
          0.07315968859278624,
          0.07357255767830402,
          0.07300689773893794,
          0.07361326172898162,
          0.0726659122711379,
          0.07427143607418762,
          0.07506640387391138,
          0.07309147566526855,
          0.07259738768736032,
          0.07256029960712282,
          0.07300140618132106,
          0.07287263849356913,
          0.07088144619391412,
          0.07168234357167147,
          0.07199864202455668,
          0.07113317830168447,
          0.07091043949542948,
          0.07135599161268301,
          0.07097621251042699,
          0.07014159922893232,
          0.07180766268215809,
          0.07056589762285953,
          0.07123955725178377,
          0.07129556332602703,
          0.07214439498482382,
          0.07029948552053757,
          0.07097616464653966,
          0.07147827251895329,
          0.06931973048163197,
          0.07028349476826029,
          0.06935180505968376,
          0.07030590602502729,
          0.07065150829880462,
          0.07091041433912637,
          0.07137991108761677,
          0.07182164441833622,
          0.07029122052083676,
          0.07047075165198086,
          0.07003482938583569,
          0.07147040787336903,
          0.0713857823368047,
          0.07103530927768366,
          0.07325577791728788,
          0.07151255806249754,
          0.07364771141912209,
          0.07180968878617222,
          0.07299090952879518,
          0.0708019873443964,
          0.07121505024884935,
          0.07188268510834216,
          0.0707433533722329,
          0.07041444546246271,
          0.07097222683185926,
          0.07105982002626605,
          0.07127321105689821,
          0.07099444912933923,
          0.07192272033755215,
          0.06975418348908438,
          0.07078756442885659,
          0.06892168559340525,
          0.07050740134417038,
          0.07031136585608466,
          0.06951156833465384,
          0.07007610223476629,
          0.07109363735067278,
          0.07176698182194033,
          0.07051984131663046,
          0.07017222024145668,
          0.07149554065982444,
          0.07203898278741011,
          0.07086337507309491,
          0.07020514760958542,
          0.0699458229468795,
          0.0695748408985752,
          0.07032646335435785,
          0.07075388486625439,
          0.07285058901291193,
          0.07129354293670773,
          0.06960103608033355,
          0.06973688738667869,
          0.0710802956890678,
          0.07094565638928577,
          0.06996407483869087,
          0.07130505992642235,
          0.06936775742417714,
          0.06833053201454029,
          0.0684298766238193,
          0.07002070737211565,
          0.06863763656581688,
          0.07096649581510925,
          0.07244511778701765,
          0.07158492808860882,
          0.06877596035284872,
          0.06766606098403098,
          0.0687438793730736,
          0.07272248798551088,
          0.07263411964090102,
          0.06945333087178575,
          0.06779738643588064,
          0.06960361951157626,
          0.07022158085830273,
          0.07066767751982661,
          0.07047138961421072,
          0.06951014102820069,
          0.07121506967418618,
          0.0731124028765883,
          0.0707501973088619,
          0.07058067215834424,
          0.06921152433472723,
          0.06995673571988001,
          0.06906965410076857,
          0.07021175057226954,
          0.0703234341658478,
          0.06878895140706387,
          0.07029031021821508,
          0.06914724699697061,
          0.06690555895399193,
          0.06864827745948474,
          0.06946468085668227,
          0.07031343140300826,
          0.06847039558163906,
          0.06836968845834161,
          0.06836022978638724,
          0.06837603228477773,
          0.06829346537274437,
          0.06926092412563235,
          0.06695946161145923,
          0.069807030457667,
          0.06828389415573231,
          0.06953992475661437,
          0.07096463139695482,
          0.0684911252766097,
          0.06974067533743825,
          0.06902265855451041,
          0.0680154867533307,
          0.06927879171422686,
          0.06814019769317119,
          0.07009667843475867,
          0.06859184372902039,
          0.06839315114101041,
          0.06754592184618996,
          0.06945350768458801,
          0.06900220325209676,
          0.06857953086083408,
          0.0679353851274312,
          0.07127205677394256,
          0.06767936509275357,
          0.0685694651145158,
          0.0698283924387468,
          0.06729609572632478,
          0.07059760028146746,
          0.06848104666036975,
          0.06819743494649841,
          0.06848538022876623,
          0.0679949596969149,
          0.07275156541363369,
          0.06889758541851462,
          0.06842125250035741,
          0.0683647206246552,
          0.06867576511479744,
          0.06809600769147052,
          0.06845655927146675,
          0.06747464025841614,
          0.07035336638343886,
          0.06885052335232505,
          0.0674938873779742,
          0.06734760825880794,
          0.06631706299375094,
          0.0672472390716355,
          0.07039368880996417,
          0.06978968056338122,
          0.06840144504826044,
          0.06862386094016121,
          0.07052304635371572,
          0.06899218330163784,
          0.07191380034332026,
          0.07036735917130692,
          0.07100096584661636,
          0.0683843737445882,
          0.07032158574019243,
          0.0668555252125358,
          0.06739381660429469,
          0.06657942383971467,
          0.06647981339129992,
          0.06779461318919686,
          0.06805399357541196,
          0.0694662945627089,
          0.06891606578655703,
          0.0684583813532746,
          0.06864019248890205,
          0.06825250664084699,
          0.06834578352543719,
          0.06853945592105744,
          0.07041131152464473,
          0.06838846257212702,
          0.06825600897937004,
          0.07232932660687495,
          0.06970747645580198,
          0.06863360494982183,
          0.07120170404131357,
          0.06819454142613599,
          0.07036434880024352,
          0.06992017172204287,
          0.07020421678667679,
          0.07133845476100234,
          0.07358123474358859,
          0.07026204260086023,
          0.07212210149630768,
          0.0718075175876366,
          0.07166251574595105,
          0.07013655520110172,
          0.07116977436389095,
          0.07117893261800855,
          0.07121854519029709,
          0.07064140112785448,
          0.07432403599234258,
          0.07161599472283936,
          0.07335365472301855,
          0.07191720842492874,
          0.07249202772547415,
          0.07321117910618878,
          0.07047864534450433,
          0.07172162846323026,
          0.07218282973073523,
          0.07650358356652122,
          0.07160165295887572,
          0.07340610891746026,
          0.07133420857134098,
          0.06969578710209406,
          0.06901954010331031,
          0.09505121874649425,
          0.08268910330876722,
          0.07982216550299573,
          0.07835087178431219,
          0.07675636256955329,
          0.07365002766340578,
          0.07552209377277834,
          0.07430421916377707,
          0.07783275229595903,
          0.07375732060958522,
          0.07443443659590283,
          0.07417517840222597,
          0.07312783442140056,
          0.07266500632115133,
          0.07070534552451971,
          0.07233346186447465,
          0.07252148614856564,
          0.07341643994350738,
          0.07021411363552653,
          0.07142768778751914,
          0.07231039279236835,
          0.07309647605400058,
          0.07254699328834664,
          0.07109814209790453,
          0.07179771500885913,
          0.07318478113628638,
          0.07265656651500255,
          0.07372751477019945,
          0.06993963570577899,
          0.06964015400289425,
          0.06969947363817057,
          0.07020940344426332,
          0.0697886124386975,
          0.0690100501305341,
          0.07145248585821894,
          0.07022578023602731,
          0.06933157761532997,
          0.06976293353111444,
          0.07098528229546455,
          0.07067468878814875,
          0.07093403078326196,
          0.07105457384325069,
          0.0700583653622077,
          0.06856247161885702,
          0.06780486557678181,
          0.0706028705304451,
          0.06874199668656164,
          0.0696524442130257,
          0.07189140509242252,
          0.07379211464017287,
          0.07047669424208022,
          0.07028750619850924,
          0.06933468713871074,
          0.0700279430873783,
          0.06869642440492539,
          0.0695960721352728,
          0.06972240056161086,
          0.07109840019675309,
          0.07021314800552847,
          0.06954903187920965,
          0.06780029275044254
         ]
        },
        {
         "mode": "lines+markers",
         "name": "validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355
         ],
         "y": [
          0.13988831169294424,
          0.12168311181183036,
          0.10978300053521639,
          0.1052221499118524,
          0.10159429097684923,
          0.09800500457452223,
          0.09702391711385851,
          0.09870393364934625,
          0.09493827985444163,
          0.09708304500511232,
          0.09406298950012126,
          0.09939359086708369,
          0.09172442199119563,
          0.09169763577886537,
          0.09604278510668719,
          0.09141145191439057,
          0.08885665622803636,
          0.09255592393383508,
          0.0880200963166079,
          0.08776616980052296,
          0.08957466261215974,
          0.08785196941879872,
          0.08778547366104109,
          0.08868866760660503,
          0.08574412592498909,
          0.08559061257350326,
          0.08678385430862008,
          0.08428432937805268,
          0.08581690670876876,
          0.08669784337277375,
          0.0862258802748572,
          0.08835700186231724,
          0.08792988400529073,
          0.08907703215739575,
          0.08693808159859517,
          0.08494556273349939,
          0.08537368170653825,
          0.08608401032333353,
          0.0855744144449936,
          0.08655367766447282,
          0.08342668518461448,
          0.08381898776681286,
          0.08564473275842605,
          0.08489743096827737,
          0.08586684969149014,
          0.08371869619188599,
          0.08771228902900875,
          0.08341792924197705,
          0.0853720186298461,
          0.08822978042134003,
          0.08466752290268967,
          0.0901492253622201,
          0.08492659600192798,
          0.08475278550303089,
          0.08347900478121024,
          0.08696184917512237,
          0.08238058615944446,
          0.08306710826606833,
          0.08318376884419654,
          0.08214471183905976,
          0.08416762259750346,
          0.08527985475181381,
          0.08270534523651388,
          0.08335888000317757,
          0.0834976745125331,
          0.08333154274827702,
          0.08340229372883924,
          0.08374705827589532,
          0.08181663656771297,
          0.08537701832954461,
          0.08894806603058622,
          0.08216185301966415,
          0.08811518979103096,
          0.08736491570479701,
          0.08554477147500976,
          0.08352524642699893,
          0.08262062090139109,
          0.08406777651963143,
          0.08097069368795763,
          0.08517413581258072,
          0.08209681630236182,
          0.08298390773070968,
          0.08246466639162008,
          0.08210745839375293,
          0.08281753747733829,
          0.08120709460150508,
          0.08561575716793932,
          0.08937639353498662,
          0.0842546769588478,
          0.08591107721878664,
          0.08475743925566911,
          0.08334568529221145,
          0.0889083509127408,
          0.08016866235116926,
          0.08374591070496562,
          0.08252368925010463,
          0.08476357897217207,
          0.09425154689499673,
          0.08610293017967256,
          0.08897862662458873,
          0.08418959902777381,
          0.08257612996939201,
          0.08386286429023758,
          0.08357150348635177,
          0.08548145683508161,
          0.08521477969516203,
          0.08491183646841162,
          0.08935451621593322,
          0.08695083467563698,
          0.08356507710020933,
          0.0818697296593317,
          0.0824280805442266,
          0.08652243342279389,
          0.08591634866390901,
          0.08242100808807479,
          0.08113905029183642,
          0.08480112051586286,
          0.08081177705882363,
          0.08875810047706487,
          0.0886556668989741,
          0.0841740566962917,
          0.08331889008957459,
          0.08266174094151162,
          0.08203713302429645,
          0.08303811384452933,
          0.08304055876199994,
          0.08429657561676242,
          0.0861295352376163,
          0.0871056490961795,
          0.08475822666314492,
          0.08405857824737555,
          0.08584084038200297,
          0.08931833024393888,
          0.08706972521953425,
          0.0840993395106251,
          0.08697206441796342,
          0.08677511392879984,
          0.08955227396065069,
          0.08536857076476707,
          0.08626414774109983,
          0.08492470384878631,
          0.08879037496134962,
          0.08821595092215416,
          0.09292987874802824,
          0.08583669254277429,
          0.08553956594984012,
          0.10547255361261126,
          0.08703708193691602,
          0.0862822103129459,
          0.08527147724253921,
          0.08567060238235569,
          0.08816266944867555,
          0.08691593531712334,
          0.08573917610257394,
          0.08790684849368663,
          0.08440743945938016,
          0.08964510977202775,
          0.08251396686729755,
          0.09391467615407464,
          0.0870505705273752,
          0.08407989743831583,
          0.08510599141030926,
          0.08166337778124909,
          0.08659231372287496,
          0.09003958992863645,
          0.08591823930140882,
          0.08593771250284211,
          0.08263119614295851,
          0.09397661241628388,
          0.08743380716007877,
          0.08514678214745591,
          0.0867279386694684,
          0.09712975558422765,
          0.08886277575361978,
          0.09170428740246815,
          0.08664791836225619,
          0.08682304263353596,
          0.08212976815362524,
          0.08912652755986991,
          0.08443698386607555,
          0.08585693876738731,
          0.08373915114522466,
          0.09016859421708193,
          0.09318137371734528,
          0.08625290762452854,
          0.08473726869107019,
          0.08815414215881272,
          0.0867378157487172,
          0.08707499006285609,
          0.08624238587941584,
          0.08320138181513025,
          0.08860078337778765,
          0.0845880142963175,
          0.0895879202311308,
          0.08535577262566829,
          0.09667565467810459,
          0.08957749394628522,
          0.08642098922973661,
          0.09112567254706726,
          0.08476413024316985,
          0.0894306696780512,
          0.08692860616095398,
          0.08581503722767078,
          0.09426628534087407,
          0.08401735158258698,
          0.08574238659001218,
          0.09101410103538822,
          0.08657829367030925,
          0.09649671460060176,
          0.10598680868586158,
          0.08465404040998027,
          0.08482274861611593,
          0.088153142117548,
          0.0946865365592681,
          0.08557172331872541,
          0.08730037403406546,
          0.08826404697837532,
          0.08745280877435334,
          0.08914475889426852,
          0.0925735862960216,
          0.08606757498651575,
          0.08455860927086707,
          0.08575878637943883,
          0.08990677408198706,
          0.08408794787700474,
          0.08465471258519618,
          0.08457219166264804,
          0.09106224770325883,
          0.0905140101613763,
          0.08482938444343982,
          0.08769721745913135,
          0.0950862743693675,
          0.08538121534509946,
          0.08944155424188002,
          0.08696876321614957,
          0.08955440104606335,
          0.08584651246269091,
          0.08373719367606439,
          0.08601305550043754,
          0.08473750136091932,
          0.09161526765188523,
          0.08489909576832996,
          0.08696869079079005,
          0.08361199272472133,
          0.09662526999715826,
          0.08441343749975133,
          0.08487968905766073,
          0.08773170317200955,
          0.08423913297293965,
          0.08862159582141217,
          0.08792885830949612,
          0.09081400583783836,
          0.0919176817960537,
          0.09194974084523788,
          0.08576677681103183,
          0.10020856096409139,
          0.0856867324263147,
          0.08507482260199037,
          0.09225808254745327,
          0.09820978275856687,
          0.08655076403901386,
          0.08688863177292644,
          0.08494353749557101,
          0.09082068057243405,
          0.08964678634911084,
          0.09733904765423568,
          0.08921954269666894,
          0.08930443657636378,
          0.09159990536600383,
          0.09028801840536059,
          0.09281755764875482,
          0.08346639944275333,
          0.08821673288180874,
          0.09018554117118895,
          0.09137951947055828,
          0.08649334987048304,
          0.09621306336031592,
          0.085735601435351,
          0.09021557181088946,
          0.08680459603703071,
          0.09672102806092212,
          0.08608916980855,
          0.0841117763821752,
          0.09676143329260675,
          0.0863126407227275,
          0.08688887410452056,
          0.08515782181541204,
          0.09396238590622427,
          0.09321188878356874,
          0.08771318364363413,
          0.08784053501752195,
          0.09060543473974685,
          0.0921352715346357,
          0.09547401429001129,
          0.1165464757961793,
          0.09292311751343837,
          0.09690850393130529,
          0.09102847539804625,
          0.08977428784402568,
          0.10241140707338642,
          0.0934034642926912,
          0.09098720916781952,
          0.09220411238367408,
          0.10163516254466338,
          0.0918534068859009,
          0.0929470466450672,
          0.09277183677423118,
          0.08777021335667995,
          0.09016045418744818,
          0.10406759864424406,
          0.0944164889798056,
          0.09073773665005022,
          0.09371454791680187,
          0.09274741614827074,
          0.09910752029389298,
          0.09312905204287737,
          0.08878212878129374,
          0.09610978388014892,
          0.09168430186110699,
          0.09165628773618485,
          0.09123924787517568,
          0.09227553528499553,
          0.0905800494869638,
          0.08994110869605647,
          0.09263614632277888,
          0.09155017290447459,
          0.09421647139360013,
          0.08908285357846418,
          0.09270222145215921,
          0.08836915390463376,
          0.09577491614263052,
          0.09043901195314338,
          0.09388241338457919,
          0.09162849130815587,
          0.09710828121110114,
          0.09243341739644567,
          0.09334897057040822,
          0.09257409255513295,
          0.08888630108522144,
          0.09033520723178631,
          0.08871823474975918,
          0.09025465711603552,
          0.09650038981562349,
          0.08998970183092633,
          0.09013317449736293,
          0.08928722079364546,
          0.08869855411980061,
          0.09068839359847417,
          0.09569126599142848,
          0.09102204755467026,
          0.08764773823233282,
          0.09028722236083128,
          0.08825303258661069,
          0.08715742383210626
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355
         ],
         "y": [
          0.9323633874686563,
          0.9526997825958191,
          0.9584431140351839,
          0.9619312335877394,
          0.9635326972816799,
          0.9646515280815562,
          0.9654083842108843,
          0.965463228857937,
          0.966676392450744,
          0.9669615846154184,
          0.9677513475329781,
          0.9679158814741363,
          0.9681418414199937,
          0.9682142363541034,
          0.9689732862693136,
          0.9689667049116673,
          0.9690676190622443,
          0.9692365405751667,
          0.9691136885657686,
          0.9697147858974668,
          0.9698069249045155,
          0.9695985152457149,
          0.970254457224466,
          0.970671276542067,
          0.9701908374338848,
          0.9706690827561848,
          0.9711231964337816,
          0.9712460484431799,
          0.9713996134549275,
          0.9711122275043711,
          0.9712943117325863,
          0.971210947869066,
          0.9710025382102656,
          0.971467620817273,
          0.9712416608714156,
          0.9708928489161601,
          0.9715992479701996,
          0.9711780410808344,
          0.9716299609725492,
          0.9722288645183653,
          0.9720774932924997,
          0.9723955922454056,
          0.9722376396618937,
          0.9718625022760529,
          0.9727202725559579,
          0.9721937639442515,
          0.9720906560077923,
          0.9724745685371616,
          0.9722573837348327,
          0.9725052815395112,
          0.9717593943395937,
          0.9723319724548245,
          0.9722508023771864,
          0.9722398334477759,
          0.9726281335489093,
          0.9726961409112548,
          0.9728124115630066,
          0.9730493404382745,
          0.9728102177771245,
          0.9726500714077304,
          0.9733323388170668,
          0.9734990665441071,
          0.9732753003841319,
          0.9734113151088227,
          0.9735933993370379,
          0.9735670739064526,
          0.9734288653958796,
          0.9732884630994245,
          0.9733455015323594,
          0.9730866347982704,
          0.9725074753253933,
          0.9734573846123471,
          0.9736877321299686,
          0.9737557394923141,
          0.9734529970405829,
          0.9733915710358838,
          0.9741572023087403,
          0.973854459857009,
          0.9739400175064113,
          0.9741813339534435,
          0.9742756667463742,
          0.9741681712381508,
          0.9744906577628211,
          0.974527952122817,
          0.9740211875840494,
          0.9742932170334311,
          0.9741659774522687,
          0.9740211875840494,
          0.9735868179793916,
          0.9744840764051746,
          0.974231791028732,
          0.9740826135887485,
          0.9747604934263207,
          0.9743239300357807,
          0.9748021753580807,
          0.9741308768781549,
          0.974409487685183,
          0.9738061965676026,
          0.9736657942711475,
          0.9735275857605746,
          0.9742098531699109,
          0.9742098531699109,
          0.9744138752569472,
          0.9735977869088022,
          0.9737798711370172,
          0.9739992497252283,
          0.9730559217959208,
          0.973733801633493,
          0.9729901082194575,
          0.9738829790734764,
          0.973435446753526,
          0.9739816994381715,
          0.973795227638192,
          0.97359559312292,
          0.9738807852875944,
          0.9742449537440246,
          0.9740233813699315,
          0.9742098531699109,
          0.9739685367228788,
          0.973852266071127,
          0.9738105841393668,
          0.974648610346333,
          0.9738807852875944,
          0.9744467820451789,
          0.9736636004852655,
          0.9741001638758054,
          0.9744226504004756,
          0.974051900586399,
          0.9739465988640577,
          0.9740694508734559,
          0.9744950453345853,
          0.9743414803228375,
          0.9739707305087609,
          0.973852266071127,
          0.9741221017346265,
          0.9745476961957559,
          0.9743151548922522,
          0.974648610346333,
          0.9741462333793297,
          0.9738412971417164,
          0.9735012603299893,
          0.9740628695158096,
          0.974549889981638,
          0.9744402006875325,
          0.9742164345275572,
          0.9737359954193751,
          0.9740628695158096,
          0.9734486094688186,
          0.9742098531699109,
          0.9747012612075037,
          0.9746398352028045,
          0.9743721933251871,
          0.9747144239227963,
          0.9741001638758054,
          0.97335647046177,
          0.9734880976146966,
          0.9748416635039587,
          0.9748833454357188,
          0.9747912064286701,
          0.9732796879558961,
          0.9738369095699522,
          0.9745060142639959,
          0.9748745702921904,
          0.9743063797487238,
          0.9740409316569885,
          0.9738566536428912,
          0.9739882807958178,
          0.9741901090969719,
          0.9738127779252489,
          0.973058115581803,
          0.9740365440852242,
          0.9740233813699315,
          0.9743173486781344,
          0.9742252096710857,
          0.9742603102451994,
          0.973277494170014,
          0.9739400175064113,
          0.9743831622545976,
          0.974150620951094,
          0.9743261238216627,
          0.9752387387486207,
          0.9745038204781137,
          0.9742361786004963,
          0.9737908400664278,
          0.9744007125416545,
          0.974628866273394,
          0.9742800543181385,
          0.9743085735346059,
          0.9745827967698697,
          0.9741769463816793,
          0.9752080257462711,
          0.9741879153110898,
          0.9746946798498572,
          0.9741813339534435,
          0.9735385546899852,
          0.9743480616804838,
          0.9736175309817411,
          0.9743173486781344,
          0.9748021753580807,
          0.9741045514475696,
          0.9747231990663248,
          0.9739027231464155,
          0.9747626872122027,
          0.9749228335815968,
          0.9748197256451376,
          0.974111132805216,
          0.9741199079487444,
          0.9745060142639959,
          0.9746902922780931,
          0.9735144230452819,
          0.9746266724875119,
          0.9741089390193338,
          0.9739378237205293,
          0.9750040036592349,
          0.9741089390193338,
          0.9744643323322357,
          0.9748153380733734,
          0.9745345334804633,
          0.9747626872122027,
          0.9730800534406241,
          0.9745016266922316,
          0.9749184460098326,
          0.9746946798498572,
          0.9744731074757641,
          0.9744643323322357,
          0.9746617730616256,
          0.9747977877863164,
          0.9736263061252696,
          0.9742230158852035,
          0.9748526324333693,
          0.9750588483062876,
          0.9753352653274335,
          0.9749359962968894,
          0.9739707305087609,
          0.9736284999111516,
          0.9745564713392844,
          0.9744029063275366,
          0.9739378237205293,
          0.9744774950475283,
          0.9732665252406034,
          0.9739773118664072,
          0.9733060133864815,
          0.9743085735346059,
          0.9738105841393668,
          0.9750720110215803,
          0.9749710968710033,
          0.9752870020380271,
          0.9752562890356775,
          0.9746157035581013,
          0.9746376414169224,
          0.9738610412146553,
          0.9745674402686949,
          0.9743283176075449,
          0.9746464165604508,
          0.9747780437133775,
          0.9746837109204467,
          0.9746398352028045,
          0.9737425767770214,
          0.9746464165604508,
          0.9746157035581013,
          0.9733740207488268,
          0.9743370927510733,
          0.9747056487792678,
          0.9735977869088022,
          0.9747604934263207,
          0.9739860870099356,
          0.9740146062264031,
          0.9742778605322563,
          0.973435446753526,
          0.9730910223700346,
          0.9736657942711475,
          0.9731699986617907,
          0.9737272202758467,
          0.9739246610052366,
          0.974012412440521,
          0.9737294140617287,
          0.9736877321299686,
          0.9735473298335136,
          0.9740804198028664,
          0.9725710951159745,
          0.9735626863346883,
          0.972700528483019,
          0.9730405652947461,
          0.9735275857605746,
          0.9728870002829983,
          0.9737162513464361,
          0.9734551908264649,
          0.9725403821136249,
          0.9712943117325863,
          0.9733125947441278,
          0.9726281335489093,
          0.9736219185535053,
          0.9740694508734559,
          0.9737798711370172,
          0.9667992444601422,
          0.9718032700572359,
          0.9722157018030726,
          0.973038371508864,
          0.9736087558382127,
          0.9741155203769801,
          0.9739948621534641,
          0.9739795056522893,
          0.9736394688405622,
          0.9745871843416339,
          0.9745235645510527,
          0.9741615898805045,
          0.974589378127516,
          0.9748833454357188,
          0.9752562890356775,
          0.9748350821463123,
          0.9749359962968894,
          0.9748745702921904,
          0.9754734738380064,
          0.9752189946756816,
          0.9749601279415926,
          0.974468719904,
          0.9746880984922109,
          0.9749579341557105,
          0.974828500788666,
          0.9743853560404797,
          0.9746617730616256,
          0.9742010780263824,
          0.9757520846450345,
          0.975563419059173,
          0.9757806038615019,
          0.9756314264215185,
          0.9754186291909537,
          0.9758946807273716,
          0.9755941320615226,
          0.9757301467862134,
          0.9759166185861927,
          0.9755392874144698,
          0.9753221026121408,
          0.9752935833956734,
          0.975225576033328,
          0.9748657951486619,
          0.975324296398023,
          0.9759583005179528,
          0.9761974231791029,
          0.9760153389508878,
          0.9761579350332249,
          0.9755546439156445,
          0.974867988934544,
          0.9740475130146348,
          0.9752891958239092,
          0.9754317919062464,
          0.9758244795791441,
          0.9752036381745068,
          0.976002176235595,
          0.9756731083532785,
          0.9755743879885835,
          0.9752694517509702,
          0.9754274043344822,
          0.9757586660026808,
          0.9761469661038144
         ]
        },
        {
         "mode": "lines+markers",
         "name": "validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355
         ],
         "y": [
          0.9439645574674252,
          0.9523798554964334,
          0.9596818157387572,
          0.9615860072635692,
          0.9639662466695844,
          0.964634249341595,
          0.9655249195709427,
          0.9650795844562688,
          0.9662773823509088,
          0.9652868956303411,
          0.966507728099878,
          0.9629527253741199,
          0.9672064435384178,
          0.9674521456706516,
          0.9670452015141394,
          0.9678053424857378,
          0.9680203318514423,
          0.9667841429986409,
          0.9677823079108409,
          0.9692027733628176,
          0.96801265365981,
          0.9687420818648792,
          0.9686960127150853,
          0.9684656669661161,
          0.9700550526340036,
          0.9702009382750175,
          0.9686652999485561,
          0.9700780872089005,
          0.9699322015678867,
          0.968887967505893,
          0.9705618132817359,
          0.9691797387879206,
          0.9692949116624052,
          0.9685808398406007,
          0.969087600488333,
          0.9697248903938145,
          0.9696020393276975,
          0.9695022228364776,
          0.969939879759519,
          0.9698016723101375,
          0.9707460898809113,
          0.9701087999754298,
          0.9706309170064267,
          0.9707537680725435,
          0.9696557866691237,
          0.9703314675327667,
          0.9690184967636423,
          0.9701779037001206,
          0.969939879759519,
          0.9682813903669408,
          0.9698170286934021,
          0.9685731616489685,
          0.969863097843196,
          0.9697786377352406,
          0.9705925260482651,
          0.9701241563586944,
          0.9709610792466158,
          0.9708075154139697,
          0.970615560623162,
          0.9711453558457912,
          0.9711069648876297,
          0.9700320180591068,
          0.9708382281804989,
          0.9714294489361865,
          0.9715369436190389,
          0.9712451723370112,
          0.9716290819186265,
          0.9710301829713066,
          0.9711299994625265,
          0.970239329233179,
          0.9698707760348283,
          0.9710301829713066,
          0.9710839303127328,
          0.9704312840239867,
          0.9705618132817359,
          0.9718594276675957,
          0.9718363930926988,
          0.9711299994625265,
          0.971590690960465,
          0.9709226882884543,
          0.9715983691520973,
          0.9718440712843311,
          0.9718440712843311,
          0.971467839894348,
          0.9714448053194512,
          0.9717749675596403,
          0.9708305499888666,
          0.9713680234031281,
          0.9710301829713066,
          0.9715369436190389,
          0.9711607122290559,
          0.9711914249955851,
          0.9711607122290559,
          0.9720129915002419,
          0.9720437042667711,
          0.9714140925529219,
          0.9717135420265819,
          0.9671450180053593,
          0.9708689409470281,
          0.9711376776541589,
          0.971667472876788,
          0.9716214037269942,
          0.9703545021076636,
          0.9698247068850344,
          0.9710225047796743,
          0.9705925260482651,
          0.9695559701779037,
          0.9688265419728346,
          0.9699859489093129,
          0.9702853983829729,
          0.9712528505286435,
          0.9716751510684204,
          0.969563648369536,
          0.9708689409470281,
          0.9709994702047774,
          0.9724583266149156,
          0.9711453558457912,
          0.9719131750090219,
          0.9712835632951727,
          0.9695406137946391,
          0.9719438877755511,
          0.9714755180859804,
          0.9711991031872174,
          0.9714294489361865,
          0.9713219542533342,
          0.9710762521211005,
          0.9721281643747265,
          0.9694868664532129,
          0.9692181297460822,
          0.9709994702047774,
          0.9710378611629389,
          0.970239329233179,
          0.9699552361427837,
          0.970815193605602,
          0.972466004806548,
          0.9710378611629389,
          0.9712605287202758,
          0.9699322015678867,
          0.9709764356298805,
          0.9702700419997082,
          0.9702853983829729,
          0.9693716935787283,
          0.9711760686123204,
          0.9710839303127328,
          0.9710992866959973,
          0.9703391457243989,
          0.9686422653736592,
          0.9709457228633512,
          0.9723277973571665,
          0.9707307334976466,
          0.9708766191386604,
          0.9714755180859804,
          0.9717212202182142,
          0.9701855818917529,
          0.9692181297460822,
          0.9705003877486774,
          0.9716597946851557,
          0.9720513824584034,
          0.9713219542533342,
          0.9705387787068389,
          0.9716367601102588,
          0.9710685739294681,
          0.9715062308525096,
          0.9709226882884543,
          0.9706693079645882,
          0.9712144595704819,
          0.9703468239160313,
          0.9714294489361865,
          0.9684579887744839,
          0.970738411689279,
          0.9715523000023034,
          0.9707844808390728,
          0.970915010096822,
          0.9709457228633512,
          0.9710071483964097,
          0.9710685739294681,
          0.9697248903938145,
          0.9716597946851557,
          0.9708766191386604,
          0.9716444383018912,
          0.9723892228902249,
          0.9710992866959973,
          0.9694791882615806,
          0.9694254409201545,
          0.9714601617027158,
          0.9707000207311174,
          0.9702470074248113,
          0.9712451723370112,
          0.9705234223235744,
          0.9716981856433173,
          0.9709917920131451,
          0.9709917920131451,
          0.9713833797863927,
          0.9694407973034191,
          0.9715523000023034,
          0.9707537680725435,
          0.9698938106097252,
          0.9712451723370112,
          0.9708996537135574,
          0.9720590606500357,
          0.9708689409470281,
          0.9707460898809113,
          0.970738411689279,
          0.9710685739294681,
          0.9717365766014788,
          0.970062730825636,
          0.9717519329847434,
          0.9719438877755511,
          0.9697248903938145,
          0.969064565913436,
          0.9712144595704819,
          0.9716981856433173,
          0.970715377114382,
          0.9694024063452575,
          0.9706846643478528,
          0.9715676563855681,
          0.9707460898809113,
          0.9713680234031281,
          0.9705694914733682,
          0.9716981856433173,
          0.9707076989227497,
          0.9714524835110835,
          0.9701471909335914,
          0.9700473744423713,
          0.9713296324449665,
          0.9706078824315297,
          0.9716751510684204,
          0.9708996537135574,
          0.9704312840239867,
          0.9718287149010665,
          0.9701011217837975,
          0.9703775366825605,
          0.9715676563855681,
          0.9693102680456699,
          0.9697479249687113,
          0.9697018558189175,
          0.9704927095570451,
          0.9710532175462036,
          0.9703545021076636,
          0.9701779037001206,
          0.9698323850766667,
          0.9699014888013575,
          0.9715139090441419,
          0.9715446218106711,
          0.9693409808121991,
          0.9716060473437296,
          0.971767289368008,
          0.971114643079262,
          0.9708459063721312,
          0.9693256244289346,
          0.9716597946851557,
          0.9718210367094342,
          0.9712758851035405,
          0.9690108185720099,
          0.971767289368008,
          0.9708766191386604,
          0.971291241486805,
          0.9712221377621143,
          0.9698477414599314,
          0.9680049754681778,
          0.9702162946582821,
          0.9713065978700697,
          0.9711530340374235,
          0.9707076989227497,
          0.9713219542533342,
          0.9702239728499144,
          0.9699475579511514,
          0.9702546856164436,
          0.9699322015678867,
          0.9707844808390728,
          0.9700089834842098,
          0.9711453558457912,
          0.9702777201913405,
          0.9715983691520973,
          0.970139512741959,
          0.9712144595704819,
          0.9698247068850344,
          0.971014826588042,
          0.9695406137946391,
          0.970815193605602,
          0.9709457228633512,
          0.9696327520942267,
          0.9708996537135574,
          0.96831210313347,
          0.9707460898809113,
          0.9710378611629389,
          0.970938044671719,
          0.9669069940647579,
          0.9684272760079546,
          0.9705541350901036,
          0.9692411643209792,
          0.9698170286934021,
          0.9707537680725435,
          0.9692795552791407,
          0.9664770153333487,
          0.9695022228364776,
          0.9686652999485561,
          0.9696327520942267,
          0.9703468239160313,
          0.9661238185182626,
          0.9705157441319421,
          0.9700013052925774,
          0.9703928930658251,
          0.9706846643478528,
          0.9691336696381269,
          0.9703775366825605,
          0.9707000207311174,
          0.9719822787337127,
          0.9712067813788496,
          0.9716444383018912,
          0.969064565913436,
          0.9714755180859804,
          0.9714831962776127,
          0.9711453558457912,
          0.9705387787068389,
          0.9706846643478528,
          0.9709073319051897,
          0.970438962215619,
          0.9699475579511514,
          0.9707998372223374,
          0.9708996537135574,
          0.9703314675327667,
          0.9719131750090219,
          0.9712221377621143,
          0.971291241486805,
          0.9718901404341249,
          0.9715062308525096,
          0.9712682069119081,
          0.9704927095570451,
          0.9715830127688326,
          0.9713680234031281,
          0.970615560623162,
          0.9707076989227497,
          0.9702086164666498,
          0.9710532175462036,
          0.9701164781670621,
          0.9713373106365989,
          0.9721588771412557,
          0.9720360260751388,
          0.9715369436190389,
          0.9711607122290559,
          0.9711991031872174,
          0.9691490260213914,
          0.9714294489361865,
          0.9713757015947604,
          0.9711991031872174,
          0.9725734994894003,
          0.9705848478566328,
          0.9716597946851557,
          0.972266371824108,
          0.9717980021345373,
          0.970615560623162,
          0.970738411689279,
          0.9716521164935235
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "epochs_range = list(range(1, len(Train_loss) + 1))\n",
    "\n",
    "fig_loss = go.Figure()\n",
    "\n",
    "\n",
    "fig_loss.add_trace(go.Scatter(x=epochs_range, y=Train_loss, mode='lines+markers', name='Train Loss'))\n",
    "fig_loss.add_trace(go.Scatter(x=epochs_range, y=Val_loss, mode='lines+markers', name='validation Loss'))\n",
    "fig_loss.show()\n",
    "\n",
    "fig_accuracy = go.Figure()\n",
    "\n",
    "\n",
    "fig_accuracy.add_trace(go.Scatter(x=epochs_range, y=Train_accuracy, mode='lines+markers', name='Train Loss'))\n",
    "fig_accuracy.add_trace(go.Scatter(x=epochs_range, y=Val_accuracy, mode='lines+markers', name='validation Loss'))\n",
    "fig_accuracy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79c5a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9724811498948079\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98     42840\n",
      "        True       0.96      0.96      0.96     22279\n",
      "\n",
      "    accuracy                           0.97     65119\n",
      "   macro avg       0.97      0.97      0.97     65119\n",
      "weighted avg       0.97      0.97      0.97     65119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred = model(X_test_tensor)\n",
    "\n",
    "# Evaluate model\n",
    "\n",
    "y_pred = y_pred.cpu()\n",
    "y_pred = [1 if o > z else 0 for z,o in y_pred]\n",
    "with torch.no_grad():\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa41e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "743699d0",
   "metadata": {},
   "source": [
    "# Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16226e0",
   "metadata": {},
   "source": [
    "### 🧮 Accuracy without Z-score Normalization (XGBoost)\n",
    "\n",
    "> **Accuracy:** `0.833455602268559`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:-----------|:--------|:----------|:----------|\n",
    "| **0** | 0.85 | 0.81 | 0.83 | 35239 |\n",
    "| **1** | 0.82 | 0.85 | 0.84 | 35643 |\n",
    "| **Accuracy** |  |  | **0.83** | 70882 |\n",
    "| **Macro Avg** | 0.83 | 0.83 | 0.83 | 70882 |\n",
    "| **Weighted Avg** | 0.83 | 0.83 | 0.83 | 70882 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 🧮 Accuracy without Z-score Normalization (RandomForest)\n",
    "\n",
    "> **Accuracy:** `0.8248920741514065`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:----------|:------|:---------|:--------|\n",
    "| **0** | 0.83      | 0.81  | 0.82     | 35239   |\n",
    "| **1** | 0.82      | 0.84  | 0.83     | 35643   |\n",
    "| **Accuracy** |           |        | **0.82** | 70882   |\n",
    "| **Macro Avg** | 0.83      | 0.82  | 0.82     | 70882   |\n",
    "| **Weighted Avg** | 0.83      | 0.82  | 0.82     | 70882   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e305635c",
   "metadata": {},
   "source": [
    "### 🧮 Accuracy with Z-score Normalization (FNN)\n",
    "\n",
    "> **Accuracy:** `0.8490589994638977`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:-----------|:--------|:----------|:----------|\n",
    "| **0** | 0.88 | 0.81 | 0.84 | 35239 |\n",
    "| **1** | 0.82 | 0.89 | 0.86 | 35643 |\n",
    "| **Accuracy** |  |  | **0.85** | 70882 |\n",
    "| **Macro Avg** | 0.85 | 0.85 | 0.85 | 70882 |\n",
    "| **Weighted Avg** | 0.85 | 0.85 | 0.85 | 70882 |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499323c6",
   "metadata": {},
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77197f5",
   "metadata": {},
   "source": [
    "### 🧮 Accuracy without Z-score Normalization (XGBoost)\n",
    "\n",
    "> **Accuracy:** `0.9694866321657274`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:-----------|:--------|:----------|:----------|\n",
    "| **0** | 0.97 | 0.99 | 0.98 | 35239 |\n",
    "| **1** | 0.97 | 0.94 | 0.95 | 35643 |\n",
    "| **Accuracy** |  |  | **0.97** | 70882 |\n",
    "| **Macro Avg** | 0.97 | 0.96 | 0.97 | 70882 |\n",
    "| **Weighted Avg** | 0.97 | 0.97 | 0.97 | 70882 |\n",
    "\n",
    "\n",
    "### 🧮 Accuracy without Z-score Normalization (RandomForest)\n",
    "\n",
    "> **Accuracy:** `0.973018627435925`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:----------|:------|:---------|:--------|\n",
    "| **0** | 0.97      | 0.98  | 0.98     | 35239   |\n",
    "| **1** | 0.97      | 0.95  | 0.96     | 35643   |\n",
    "| **Accuracy** |           |        | **0.97** | 70882   |\n",
    "| **Macro Avg** | 0.97      | 0.97  | 0.97     | 70882   |\n",
    "| **Weighted Avg** | 0.97      | 0.97  | 0.97     | 70882   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd31f56",
   "metadata": {},
   "source": [
    "### 🧮 Accuracy with Z-score Normalization (FNN)\n",
    "\n",
    "> **Accuracy:** `0.9724811498948079`\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|:------|:-----------|:--------|:----------|:----------|\n",
    "| **0** | 0.98 | 0.98 | 0.98 | 35239 |\n",
    "| **1** | 0.96 | 0.96 | 0.96 | 35643 |\n",
    "| **Accuracy** |  |  | **0.97** | 70882 |\n",
    "| **Macro Avg** | 0.97 | 0.97 | 0.97 | 70882 |\n",
    "| **Weighted Avg** | 0.97 | 0.97 | 0.97 | 70882 |\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
