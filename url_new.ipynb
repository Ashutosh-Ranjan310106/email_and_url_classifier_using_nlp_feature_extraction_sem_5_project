{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ce3641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.3.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.1.8)\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5926c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"kmack/Phishing_urls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9051b6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 567056\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 70882\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 70882\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e25757e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbdac877",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = ds['test'].to_pandas()\n",
    "valid_df = ds['valid'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa9ec70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0             xenophongroup.com/montjoie/compgns.htm      0\n",
      "1    www.azzali.eu/&usg=AOvVaw2phVSb_ENMrkATGNx5LQ0l      1\n",
      "2                     guildmusic.edu.au/js/index.htm      1\n",
      "3  memo.unexpectedrunner.com/ezxgytw4et\\nholotili...      1\n",
      "4  en.wikipedia.org/wiki/Category:American_televi...      0                                                 text  label\n",
      "0    www.linuxplanet.com/linuxplanet/reviews/4149/1/      1\n",
      "1  sdnmargorejo1-403.sch.id/images/login.alibaba....      1\n",
      "2  '9d345009-a-62cb3a1a-s-sites.googlegroups.com/...      0\n",
      "3            everyculture.com/Ma-Ni/New-Zealand.html      0\n",
      "4                    www.aoseocn.acseosn.selfie.ltd/      1                                                 text  label\n",
      "0       absoluteastronomy.com/topics/Sri_Lankan_Navy      0\n",
      "1                    www.angelfire.com/amiga/grotto/      1\n",
      "2  www.etc-meisai.jp.lmxnzp.shop/kaduxn.php?lia71...      1\n",
      "3  http://torcache.net/torrent/DCA42EC92836BAC652...      0\n",
      "4                                shanghaitaihong.cn/      1\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head(),test_df.head(),valid_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b58e2f",
   "metadata": {},
   "source": [
    "verifying data leakage prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e52154f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test overlap: 0\n",
      "Train-Valid overlap: 0\n",
      "Test-Valid overlap: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming you have 'id' or can hash rows\n",
    "train_hashes = set(train_df.apply(lambda x: hash(tuple(x)), axis=1))\n",
    "test_hashes = set(test_df.apply(lambda x: hash(tuple(x)), axis=1))\n",
    "valid_hashes = set(valid_df.apply(lambda x: hash(tuple(x)), axis=1))\n",
    "\n",
    "print(\"Train-Test overlap:\", len(train_hashes & test_hashes))\n",
    "print(\"Train-Valid overlap:\", len(train_hashes & valid_hashes))\n",
    "print(\"Test-Valid overlap:\", len(test_hashes & valid_hashes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29cf1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset is : (567056, 2)\n",
      "No. of missing values : text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "Duplicate values in urls: 31218\n",
      "Number of unique values :  text     535838\n",
      "label         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the training dataset is :\",train_df.shape)\n",
    "print(\"No. of missing values :\",train_df.isnull().sum())\n",
    "print(\"Duplicate values in urls:\",train_df[\"text\"].duplicated().sum())\n",
    "print(\"Number of unique values : \",train_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ede455b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates(subset = \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a001f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate values in urls: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate values in urls:\",train_df[\"text\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88c061",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dd3ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_url(url):\n",
    "    url = url.lower().strip()\n",
    "\n",
    "    # Remove protocol but keep subdomains\n",
    "    url = re.sub(r'^https?://', '', url)\n",
    "\n",
    "    # Remove trailing slashes and fragments (#, etc.)\n",
    "    url = re.sub(r'[#]+.*', '', url)\n",
    "    \n",
    "    # Remove common tracking parameters (optional)\n",
    "    url = re.sub(r'(\\?|&)(utm_[^=]+|fbclid|gclid)=[^&]+', '', url)\n",
    "\n",
    "    # Remove non-useful symbols, but keep . / ? = _ - &\n",
    "    url = re.sub(r'[^a-z0-9./?=&_-]', '', url)\n",
    "\n",
    "    # Replace multiple slashes with one (to avoid //)\n",
    "    url = re.sub(r'/+', '/', url)\n",
    "\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5bb815e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].apply(clean_url)\n",
    "valid_df['text'] = valid_df['text'].apply(clean_url)\n",
    "test_df['text'] = test_df['text'].apply(clean_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8bb02a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535838, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3113487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(9575)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da652bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535838,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "461f2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates(subset = \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd25603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ade6d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    525364.000000\n",
      "mean         46.736122\n",
      "std          46.452726\n",
      "min           0.000000\n",
      "25%          21.000000\n",
      "50%          34.000000\n",
      "75%          56.000000\n",
      "max        2307.000000\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "url_lengths = train_df['text'].apply(len)\n",
    "print(url_lengths.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbeeebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen maxlen: 182\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "maxlen = int(np.percentile(url_lengths, 98))\n",
    "print(\"Chosen maxlen:\", maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27340518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/332.0 MB 6.3 MB/s eta 0:00:53\n",
      "    --------------------------------------- 5.0/332.0 MB 12.4 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 8.4/332.0 MB 13.5 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 12.6/332.0 MB 15.3 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 17.0/332.0 MB 16.5 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 22.3/332.0 MB 17.7 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 27.0/332.0 MB 18.5 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 32.0/332.0 MB 19.2 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 37.0/332.0 MB 19.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 44.3/332.0 MB 21.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 50.6/332.0 MB 21.9 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 55.6/332.0 MB 22.1 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 60.0/332.0 MB 22.1 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 65.0/332.0 MB 22.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 70.5/332.0 MB 22.4 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 76.0/332.0 MB 22.6 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 81.0/332.0 MB 22.6 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 86.2/332.0 MB 22.7 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 92.5/332.0 MB 23.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 98.8/332.0 MB 23.4 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 105.1/332.0 MB 23.6 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 110.4/332.0 MB 23.7 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 114.3/332.0 MB 23.5 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 119.8/332.0 MB 23.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 126.1/332.0 MB 23.8 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 132.1/332.0 MB 24.0 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 139.2/332.0 MB 24.3 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 146.5/332.0 MB 24.6 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 154.1/332.0 MB 25.0 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 160.2/332.0 MB 25.3 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 165.7/332.0 MB 25.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 172.5/332.0 MB 25.3 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 179.0/332.0 MB 25.5 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 186.1/332.0 MB 25.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 192.9/332.0 MB 25.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 200.3/332.0 MB 26.1 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 207.9/332.0 MB 26.4 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 215.5/332.0 MB 26.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 222.6/332.0 MB 26.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 228.9/332.0 MB 26.8 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 236.2/332.0 MB 27.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 242.0/332.0 MB 27.0 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 248.5/332.0 MB 27.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 253.8/332.0 MB 27.0 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 257.7/332.0 MB 26.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 262.7/332.0 MB 26.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 267.9/332.0 MB 27.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 273.2/332.0 MB 27.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 278.7/332.0 MB 27.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 283.9/332.0 MB 27.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 288.4/332.0 MB 27.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 295.7/332.0 MB 27.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 301.2/332.0 MB 27.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 307.2/332.0 MB 27.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 313.3/332.0 MB 27.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 319.6/332.0 MB 27.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 323.5/332.0 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  329.5/332.0 MB 27.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 27.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 27.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 27.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 27.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 332.0/332.0 MB 25.7 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.7/4.7 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl (208 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 5.2/5.5 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 6.0/26.4 MB 27.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 25.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.0/26.4 MB 26.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.0/26.4 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-win_amd64.whl (316 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   ---------- -----------------------------  4/16 [tensorboard-data-server]\n",
      "   ------------ ---------------------------  5/16 [optree]\n",
      "   --------------- ------------------------  6/16 [opt_einsum]\n",
      "   ----------------- ----------------------  7/16 [ml_dtypes]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   ---------------------- -----------------  9/16 [google_pasta]\n",
      "   --------------------------- ------------ 11/16 [astunparse]\n",
      "   ------------------------------ --------- 12/16 [absl-py]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ---------------------------------------- 16/16 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 keras-3.12.0 libclang-18.1.1 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c85f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Build a character-level tokenizer\n",
    "tokenizer = Tokenizer(char_level=True, lower=True, filters='')  # keep special chars\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "\n",
    "# Convert to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
    "X_val_seq   = tokenizer.texts_to_sequences(valid_df['text'])\n",
    "X_test_seq  = tokenizer.texts_to_sequences(test_df['text'])\n",
    "\n",
    "# Padding to a fixed length\n",
    "maxlen = maxlen  # adjust based on URL length distribution\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post')\n",
    "X_val_pad   = pad_sequences(X_val_seq, maxlen=maxlen, padding='post')\n",
    "X_test_pad  = pad_sequences(X_test_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "# Labels\n",
    "y_train = train_df['label'].values\n",
    "y_val   = valid_df['label'].values\n",
    "y_test  = test_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8878a437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 44\n",
      "Sample tokens: ['e', 'o', 'a', 'c', '.', 'i', 't', 's', 'n', '/', 'r', 'm', 'l', 'd', 'p', 'w', '-', 'u', 'h', 'b', 'g', 'f', '1', '0', '2', 'y', 'k', '3', '8', 'v', '5', '4', '9', '6', '7', 'x', 'j', '_', '=', 'z', 'q', '?', '&']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size:\", len(tokenizer.word_index) + 1)\n",
    "print(\"Sample tokens:\", list(tokenizer.word_index.keys())[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb47260e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xenophongroup.com/montjoie/compgns.htm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.azzali.eu/&amp;usg=aovvaw2phvsb_enmrkatgnx5lq0l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guildmusic.edu.au/js/index.htm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>memo.unexpectedrunner.com/ezxgytw4etnholotilic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en.wikipedia.org/wiki/categoryamerican_televis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567049</th>\n",
       "      <td>ucdavisaggies.com/sports/m-footbl/mtt/allen_dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567050</th>\n",
       "      <td>www.aoscuu-smaocmeouusnauu.fhoarcu.museum.mw/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567051</th>\n",
       "      <td>www.en.wikipedia.org/wiki/charles_taylor_philo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567054</th>\n",
       "      <td>revenue.ky.gov</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567055</th>\n",
       "      <td>www.minutiaesoftware.com/reunion.htm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525364 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0                  xenophongroup.com/montjoie/compgns.htm      0\n",
       "1         www.azzali.eu/&usg=aovvaw2phvsb_enmrkatgnx5lq0l      1\n",
       "2                          guildmusic.edu.au/js/index.htm      1\n",
       "3       memo.unexpectedrunner.com/ezxgytw4etnholotilic...      1\n",
       "4       en.wikipedia.org/wiki/categoryamerican_televis...      0\n",
       "...                                                   ...    ...\n",
       "567049  ucdavisaggies.com/sports/m-footbl/mtt/allen_dr...      0\n",
       "567050      www.aoscuu-smaocmeouusnauu.fhoarcu.museum.mw/      1\n",
       "567051  www.en.wikipedia.org/wiki/charles_taylor_philo...      0\n",
       "567054                                     revenue.ky.gov      0\n",
       "567055               www.minutiaesoftware.com/reunion.htm      1\n",
       "\n",
       "[525364 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5003ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525364, 182)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "335c9d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading xgboost-3.1.1-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.1.1-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 4.2/72.0 MB 20.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 10.2/72.0 MB 27.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 17.0/72.0 MB 27.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 24.9/72.0 MB 30.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 33.0/72.0 MB 31.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 40.6/72.0 MB 32.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 49.5/72.0 MB 33.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 58.7/72.0 MB 34.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 67.6/72.0 MB 35.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 36.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 33.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1eff4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Concatenate, \\\n",
    "                                     BatchNormalization, ReLU, Bidirectional, LSTM, Dense, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a4eb6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your values\n",
    "vocab_size = 44         # given\n",
    "maxlen = 182            # given\n",
    "\n",
    "# Model hyperparams (sensible defaults for URL data)\n",
    "embedding_dim = 100      # smaller -> faster; increase to 100-200 if GPU and memory allow\n",
    "conv_filters = 128\n",
    "conv_kernel_sizes = [3,5,7]   # parallel convs capture tri/5/7-gram char patterns\n",
    "pool_size = 2\n",
    "bilstm_units = 128\n",
    "dense_proj_units = 128   # final neural feature dimension to feed XGBoost\n",
    "\n",
    "# Federated training hyperparams\n",
    "num_clients = 10\n",
    "federated_rounds = 5\n",
    "local_epochs = 1        # keep small for FL experiments; increase later\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f00e55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_bilstm_extractor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cnn_bilstm_extractor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input_ids            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " embedding            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">4,400</span>  input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "\n",
       " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">64,128</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "\n",
       " conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">89,728</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "\n",
       " batch_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " max_pooling1d        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " max_pooling1d_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " max_pooling1d_2      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                     max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " bidirectional        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span>  re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " dense_proj (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_ids            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " embedding            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m4,400\u001b[0m  input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " conv1d (\u001b[38;5;33mConv1D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m38,528\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "\n",
       " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m64,128\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "\n",
       " conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m89,728\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "\n",
       " batch_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu (\u001b[38;5;33mReLU\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " max_pooling1d        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m0\u001b[0m  re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " max_pooling1d_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m0\u001b[0m  re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " max_pooling1d_2      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m0\u001b[0m  re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m384\u001b[0m)             \u001b[38;5;34m0\u001b[0m  max_pooling1d[\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       max_pooling1d_1[\u001b[38;5;34m\u001b[0m \n",
       "                                                     max_pooling1d_2[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m147,584\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m512\u001b[0m  conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " bidirectional        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m263,168\u001b[0m  re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " dense_proj (\u001b[38;5;33mDense\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m32,896\u001b[0m  bidirectional[\u001b[38;5;34m0\u001b[0m] \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">642,480</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m642,480\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641,456</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m641,456\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_feature_extractor(vocab_size, maxlen,\n",
    "                            embedding_dim=64,\n",
    "                            conv_filters=128,\n",
    "                            conv_kernel_sizes=[3,5,7],\n",
    "                            pool_size=2,\n",
    "                            bilstm_units=128,\n",
    "                            dense_proj_units=128):\n",
    "    inp = Input(shape=(maxlen,), dtype='int32', name='input_ids')\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "                  input_length=maxlen, mask_zero=False, name='embedding')(inp)\n",
    "    # Parallel convs\n",
    "    convs = []\n",
    "    for k in conv_kernel_sizes:\n",
    "        c = Conv1D(filters=conv_filters, kernel_size=k, padding='same')(x)\n",
    "        c = BatchNormalization()(c)\n",
    "        c = ReLU()(c)\n",
    "        c = MaxPooling1D(pool_size=pool_size)(c)\n",
    "        convs.append(c)\n",
    "    x = Concatenate(axis=-1)(convs)  # shape: (batch, reduced_len, conv_filters*len(k))\n",
    "    # Optional extra conv to mix channels\n",
    "    x = Conv1D(filters=conv_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # BiLSTM for context; return_sequences=False to get a single vector per sample\n",
    "    x = Bidirectional(LSTM(bilstm_units, return_sequences=False))(x)\n",
    "\n",
    "    # Projection / fusion: compact vector for XGBoost. No final activation here.\n",
    "    x = Dense(dense_proj_units, activation='relu', name='dense_proj')(x)\n",
    "    # Note: don't apply dropout here because we want deterministic features for XGBoost\n",
    "    model = Model(inputs=inp, outputs=x, name='cnn_bilstm_extractor')\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "feature_extractor = build_feature_extractor(vocab_size=vocab_size,\n",
    "                                            maxlen=maxlen,\n",
    "                                            embedding_dim=embedding_dim,\n",
    "                                            conv_filters=conv_filters,\n",
    "                                            conv_kernel_sizes=conv_kernel_sizes,\n",
    "                                            pool_size=pool_size,\n",
    "                                            bilstm_units=bilstm_units,\n",
    "                                            dense_proj_units=dense_proj_units)\n",
    "feature_extractor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6a5642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_local_model(model, lr=1e-3):\n",
    "    # Local training uses a temporary head for supervised training.\n",
    "    # We'll attach a tiny classifier head for local training (binary classification),\n",
    "    # then remove it for feature extraction.\n",
    "    inp = model.input\n",
    "    features = model.output\n",
    "    out = Dense(1, activation='sigmoid', name='tmp_output')(features)\n",
    "    train_model = Model(inputs=inp, outputs=out)\n",
    "    train_model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return train_model\n",
    "\n",
    "def get_model_weights(model):\n",
    "    return model.get_weights()\n",
    "\n",
    "def set_model_weights(model, weights):\n",
    "    model.set_weights(weights)\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    # simple element-wise average\n",
    "    avg = []\n",
    "    for weights in zip(*weight_list):\n",
    "        avg.append(np.mean(weights, axis=0))\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2bb5e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clients(X, y, num_clients):\n",
    "    # simple IID split\n",
    "    n = X.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    splits = np.array_split(indices, num_clients)\n",
    "    clients = [(X[s], y[s]) for s in splits]\n",
    "    return clients\n",
    "\n",
    "def federated_train(global_model, X_train, y_train,\n",
    "                    num_clients=10,\n",
    "                    rounds=5,\n",
    "                    local_epochs=1,\n",
    "                    batch_size=256,\n",
    "                    lr=1e-3):\n",
    "    # compile a local copy model with a temporary classifier head\n",
    "    clients = make_clients(X_train, y_train, num_clients)\n",
    "    # We'll hold global weights\n",
    "    global_weights = get_model_weights(global_model)\n",
    "    for r in range(rounds):\n",
    "        print(f\"\\n=== Federated round {r+1}/{rounds} ===\")\n",
    "        local_weights = []\n",
    "        for i, (X_c, y_c) in enumerate(clients):\n",
    "            # create a fresh local train model from global extractor\n",
    "            local_extractor = build_feature_extractor(vocab_size, maxlen,\n",
    "                                                      embedding_dim, conv_filters,\n",
    "                                                      conv_kernel_sizes, pool_size,\n",
    "                                                      bilstm_units, dense_proj_units)\n",
    "            # set global weights into local extractor\n",
    "            set_model_weights(local_extractor, global_weights)\n",
    "            # attach tiny head and compile\n",
    "            local_train_model = compile_local_model(local_extractor, lr=lr)\n",
    "            print(f\" Client {i+1}: training on {X_c.shape[0]} samples\")\n",
    "            # Local training (small epochs)\n",
    "            local_train_model.fit(X_c, y_c, epochs=local_epochs, batch_size=batch_size, verbose=1)\n",
    "            # Extract updated extractor weights (strip off the tmp head)\n",
    "            local_weights.append(get_model_weights(local_extractor))\n",
    "            tf.keras.backend.clear_session()\n",
    "        # Aggregate weights via FedAvg\n",
    "        global_weights = average_weights(local_weights)\n",
    "        # Set new global weights\n",
    "        set_model_weights(global_model, global_weights)\n",
    "        print(\" Aggregated global weights updated.\")\n",
    "    return global_model\n",
    "\n",
    "# Example usage:\n",
    "# global_extractor = build_feature_extractor(...)\n",
    "# trained_global_extractor = federated_train(global_extractor, X_train, y_train, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d360b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 'trained_global_extractor' is the returned model from federated_train\n",
    "# or you can skip federated and just use the initial feature_extractor\n",
    "\n",
    "def extract_features(extractor_model, X):\n",
    "    # extractor_model outputs the dense feature vector (dense_proj)\n",
    "    features = extractor_model.predict(X, batch_size=512, verbose=1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "450c1202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Federated round 1/3 ===\n",
      " Client 1: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 821ms/step - accuracy: 0.8408 - loss: 0.3612\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      " Client 2: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 890ms/step - accuracy: 0.8364 - loss: 0.3689\n",
      " Client 3: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 875ms/step - accuracy: 0.8421 - loss: 0.3572\n",
      " Client 4: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 768ms/step - accuracy: 0.8365 - loss: 0.3643\n",
      " Client 5: training on 105072 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 887ms/step - accuracy: 0.8406 - loss: 0.3594\n",
      " Aggregated global weights updated.\n",
      "\n",
      "=== Federated round 2/3 ===\n",
      " Client 1: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 916ms/step - accuracy: 0.8703 - loss: 0.3115\n",
      " Client 2: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 858ms/step - accuracy: 0.8694 - loss: 0.3131\n",
      " Client 3: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 943ms/step - accuracy: 0.8684 - loss: 0.3123\n",
      " Client 4: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 898ms/step - accuracy: 0.8685 - loss: 0.3117\n",
      " Client 5: training on 105072 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 850ms/step - accuracy: 0.8706 - loss: 0.3083\n",
      " Aggregated global weights updated.\n",
      "\n",
      "=== Federated round 3/3 ===\n",
      " Client 1: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 918ms/step - accuracy: 0.8825 - loss: 0.2844\n",
      " Client 2: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 899ms/step - accuracy: 0.8788 - loss: 0.2915\n",
      " Client 3: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 854ms/step - accuracy: 0.8811 - loss: 0.2861\n",
      " Client 4: training on 105073 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 939ms/step - accuracy: 0.8830 - loss: 0.2851\n",
      " Client 5: training on 105072 samples\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 913ms/step - accuracy: 0.8848 - loss: 0.2800\n",
      " Aggregated global weights updated.\n"
     ]
    }
   ],
   "source": [
    "# Run federated training\n",
    "trained_global_extractor = federated_train(\n",
    "    global_model=feature_extractor,\n",
    "    X_train=X_train_pad,\n",
    "    y_train=y_train,\n",
    "    num_clients=5,        # you can reduce to 5 to test faster\n",
    "    rounds=3,              # start small; increase later\n",
    "    local_epochs=1,\n",
    "    batch_size=256,\n",
    "    lr=1e-3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eac1c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1027/1027\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 539ms/step\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 460ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "X_train_feats = extract_features(trained_global_extractor, X_train_pad)\n",
    "X_val_feats   = extract_features(trained_global_extractor, X_val_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b9824d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "pip install -U xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc858342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [03:52:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.66139\n",
      "[1]\tvalidation_0-logloss:0.63257\n",
      "[2]\tvalidation_0-logloss:0.60648\n",
      "[3]\tvalidation_0-logloss:0.58271\n",
      "[4]\tvalidation_0-logloss:0.56102\n",
      "[5]\tvalidation_0-logloss:0.54117\n",
      "[6]\tvalidation_0-logloss:0.52298\n",
      "[7]\tvalidation_0-logloss:0.50624\n",
      "[8]\tvalidation_0-logloss:0.49085\n",
      "[9]\tvalidation_0-logloss:0.47666\n",
      "[10]\tvalidation_0-logloss:0.46357\n",
      "[11]\tvalidation_0-logloss:0.45144\n",
      "[12]\tvalidation_0-logloss:0.44022\n",
      "[13]\tvalidation_0-logloss:0.42981\n",
      "[14]\tvalidation_0-logloss:0.42017\n",
      "[15]\tvalidation_0-logloss:0.41122\n",
      "[16]\tvalidation_0-logloss:0.40291\n",
      "[17]\tvalidation_0-logloss:0.39517\n",
      "[18]\tvalidation_0-logloss:0.38798\n",
      "[19]\tvalidation_0-logloss:0.38127\n",
      "[20]\tvalidation_0-logloss:0.37504\n",
      "[21]\tvalidation_0-logloss:0.36923\n",
      "[22]\tvalidation_0-logloss:0.36384\n",
      "[23]\tvalidation_0-logloss:0.35881\n",
      "[24]\tvalidation_0-logloss:0.35409\n",
      "[25]\tvalidation_0-logloss:0.34971\n",
      "[26]\tvalidation_0-logloss:0.34560\n",
      "[27]\tvalidation_0-logloss:0.34176\n",
      "[28]\tvalidation_0-logloss:0.33819\n",
      "[29]\tvalidation_0-logloss:0.33487\n",
      "[30]\tvalidation_0-logloss:0.33176\n",
      "[31]\tvalidation_0-logloss:0.32883\n",
      "[32]\tvalidation_0-logloss:0.32610\n",
      "[33]\tvalidation_0-logloss:0.32355\n",
      "[34]\tvalidation_0-logloss:0.32119\n",
      "[35]\tvalidation_0-logloss:0.31894\n",
      "[36]\tvalidation_0-logloss:0.31684\n",
      "[37]\tvalidation_0-logloss:0.31489\n",
      "[38]\tvalidation_0-logloss:0.31307\n",
      "[39]\tvalidation_0-logloss:0.31138\n",
      "[40]\tvalidation_0-logloss:0.30978\n",
      "[41]\tvalidation_0-logloss:0.30827\n",
      "[42]\tvalidation_0-logloss:0.30687\n",
      "[43]\tvalidation_0-logloss:0.30555\n",
      "[44]\tvalidation_0-logloss:0.30431\n",
      "[45]\tvalidation_0-logloss:0.30315\n",
      "[46]\tvalidation_0-logloss:0.30207\n",
      "[47]\tvalidation_0-logloss:0.30106\n",
      "[48]\tvalidation_0-logloss:0.30009\n",
      "[49]\tvalidation_0-logloss:0.29920\n",
      "[50]\tvalidation_0-logloss:0.29836\n",
      "[51]\tvalidation_0-logloss:0.29758\n",
      "[52]\tvalidation_0-logloss:0.29684\n",
      "[53]\tvalidation_0-logloss:0.29617\n",
      "[54]\tvalidation_0-logloss:0.29551\n",
      "[55]\tvalidation_0-logloss:0.29491\n",
      "[56]\tvalidation_0-logloss:0.29434\n",
      "[57]\tvalidation_0-logloss:0.29383\n",
      "[58]\tvalidation_0-logloss:0.29335\n",
      "[59]\tvalidation_0-logloss:0.29289\n",
      "[60]\tvalidation_0-logloss:0.29248\n",
      "[61]\tvalidation_0-logloss:0.29205\n",
      "[62]\tvalidation_0-logloss:0.29167\n",
      "[63]\tvalidation_0-logloss:0.29131\n",
      "[64]\tvalidation_0-logloss:0.29096\n",
      "[65]\tvalidation_0-logloss:0.29066\n",
      "[66]\tvalidation_0-logloss:0.29035\n",
      "[67]\tvalidation_0-logloss:0.29007\n",
      "[68]\tvalidation_0-logloss:0.28982\n",
      "[69]\tvalidation_0-logloss:0.28956\n",
      "[70]\tvalidation_0-logloss:0.28934\n",
      "[71]\tvalidation_0-logloss:0.28912\n",
      "[72]\tvalidation_0-logloss:0.28892\n",
      "[73]\tvalidation_0-logloss:0.28873\n",
      "[74]\tvalidation_0-logloss:0.28855\n",
      "[75]\tvalidation_0-logloss:0.28839\n",
      "[76]\tvalidation_0-logloss:0.28823\n",
      "[77]\tvalidation_0-logloss:0.28808\n",
      "[78]\tvalidation_0-logloss:0.28794\n",
      "[79]\tvalidation_0-logloss:0.28783\n",
      "[80]\tvalidation_0-logloss:0.28771\n",
      "[81]\tvalidation_0-logloss:0.28758\n",
      "[82]\tvalidation_0-logloss:0.28747\n",
      "[83]\tvalidation_0-logloss:0.28737\n",
      "[84]\tvalidation_0-logloss:0.28726\n",
      "[85]\tvalidation_0-logloss:0.28715\n",
      "[86]\tvalidation_0-logloss:0.28707\n",
      "[87]\tvalidation_0-logloss:0.28699\n",
      "[88]\tvalidation_0-logloss:0.28689\n",
      "[89]\tvalidation_0-logloss:0.28681\n",
      "[90]\tvalidation_0-logloss:0.28674\n",
      "[91]\tvalidation_0-logloss:0.28668\n",
      "[92]\tvalidation_0-logloss:0.28662\n",
      "[93]\tvalidation_0-logloss:0.28657\n",
      "[94]\tvalidation_0-logloss:0.28652\n",
      "[95]\tvalidation_0-logloss:0.28649\n",
      "[96]\tvalidation_0-logloss:0.28645\n",
      "[97]\tvalidation_0-logloss:0.28641\n",
      "[98]\tvalidation_0-logloss:0.28637\n",
      "[99]\tvalidation_0-logloss:0.28632\n",
      "[100]\tvalidation_0-logloss:0.28629\n",
      "[101]\tvalidation_0-logloss:0.28625\n",
      "[102]\tvalidation_0-logloss:0.28621\n",
      "[103]\tvalidation_0-logloss:0.28618\n",
      "[104]\tvalidation_0-logloss:0.28614\n",
      "[105]\tvalidation_0-logloss:0.28612\n",
      "[106]\tvalidation_0-logloss:0.28610\n",
      "[107]\tvalidation_0-logloss:0.28608\n",
      "[108]\tvalidation_0-logloss:0.28605\n",
      "[109]\tvalidation_0-logloss:0.28603\n",
      "[110]\tvalidation_0-logloss:0.28599\n",
      "[111]\tvalidation_0-logloss:0.28597\n",
      "[112]\tvalidation_0-logloss:0.28595\n",
      "[113]\tvalidation_0-logloss:0.28592\n",
      "[114]\tvalidation_0-logloss:0.28591\n",
      "[115]\tvalidation_0-logloss:0.28588\n",
      "[116]\tvalidation_0-logloss:0.28586\n",
      "[117]\tvalidation_0-logloss:0.28583\n",
      "[118]\tvalidation_0-logloss:0.28581\n",
      "[119]\tvalidation_0-logloss:0.28578\n",
      "[120]\tvalidation_0-logloss:0.28576\n",
      "[121]\tvalidation_0-logloss:0.28574\n",
      "[122]\tvalidation_0-logloss:0.28572\n",
      "[123]\tvalidation_0-logloss:0.28569\n",
      "[124]\tvalidation_0-logloss:0.28568\n",
      "[125]\tvalidation_0-logloss:0.28566\n",
      "[126]\tvalidation_0-logloss:0.28565\n",
      "[127]\tvalidation_0-logloss:0.28564\n",
      "[128]\tvalidation_0-logloss:0.28561\n",
      "[129]\tvalidation_0-logloss:0.28559\n",
      "[130]\tvalidation_0-logloss:0.28557\n",
      "[131]\tvalidation_0-logloss:0.28556\n",
      "[132]\tvalidation_0-logloss:0.28555\n",
      "[133]\tvalidation_0-logloss:0.28555\n",
      "[134]\tvalidation_0-logloss:0.28552\n",
      "[135]\tvalidation_0-logloss:0.28552\n",
      "[136]\tvalidation_0-logloss:0.28550\n",
      "[137]\tvalidation_0-logloss:0.28549\n",
      "[138]\tvalidation_0-logloss:0.28547\n",
      "[139]\tvalidation_0-logloss:0.28545\n",
      "[140]\tvalidation_0-logloss:0.28545\n",
      "[141]\tvalidation_0-logloss:0.28544\n",
      "[142]\tvalidation_0-logloss:0.28542\n",
      "[143]\tvalidation_0-logloss:0.28539\n",
      "[144]\tvalidation_0-logloss:0.28537\n",
      "[145]\tvalidation_0-logloss:0.28536\n",
      "[146]\tvalidation_0-logloss:0.28533\n",
      "[147]\tvalidation_0-logloss:0.28530\n",
      "[148]\tvalidation_0-logloss:0.28529\n",
      "[149]\tvalidation_0-logloss:0.28527\n",
      "[150]\tvalidation_0-logloss:0.28525\n",
      "[151]\tvalidation_0-logloss:0.28523\n",
      "[152]\tvalidation_0-logloss:0.28524\n",
      "[153]\tvalidation_0-logloss:0.28523\n",
      "[154]\tvalidation_0-logloss:0.28522\n",
      "[155]\tvalidation_0-logloss:0.28521\n",
      "[156]\tvalidation_0-logloss:0.28517\n",
      "[157]\tvalidation_0-logloss:0.28517\n",
      "[158]\tvalidation_0-logloss:0.28516\n",
      "[159]\tvalidation_0-logloss:0.28513\n",
      "[160]\tvalidation_0-logloss:0.28511\n",
      "[161]\tvalidation_0-logloss:0.28510\n",
      "[162]\tvalidation_0-logloss:0.28510\n",
      "[163]\tvalidation_0-logloss:0.28508\n",
      "[164]\tvalidation_0-logloss:0.28505\n",
      "[165]\tvalidation_0-logloss:0.28504\n",
      "[166]\tvalidation_0-logloss:0.28502\n",
      "[167]\tvalidation_0-logloss:0.28501\n",
      "[168]\tvalidation_0-logloss:0.28500\n",
      "[169]\tvalidation_0-logloss:0.28499\n",
      "[170]\tvalidation_0-logloss:0.28498\n",
      "[171]\tvalidation_0-logloss:0.28495\n",
      "[172]\tvalidation_0-logloss:0.28495\n",
      "[173]\tvalidation_0-logloss:0.28494\n",
      "[174]\tvalidation_0-logloss:0.28490\n",
      "[175]\tvalidation_0-logloss:0.28491\n",
      "[176]\tvalidation_0-logloss:0.28490\n",
      "[177]\tvalidation_0-logloss:0.28488\n",
      "[178]\tvalidation_0-logloss:0.28485\n",
      "[179]\tvalidation_0-logloss:0.28484\n",
      "[180]\tvalidation_0-logloss:0.28481\n",
      "[181]\tvalidation_0-logloss:0.28478\n",
      "[182]\tvalidation_0-logloss:0.28477\n",
      "[183]\tvalidation_0-logloss:0.28475\n",
      "[184]\tvalidation_0-logloss:0.28475\n",
      "[185]\tvalidation_0-logloss:0.28474\n",
      "[186]\tvalidation_0-logloss:0.28473\n",
      "[187]\tvalidation_0-logloss:0.28472\n",
      "[188]\tvalidation_0-logloss:0.28469\n",
      "[189]\tvalidation_0-logloss:0.28468\n",
      "[190]\tvalidation_0-logloss:0.28468\n",
      "[191]\tvalidation_0-logloss:0.28467\n",
      "[192]\tvalidation_0-logloss:0.28465\n",
      "[193]\tvalidation_0-logloss:0.28463\n",
      "[194]\tvalidation_0-logloss:0.28460\n",
      "[195]\tvalidation_0-logloss:0.28459\n",
      "[196]\tvalidation_0-logloss:0.28459\n",
      "[197]\tvalidation_0-logloss:0.28458\n",
      "[198]\tvalidation_0-logloss:0.28456\n",
      "[199]\tvalidation_0-logloss:0.28456\n",
      "[200]\tvalidation_0-logloss:0.28453\n",
      "[201]\tvalidation_0-logloss:0.28451\n",
      "[202]\tvalidation_0-logloss:0.28451\n",
      "[203]\tvalidation_0-logloss:0.28451\n",
      "[204]\tvalidation_0-logloss:0.28451\n",
      "[205]\tvalidation_0-logloss:0.28451\n",
      "[206]\tvalidation_0-logloss:0.28449\n",
      "[207]\tvalidation_0-logloss:0.28448\n",
      "[208]\tvalidation_0-logloss:0.28446\n",
      "[209]\tvalidation_0-logloss:0.28447\n",
      "[210]\tvalidation_0-logloss:0.28446\n",
      "[211]\tvalidation_0-logloss:0.28445\n",
      "[212]\tvalidation_0-logloss:0.28442\n",
      "[213]\tvalidation_0-logloss:0.28442\n",
      "[214]\tvalidation_0-logloss:0.28441\n",
      "[215]\tvalidation_0-logloss:0.28438\n",
      "[216]\tvalidation_0-logloss:0.28436\n",
      "[217]\tvalidation_0-logloss:0.28434\n",
      "[218]\tvalidation_0-logloss:0.28434\n",
      "[219]\tvalidation_0-logloss:0.28432\n",
      "[220]\tvalidation_0-logloss:0.28431\n",
      "[221]\tvalidation_0-logloss:0.28430\n",
      "[222]\tvalidation_0-logloss:0.28429\n",
      "[223]\tvalidation_0-logloss:0.28427\n",
      "[224]\tvalidation_0-logloss:0.28427\n",
      "[225]\tvalidation_0-logloss:0.28426\n",
      "[226]\tvalidation_0-logloss:0.28425\n",
      "[227]\tvalidation_0-logloss:0.28423\n",
      "[228]\tvalidation_0-logloss:0.28423\n",
      "[229]\tvalidation_0-logloss:0.28422\n",
      "[230]\tvalidation_0-logloss:0.28420\n",
      "[231]\tvalidation_0-logloss:0.28419\n",
      "[232]\tvalidation_0-logloss:0.28418\n",
      "[233]\tvalidation_0-logloss:0.28417\n",
      "[234]\tvalidation_0-logloss:0.28417\n",
      "[235]\tvalidation_0-logloss:0.28416\n",
      "[236]\tvalidation_0-logloss:0.28415\n",
      "[237]\tvalidation_0-logloss:0.28414\n",
      "[238]\tvalidation_0-logloss:0.28414\n",
      "[239]\tvalidation_0-logloss:0.28412\n",
      "[240]\tvalidation_0-logloss:0.28412\n",
      "[241]\tvalidation_0-logloss:0.28411\n",
      "[242]\tvalidation_0-logloss:0.28411\n",
      "[243]\tvalidation_0-logloss:0.28406\n",
      "[244]\tvalidation_0-logloss:0.28405\n",
      "[245]\tvalidation_0-logloss:0.28406\n",
      "[246]\tvalidation_0-logloss:0.28405\n",
      "[247]\tvalidation_0-logloss:0.28405\n",
      "[248]\tvalidation_0-logloss:0.28403\n",
      "[249]\tvalidation_0-logloss:0.28402\n",
      "[250]\tvalidation_0-logloss:0.28401\n",
      "[251]\tvalidation_0-logloss:0.28400\n",
      "[252]\tvalidation_0-logloss:0.28399\n",
      "[253]\tvalidation_0-logloss:0.28398\n",
      "[254]\tvalidation_0-logloss:0.28397\n",
      "[255]\tvalidation_0-logloss:0.28396\n",
      "[256]\tvalidation_0-logloss:0.28394\n",
      "[257]\tvalidation_0-logloss:0.28393\n",
      "[258]\tvalidation_0-logloss:0.28391\n",
      "[259]\tvalidation_0-logloss:0.28390\n",
      "[260]\tvalidation_0-logloss:0.28389\n",
      "[261]\tvalidation_0-logloss:0.28388\n",
      "[262]\tvalidation_0-logloss:0.28386\n",
      "[263]\tvalidation_0-logloss:0.28385\n",
      "[264]\tvalidation_0-logloss:0.28385\n",
      "[265]\tvalidation_0-logloss:0.28383\n",
      "[266]\tvalidation_0-logloss:0.28383\n",
      "[267]\tvalidation_0-logloss:0.28383\n",
      "[268]\tvalidation_0-logloss:0.28382\n",
      "[269]\tvalidation_0-logloss:0.28382\n",
      "[270]\tvalidation_0-logloss:0.28382\n",
      "[271]\tvalidation_0-logloss:0.28382\n",
      "[272]\tvalidation_0-logloss:0.28382\n",
      "[273]\tvalidation_0-logloss:0.28381\n",
      "[274]\tvalidation_0-logloss:0.28381\n",
      "[275]\tvalidation_0-logloss:0.28381\n",
      "[276]\tvalidation_0-logloss:0.28381\n",
      "[277]\tvalidation_0-logloss:0.28380\n",
      "[278]\tvalidation_0-logloss:0.28380\n",
      "[279]\tvalidation_0-logloss:0.28380\n",
      "[280]\tvalidation_0-logloss:0.28379\n",
      "[281]\tvalidation_0-logloss:0.28379\n",
      "[282]\tvalidation_0-logloss:0.28378\n",
      "[283]\tvalidation_0-logloss:0.28378\n",
      "[284]\tvalidation_0-logloss:0.28376\n",
      "[285]\tvalidation_0-logloss:0.28375\n",
      "[286]\tvalidation_0-logloss:0.28375\n",
      "[287]\tvalidation_0-logloss:0.28375\n",
      "[288]\tvalidation_0-logloss:0.28373\n",
      "[289]\tvalidation_0-logloss:0.28373\n",
      "[290]\tvalidation_0-logloss:0.28372\n",
      "[291]\tvalidation_0-logloss:0.28372\n",
      "[292]\tvalidation_0-logloss:0.28372\n",
      "[293]\tvalidation_0-logloss:0.28370\n",
      "[294]\tvalidation_0-logloss:0.28369\n",
      "[295]\tvalidation_0-logloss:0.28368\n",
      "[296]\tvalidation_0-logloss:0.28367\n",
      "[297]\tvalidation_0-logloss:0.28368\n",
      "[298]\tvalidation_0-logloss:0.28368\n",
      "[299]\tvalidation_0-logloss:0.28367\n",
      "[300]\tvalidation_0-logloss:0.28366\n",
      "[301]\tvalidation_0-logloss:0.28366\n",
      "[302]\tvalidation_0-logloss:0.28365\n",
      "[303]\tvalidation_0-logloss:0.28365\n",
      "[304]\tvalidation_0-logloss:0.28365\n",
      "[305]\tvalidation_0-logloss:0.28364\n",
      "[306]\tvalidation_0-logloss:0.28362\n",
      "[307]\tvalidation_0-logloss:0.28361\n",
      "[308]\tvalidation_0-logloss:0.28362\n",
      "[309]\tvalidation_0-logloss:0.28360\n",
      "[310]\tvalidation_0-logloss:0.28359\n",
      "[311]\tvalidation_0-logloss:0.28358\n",
      "[312]\tvalidation_0-logloss:0.28358\n",
      "[313]\tvalidation_0-logloss:0.28358\n",
      "[314]\tvalidation_0-logloss:0.28358\n",
      "[315]\tvalidation_0-logloss:0.28358\n",
      "[316]\tvalidation_0-logloss:0.28357\n",
      "[317]\tvalidation_0-logloss:0.28357\n",
      "[318]\tvalidation_0-logloss:0.28356\n",
      "[319]\tvalidation_0-logloss:0.28356\n",
      "[320]\tvalidation_0-logloss:0.28355\n",
      "[321]\tvalidation_0-logloss:0.28354\n",
      "[322]\tvalidation_0-logloss:0.28353\n",
      "[323]\tvalidation_0-logloss:0.28353\n",
      "[324]\tvalidation_0-logloss:0.28354\n",
      "[325]\tvalidation_0-logloss:0.28353\n",
      "[326]\tvalidation_0-logloss:0.28352\n",
      "[327]\tvalidation_0-logloss:0.28353\n",
      "[328]\tvalidation_0-logloss:0.28352\n",
      "[329]\tvalidation_0-logloss:0.28351\n",
      "[330]\tvalidation_0-logloss:0.28351\n",
      "[331]\tvalidation_0-logloss:0.28350\n",
      "[332]\tvalidation_0-logloss:0.28348\n",
      "[333]\tvalidation_0-logloss:0.28349\n",
      "[334]\tvalidation_0-logloss:0.28348\n",
      "[335]\tvalidation_0-logloss:0.28347\n",
      "[336]\tvalidation_0-logloss:0.28347\n",
      "[337]\tvalidation_0-logloss:0.28346\n",
      "[338]\tvalidation_0-logloss:0.28345\n",
      "[339]\tvalidation_0-logloss:0.28345\n",
      "[340]\tvalidation_0-logloss:0.28344\n",
      "[341]\tvalidation_0-logloss:0.28345\n",
      "[342]\tvalidation_0-logloss:0.28344\n",
      "[343]\tvalidation_0-logloss:0.28343\n",
      "[344]\tvalidation_0-logloss:0.28343\n",
      "[345]\tvalidation_0-logloss:0.28343\n",
      "[346]\tvalidation_0-logloss:0.28344\n",
      "[347]\tvalidation_0-logloss:0.28343\n",
      "[348]\tvalidation_0-logloss:0.28342\n",
      "[349]\tvalidation_0-logloss:0.28341\n",
      "[350]\tvalidation_0-logloss:0.28341\n",
      "[351]\tvalidation_0-logloss:0.28340\n",
      "[352]\tvalidation_0-logloss:0.28338\n",
      "[353]\tvalidation_0-logloss:0.28337\n",
      "[354]\tvalidation_0-logloss:0.28336\n",
      "[355]\tvalidation_0-logloss:0.28335\n",
      "[356]\tvalidation_0-logloss:0.28333\n",
      "[357]\tvalidation_0-logloss:0.28333\n",
      "[358]\tvalidation_0-logloss:0.28334\n",
      "[359]\tvalidation_0-logloss:0.28333\n",
      "[360]\tvalidation_0-logloss:0.28333\n",
      "[361]\tvalidation_0-logloss:0.28332\n",
      "[362]\tvalidation_0-logloss:0.28331\n",
      "[363]\tvalidation_0-logloss:0.28331\n",
      "[364]\tvalidation_0-logloss:0.28332\n",
      "[365]\tvalidation_0-logloss:0.28331\n",
      "[366]\tvalidation_0-logloss:0.28333\n",
      "[367]\tvalidation_0-logloss:0.28333\n",
      "[368]\tvalidation_0-logloss:0.28332\n",
      "[369]\tvalidation_0-logloss:0.28331\n",
      "[370]\tvalidation_0-logloss:0.28333\n",
      "[371]\tvalidation_0-logloss:0.28332\n",
      "[372]\tvalidation_0-logloss:0.28332\n",
      "[373]\tvalidation_0-logloss:0.28332\n",
      "[374]\tvalidation_0-logloss:0.28332\n",
      "[375]\tvalidation_0-logloss:0.28333\n",
      "[376]\tvalidation_0-logloss:0.28332\n",
      "[377]\tvalidation_0-logloss:0.28331\n",
      "[378]\tvalidation_0-logloss:0.28330\n",
      "[379]\tvalidation_0-logloss:0.28329\n",
      "[380]\tvalidation_0-logloss:0.28329\n",
      "[381]\tvalidation_0-logloss:0.28329\n",
      "[382]\tvalidation_0-logloss:0.28329\n",
      "[383]\tvalidation_0-logloss:0.28329\n",
      "[384]\tvalidation_0-logloss:0.28329\n",
      "[385]\tvalidation_0-logloss:0.28329\n",
      "[386]\tvalidation_0-logloss:0.28327\n",
      "[387]\tvalidation_0-logloss:0.28326\n",
      "[388]\tvalidation_0-logloss:0.28325\n",
      "[389]\tvalidation_0-logloss:0.28327\n",
      "[390]\tvalidation_0-logloss:0.28326\n",
      "[391]\tvalidation_0-logloss:0.28326\n",
      "[392]\tvalidation_0-logloss:0.28323\n",
      "[393]\tvalidation_0-logloss:0.28324\n",
      "[394]\tvalidation_0-logloss:0.28324\n",
      "[395]\tvalidation_0-logloss:0.28323\n",
      "[396]\tvalidation_0-logloss:0.28323\n",
      "[397]\tvalidation_0-logloss:0.28323\n",
      "[398]\tvalidation_0-logloss:0.28322\n",
      "[399]\tvalidation_0-logloss:0.28322\n",
      "[400]\tvalidation_0-logloss:0.28322\n",
      "[401]\tvalidation_0-logloss:0.28321\n",
      "[402]\tvalidation_0-logloss:0.28321\n",
      "[403]\tvalidation_0-logloss:0.28320\n",
      "[404]\tvalidation_0-logloss:0.28321\n",
      "[405]\tvalidation_0-logloss:0.28320\n",
      "[406]\tvalidation_0-logloss:0.28320\n",
      "[407]\tvalidation_0-logloss:0.28320\n",
      "[408]\tvalidation_0-logloss:0.28320\n",
      "[409]\tvalidation_0-logloss:0.28320\n",
      "[410]\tvalidation_0-logloss:0.28320\n",
      "[411]\tvalidation_0-logloss:0.28320\n",
      "[412]\tvalidation_0-logloss:0.28319\n",
      "[413]\tvalidation_0-logloss:0.28319\n",
      "[414]\tvalidation_0-logloss:0.28319\n",
      "[415]\tvalidation_0-logloss:0.28319\n",
      "[416]\tvalidation_0-logloss:0.28319\n",
      "[417]\tvalidation_0-logloss:0.28319\n",
      "[418]\tvalidation_0-logloss:0.28319\n",
      "[419]\tvalidation_0-logloss:0.28319\n",
      "[420]\tvalidation_0-logloss:0.28319\n",
      "[421]\tvalidation_0-logloss:0.28319\n",
      "[422]\tvalidation_0-logloss:0.28318\n",
      "[423]\tvalidation_0-logloss:0.28317\n",
      "[424]\tvalidation_0-logloss:0.28316\n",
      "[425]\tvalidation_0-logloss:0.28316\n",
      "[426]\tvalidation_0-logloss:0.28315\n",
      "[427]\tvalidation_0-logloss:0.28315\n",
      "[428]\tvalidation_0-logloss:0.28315\n",
      "[429]\tvalidation_0-logloss:0.28315\n",
      "[430]\tvalidation_0-logloss:0.28317\n",
      "[431]\tvalidation_0-logloss:0.28316\n",
      "[432]\tvalidation_0-logloss:0.28316\n",
      "[433]\tvalidation_0-logloss:0.28317\n",
      "[434]\tvalidation_0-logloss:0.28317\n",
      "[435]\tvalidation_0-logloss:0.28317\n",
      "[436]\tvalidation_0-logloss:0.28316\n",
      "[437]\tvalidation_0-logloss:0.28317\n",
      "[438]\tvalidation_0-logloss:0.28317\n",
      "[439]\tvalidation_0-logloss:0.28316\n",
      "[440]\tvalidation_0-logloss:0.28316\n",
      "[441]\tvalidation_0-logloss:0.28316\n",
      "[442]\tvalidation_0-logloss:0.28317\n",
      "[443]\tvalidation_0-logloss:0.28318\n",
      "[444]\tvalidation_0-logloss:0.28319\n",
      "[445]\tvalidation_0-logloss:0.28319\n",
      "[446]\tvalidation_0-logloss:0.28318\n",
      "[447]\tvalidation_0-logloss:0.28317\n",
      "[448]\tvalidation_0-logloss:0.28317\n",
      "[449]\tvalidation_0-logloss:0.28316\n",
      "[450]\tvalidation_0-logloss:0.28316\n",
      "[451]\tvalidation_0-logloss:0.28317\n",
      "[452]\tvalidation_0-logloss:0.28316\n",
      "[453]\tvalidation_0-logloss:0.28317\n",
      "[454]\tvalidation_0-logloss:0.28316\n",
      "[455]\tvalidation_0-logloss:0.28315\n",
      "[456]\tvalidation_0-logloss:0.28315\n",
      "[457]\tvalidation_0-logloss:0.28315\n",
      "[458]\tvalidation_0-logloss:0.28315\n",
      "[459]\tvalidation_0-logloss:0.28315\n",
      "[460]\tvalidation_0-logloss:0.28314\n",
      "[461]\tvalidation_0-logloss:0.28313\n",
      "[462]\tvalidation_0-logloss:0.28312\n",
      "[463]\tvalidation_0-logloss:0.28311\n",
      "[464]\tvalidation_0-logloss:0.28311\n",
      "[465]\tvalidation_0-logloss:0.28311\n",
      "[466]\tvalidation_0-logloss:0.28311\n",
      "[467]\tvalidation_0-logloss:0.28310\n",
      "[468]\tvalidation_0-logloss:0.28311\n",
      "[469]\tvalidation_0-logloss:0.28310\n",
      "[470]\tvalidation_0-logloss:0.28310\n",
      "[471]\tvalidation_0-logloss:0.28310\n",
      "[472]\tvalidation_0-logloss:0.28312\n",
      "[473]\tvalidation_0-logloss:0.28310\n",
      "[474]\tvalidation_0-logloss:0.28310\n",
      "[475]\tvalidation_0-logloss:0.28310\n",
      "[476]\tvalidation_0-logloss:0.28310\n",
      "[477]\tvalidation_0-logloss:0.28310\n",
      "[478]\tvalidation_0-logloss:0.28310\n",
      "[479]\tvalidation_0-logloss:0.28310\n",
      "[480]\tvalidation_0-logloss:0.28310\n",
      "[481]\tvalidation_0-logloss:0.28310\n",
      "[482]\tvalidation_0-logloss:0.28309\n",
      "[483]\tvalidation_0-logloss:0.28310\n",
      "[484]\tvalidation_0-logloss:0.28309\n",
      "[485]\tvalidation_0-logloss:0.28309\n",
      "[486]\tvalidation_0-logloss:0.28310\n",
      "[487]\tvalidation_0-logloss:0.28308\n",
      "[488]\tvalidation_0-logloss:0.28309\n",
      "[489]\tvalidation_0-logloss:0.28309\n",
      "[490]\tvalidation_0-logloss:0.28310\n",
      "[491]\tvalidation_0-logloss:0.28310\n",
      "[492]\tvalidation_0-logloss:0.28309\n",
      "[493]\tvalidation_0-logloss:0.28309\n",
      "[494]\tvalidation_0-logloss:0.28308\n",
      "[495]\tvalidation_0-logloss:0.28309\n",
      "[496]\tvalidation_0-logloss:0.28308\n",
      "[497]\tvalidation_0-logloss:0.28308\n",
      "[498]\tvalidation_0-logloss:0.28308\n",
      "[499]\tvalidation_0-logloss:0.28307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: after federated training\n",
    "# trained_global_extractor = federated_train(feature_extractor, X_train, y_train, ...)\n",
    "# In case federated round is expensive, you can first try without FL:\n",
    "# trained_global_extractor = feature_extractor  # pre-trained or untrained baseline\n",
    "\n",
    "# 1) Extract features\n",
    "# X_train_feats = extract_features(trained_global_extractor, X_train)         # shape (N, dense_proj_units)\n",
    "# X_val_feats   = extract_features(trained_global_extractor, X_val_pad)      # your provided X_val_pad\n",
    "\n",
    "# 2) Train XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist'  # change to 'gpu_hist' on GPU\n",
    ")\n",
    "\n",
    "# Use early stopping on validation features\n",
    "xgb.fit(\n",
    "    X_train_feats, y_train,\n",
    "    \n",
    "    eval_set=[(X_val_feats, y_val)],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e94ae9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c992eb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87     35358\n",
      "           1       0.85      0.92      0.88     35524\n",
      "\n",
      "    accuracy                           0.88     70882\n",
      "   macro avg       0.88      0.88      0.88     70882\n",
      "weighted avg       0.88      0.88      0.88     70882\n",
      "\n",
      "AUC: 0.9486425531672593\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_proba = xgb.predict_proba(X_val_feats)[:,1]\n",
    "y_val_pred = (y_val_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_val, y_val_pred_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d64a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139/139\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 352ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_feats   = extract_features(trained_global_extractor, X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cedd63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87     35239\n",
      "           1       0.85      0.92      0.88     35643\n",
      "\n",
      "    accuracy                           0.88     70882\n",
      "   macro avg       0.88      0.88      0.88     70882\n",
      "weighted avg       0.88      0.88      0.88     70882\n",
      "\n",
      "AUC: 0.9484239173303418\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_proba = xgb.predict_proba(X_test_feats)[:,1]\n",
    "y_test_pred = (y_test_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_test_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6aa7a1",
   "metadata": {},
   "source": [
    "WITH ATTENTION LAYER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0712e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import (Input, Embedding, Conv1D, BatchNormalization,\n",
    "                                     LeakyReLU, MaxPooling1D, Concatenate,\n",
    "                                     Bidirectional, LSTM, Dense, Dropout, Attention)\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f470d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def build_attention_model(vocab_size, maxlen,\n",
    "                          embedding_dim=64,\n",
    "                          conv_filters=128,\n",
    "                          conv_kernel_sizes=[3,5,7],\n",
    "                          pool_size=2,\n",
    "                          bilstm_units=128,\n",
    "                          dense_proj_units=128,\n",
    "                          dropout_rate=0.3):\n",
    "\n",
    "    inp = Input(shape=(maxlen,), dtype='int32', name='input_ids')\n",
    "\n",
    "    # Embedding layer\n",
    "    x = Embedding(input_dim=vocab_size + 1,\n",
    "                  output_dim=embedding_dim,\n",
    "                  input_length=maxlen,\n",
    "                  mask_zero=False,\n",
    "                  name='embedding')(inp)\n",
    "\n",
    "    # Parallel Conv1D layers\n",
    "    convs = []\n",
    "    for k in conv_kernel_sizes:\n",
    "        c = Conv1D(filters=conv_filters, kernel_size=k, padding='same')(x)\n",
    "        c = BatchNormalization()(c)\n",
    "        c = LeakyReLU(alpha=0.1)(c)\n",
    "        c = MaxPooling1D(pool_size=pool_size)(c)\n",
    "        convs.append(c)\n",
    "\n",
    "    x = Concatenate(axis=-1)(convs)\n",
    "\n",
    "    # Extra convolution for richer features\n",
    "    x = Conv1D(filters=conv_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # BiLSTM contextual layer\n",
    "    x = Bidirectional(LSTM(bilstm_units, return_sequences=True))(x)\n",
    "\n",
    "    # Attention layer (self-attention)\n",
    "    attn_out = Attention()([x, x])\n",
    "    attn_vec = GlobalAveragePooling1D()(attn_out)  # safer than tf.reduce_mean\n",
    "\n",
    "    # Dense + dropout\n",
    "    x = Dense(dense_proj_units, activation='gelu')(attn_vec)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Final sigmoid output\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out, name='cnn_bilstm_attention')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_local_model_from_global(global_model, learning_rate=0.001):\n",
    "    \"\"\"Clone and compile the global model for each client.\"\"\"\n",
    "    model = clone_model(global_model)\n",
    "    model.set_weights(global_model.get_weights())\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def average_weights(client_weights):\n",
    "    \"\"\"Average weights from all clients.\"\"\"\n",
    "    avg_weights = []\n",
    "    for weights in zip(*client_weights):\n",
    "        avg_weights.append(np.mean(weights, axis=0))\n",
    "    return avg_weights\n",
    "\n",
    "\n",
    "def federated_train(global_model, X_train, y_train,\n",
    "                    X_val, y_val,\n",
    "                    num_clients=5,\n",
    "                    rounds=3,\n",
    "                    local_epochs=1,\n",
    "                    batch_size=256,\n",
    "                    learning_rate=0.001,\n",
    "                    non_iid=False):\n",
    "    \"\"\"Simulate federated averaging across clients.\"\"\"\n",
    "\n",
    "    n_samples = len(X_train)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    client_splits = np.array_split(indices, num_clients)\n",
    "\n",
    "    for r in range(rounds):\n",
    "        print(f\"\\n Federated Round {r+1}/{rounds}\")\n",
    "        client_weights = []\n",
    "\n",
    "        for i, idxs in enumerate(client_splits):\n",
    "            print(f\"   Client {i+1}: {len(idxs)} samples\")\n",
    "\n",
    "            X_c, y_c = X_train[idxs], y_train[idxs]\n",
    "\n",
    "            local_model = compile_local_model_from_global(global_model, learning_rate)\n",
    "            local_model.fit(X_c, y_c,\n",
    "                            epochs=local_epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            verbose=1)\n",
    "            client_weights.append(local_model.get_weights())\n",
    "\n",
    "        # Federated averaging\n",
    "        new_weights = average_weights(client_weights)\n",
    "        global_model.set_weights(new_weights)\n",
    "\n",
    "        # Validation performance\n",
    "        loss, acc = global_model.evaluate(X_val, y_val, verbose=1)\n",
    "        print(f\"   Global model accuracy after round {r+1}: {acc:.4f}\")\n",
    "\n",
    "    return global_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9eb09545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Federated Round 1/3\n",
      "   Client 1: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.8319 - loss: 0.3764\n",
      "   Client 2: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 1s/step - accuracy: 0.8378 - loss: 0.3674\n",
      "   Client 3: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 1s/step - accuracy: 0.8307 - loss: 0.3761\n",
      "   Client 4: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 1s/step - accuracy: 0.8306 - loss: 0.3783\n",
      "   Global model accuracy after round 1: 0.4988\n",
      "\n",
      " Federated Round 2/3\n",
      "   Client 1: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 1s/step - accuracy: 0.8699 - loss: 0.3109\n",
      "   Client 2: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 1s/step - accuracy: 0.8717 - loss: 0.3093\n",
      "   Client 3: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 2s/step - accuracy: 0.8692 - loss: 0.3142\n",
      "   Client 4: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 1s/step - accuracy: 0.8695 - loss: 0.3139\n",
      "   Global model accuracy after round 2: 0.8057\n",
      "\n",
      " Federated Round 3/3\n",
      "   Client 1: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 2s/step - accuracy: 0.8870 - loss: 0.2741\n",
      "   Client 2: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.8863 - loss: 0.2739\n",
      "   Client 3: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.8858 - loss: 0.2761\n",
      "   Client 4: 131341 samples\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 2s/step - accuracy: 0.8863 - loss: 0.2768\n",
      "   Global model accuracy after round 3: 0.7929\n"
     ]
    }
   ],
   "source": [
    "# Example params (replace with your actual data vars)\n",
    "vocab_size = 44\n",
    "maxlen = 182\n",
    "embedding_dim = 64\n",
    "conv_filters = 128\n",
    "bilstm_units = 128\n",
    "dense_proj_units = 128\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Build model\n",
    "global_model = build_attention_model(vocab_size, maxlen,\n",
    "                                     embedding_dim,\n",
    "                                     conv_filters,\n",
    "                                     bilstm_units=bilstm_units,\n",
    "                                     dense_proj_units=dense_proj_units)\n",
    "\n",
    "global_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Run federated training (simulation)\n",
    "trained_global = federated_train(global_model,\n",
    "                                 X_train_pad, y_train,\n",
    "                                 X_val=X_val_pad, y_val=y_val,\n",
    "                                 num_clients=4,\n",
    "                                 rounds=3,\n",
    "                                 local_epochs=1,\n",
    "                                 batch_size=batch_size,\n",
    "                                 learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e487048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2216/2216\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 88ms/step - accuracy: 0.7929 - loss: 0.4053\n",
      "\n",
      "Final Validation Accuracy: 0.7929\n"
     ]
    }
   ],
   "source": [
    "loss, acc = trained_global.evaluate(X_val_pad, y_val, verbose=1)\n",
    "print(f\"\\nFinal Validation Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5c883",
   "metadata": {},
   "source": [
    "Manually adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a71a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyparsing>=3.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydot) (3.2.0)\n",
      "Downloading pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-4.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "52abe9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(\n",
    "    trained_global,\n",
    "    to_file='model_structure.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    expand_nested=True,\n",
    "    dpi=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec16b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
