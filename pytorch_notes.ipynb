{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe449b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8383f5",
   "metadata": {},
   "source": [
    "Tensor: it just like numpy array but it few more features needed for neural network like it can work with GPU to exclarate process unlike numpy which can only work with CPU second is it can auto calculate gradient which to good to complex functions in NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51c17f",
   "metadata": {},
   "source": [
    "trailing _ in functions means our function will do inplace operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4ea9a",
   "metadata": {},
   "source": [
    "vector can be 1d tensor  \n",
    "matrix can be 2d tensor  \n",
    "tensor can n-dimension array like numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Tensor: \n",
      " tensor([1., 2., 3.])\n",
      "2D Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a 1D tensor\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print('1D Tensor: \\n', x)\n",
    "\n",
    "# Creating a 2D tensor\n",
    "y = torch.zeros((3, 3)) # same as np.zeros\n",
    "print('2D Tensor: \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2578fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.]])\n",
      "Element Wise Addition of a & b: \n",
      " tensor([4., 6.])\n",
      "Matrix Multiplication of a & b (using torch.matmul   (matrix multiply)): \n",
      " tensor([[3., 4.],\n",
      "        [6., 8.]])\n",
      "Matrix Multiplication of a & b (using @): \n",
      " tensor([[3., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0])\n",
    "b = torch.tensor([3.0, 4.0])\n",
    "print(a.view(2,1)) # view is same as resize in numpy used to resize the tensor but only diff is it dont change original tensor \n",
    "# Element-wise addition\n",
    "print('Element Wise Addition of a & b: \\n', a + b)\n",
    "\n",
    "# Matrix multiplication\n",
    "print('Matrix Multiplication of a & b (using torch.matmul   (matrix multiply)): \\n', \n",
    "      torch.matmul(a.view(2,1), b.view(1,2)))    # @ works same as tensor.matmul\n",
    "print('Matrix Multiplication of a & b (using @): \\n', \n",
    "      a.view(2,1) @ b.view(1,2))    # @ works same as torch.matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b87379",
   "metadata": {},
   "source": [
    "rehape gives diffrent arr with diffrent memory imean it is work like as deapcopy in fundamental python but it is slower than view  \n",
    "view need continuos memory while reshpe does not need continuos memory\n",
    "\n",
    "continuous memory means index of tenser is same as index of memory location of that element it affect in operations like transpose when actual location of element is not change but view is changed it give error doing further view oprations\n",
    "\n",
    ".t a view opration works only on 2d array same as numpy \n",
    ".transform also a view operation but can works with any dimensions it swap between two dimensions (dim0, dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ab70319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping\n",
      "tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "\n",
      "Resizing\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "\n",
      "Transposing\n",
      "tensor([[ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11],\n",
      "        [ 4,  8, 12]])\n",
      "error in view\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "t = torch.tensor([[1, 2, 3, 4],\n",
    "                 [5, 6, 7, 8],\n",
    "                 [9, 10, 11, 12]])\n",
    "\n",
    "# Reshaping\n",
    "print(\"Reshaping\")\n",
    "print(t.reshape(6, 2))\n",
    "\n",
    "# Resizing (deprecated, use reshape)\n",
    "print(\"\\nResizing\")\n",
    "print(t.view(2, 6))\n",
    "\n",
    "# Transposing\n",
    "print(\"\\nTransposing\")\n",
    "print(t.transpose(0, 1))\n",
    "\n",
    "\n",
    "x = torch.arange(9).reshape(3,3)\n",
    "y = x.t()  # transpose, not contiguous\n",
    "try:\n",
    "    y.view(9)\n",
    "except:\n",
    "    print('error in view')\n",
    "try:\n",
    "    y.reshape(9)\n",
    "except:\n",
    "    print('error in reshape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c7429",
   "metadata": {},
   "source": [
    "## Autograd and Computational Graphs\n",
    "The autograd module automates gradient calculation for backpropagation. This is crucia in training deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6e8e3",
   "metadata": {},
   "source": [
    "we can apply any algebra to tensor same as like in numpy(in parallel) we can also enable requires_grad so that our tensor will store all operation perform on it and calculate its gradient  \n",
    "gradient could be calculated result.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37c21e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True)\n",
      "tensor([7.])\n",
      "tensor([12.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "print(x)\n",
    "y = x**2 + 3*x + 2 # y = x^2 +3x +2\n",
    "y.backward()   # compute dy/dx = 2x + 3\n",
    "print(x.grad)  # -> tensor([7.]) (2*2 + 3 = 7)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "157f1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = torch.tensor(np.linspace(-5,5,500), requires_grad=True)\n",
    "y1 = torch.tanh(x)\n",
    "y3 = y1.mean()\n",
    "y3.backward()   # compute dy/dx = 2x + 3\n",
    "#print(x.grad)  # -> tensor([7.]) (2*2 + 3 = 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffb7013d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "y": {
          "bdata": "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",
          "dtype": "f8"
         }
        },
        {
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "y": {
          "bdata": "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",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_scatter(x=x.detach().numpy(),y=y1.detach().numpy())\n",
    "fig.add_scatter(x=x.detach().numpy(),y=x.grad.detach().numpy())\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc69c23",
   "metadata": {},
   "source": [
    "simple neural network on minist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a3a3c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 1.1599655151367188\n",
      "epoch 9999 loss 0.060810185968875885\n",
      "tensor([[0.0946],\n",
      "        [0.9549],\n",
      "        [0.9403],\n",
      "        [0.0354]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "xor_X = torch.tensor([[0,0],[0,1],[1,0],[1,1]],dtype=torch.float)\n",
    "xor_Y = torch.tensor([0,1,1,0],dtype=torch.float).reshape(4,1)\n",
    "class nn:\n",
    "    def __init__(self, input, output,activation, *hidden_layer,lr):\n",
    "        self.weights = []\n",
    "        if hidden_layer:\n",
    "            self.weights.append(torch.randn((input,hidden_layer[0]),requires_grad=True))\n",
    "            for l in range(1,len(hidden_layer)):\n",
    "                self.weights.append(torch.randn((hidden_layer[l-1],hidden_layer[l]),requires_grad=True))\n",
    "            self.weights.append(torch.randn((hidden_layer[-1],output),requires_grad=True))\n",
    "                \n",
    "        else:\n",
    "            self.weights.append(torch.randn((input, output),requires_grad=True))\n",
    "        self.lr = lr\n",
    "        self.act = activation\n",
    "        #print(self.weights)\n",
    "    def forward(self, input):\n",
    "        for weight in self.weights:\n",
    "            output = input @ weight\n",
    "            input = self.act(output)\n",
    "        return input\n",
    "    def loss(self, y_true, y_pred):\n",
    "        eps = 1e-9  # small constant to prevent log(0)\n",
    "        return -(y_true * torch.log(y_pred + eps) + (1 - y_true) * torch.log(1 - y_pred + eps))\n",
    "\n",
    "    def backpropagation(self, loss):\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] -= self.lr*self.weights[i].grad\n",
    "                self.weights[i].grad.zero_()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = nn(2,1,torch.sigmoid,100,10,lr=0.01)\n",
    "for epoch in range(10000):\n",
    "    y_pred = model.forward(xor_X)\n",
    "    loss = model.loss(xor_Y,y_pred).mean()\n",
    "    model.backpropagation(loss)\n",
    "\n",
    "    if epoch % 9999 == 0:\n",
    "        print(f\"epoch {epoch} loss {loss}\")\n",
    "        #print(model.weights)\n",
    "\n",
    "y_pred = model.forward(xor_X)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4570e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def init_population(pop_size, max_layers=3, max_neurons=128):\n",
    "    \"\"\"Initialize population of networks with varying hidden layer sizes.\"\"\"\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        num_layers = random.randint(0, max_layers)   # how many hidden layers\n",
    "        hidden_layers = [random.randint(1, max_neurons) for _ in range(num_layers)]\n",
    "        population.append(hidden_layers)\n",
    "    return population\n",
    "def fitness_function(hidden_layers, accuracy, alpha=0.01, beta=0.001):\n",
    "    \"\"\"\n",
    "    hidden_layers: list of hidden layer sizes\n",
    "    accuracy: float (0 to 1)\n",
    "    alpha: penalty weight for number of layers\n",
    "    beta: penalty weight for total neurons\n",
    "    \"\"\"\n",
    "    num_layers = len(hidden_layers)\n",
    "    total_neurons = sum(hidden_layers) if hidden_layers else 0\n",
    "    \n",
    "    penalty = alpha * num_layers + beta * total_neurons\n",
    "    fitness = accuracy - penalty *0  # maximize fitness\n",
    "    return fitness\n",
    "import random\n",
    "\n",
    "def select_parents(population, accuracies, top_frac=0.4, bottom_frac=0.1):\n",
    "    \"\"\"\n",
    "    population: list of architectures (list of hidden layer sizes)\n",
    "    accuracies: list of accuracies for each individual\n",
    "    Returns: selected parent architectures\n",
    "    \"\"\"\n",
    "    # Compute fitness\n",
    "    fitness_scores = [\n",
    "        (fitness_function(population[i], accuracies[i]), population[i])\n",
    "        for i in range(len(population))\n",
    "    ]\n",
    "    \n",
    "    # Sort by fitness (descending, higher is better)\n",
    "    fitness_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Select top 40%\n",
    "    n_top = max(1, int(len(population) * top_frac))\n",
    "    best = [arch for _, arch in fitness_scores[:n_top]]\n",
    "    \n",
    "    # Select bottom 10%\n",
    "    n_bottom = max(1, int(len(population) * bottom_frac))\n",
    "    worst = [arch for _, arch in fitness_scores[-n_bottom:]]\n",
    "    \n",
    "    # Merge\n",
    "    selected = best + worst\n",
    "    return selected, fitness_scores\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    \"\"\"One-point crossover between two architectures (hidden layer lists).\"\"\"\n",
    "    if not parent1:  # if parent1 empty\n",
    "        return parent2.copy()\n",
    "    if not parent2:  # if parent2 empty\n",
    "        return parent1.copy()\n",
    "    \n",
    "    # Pick crossover points\n",
    "    p1 = random.randint(0, len(parent1))\n",
    "    p2 = random.randint(0, len(parent2))\n",
    "    \n",
    "    child = parent1[:p1] + parent2[p2:]\n",
    "    return child\n",
    "\n",
    "def mutate(individual, max_neurons=128, mutation_rate=0.3):\n",
    "    \"\"\"Mutate hidden layer architecture.\"\"\"\n",
    "    child = individual.copy()\n",
    "    \n",
    "    if random.random() < mutation_rate:\n",
    "        action = random.choice([\"add\",\"remove\",\"change\"])\n",
    "        \n",
    "        if action == \"add\":\n",
    "            new_layer = random.randint(1, max_neurons)\n",
    "            pos = random.randint(0, len(child))\n",
    "            child.insert(pos, new_layer)\n",
    "            \n",
    "        elif action == \"remove\" and child:\n",
    "            pos = random.randrange(len(child))\n",
    "            child.pop(pos)\n",
    "            \n",
    "        elif action == \"change\" and child:\n",
    "            pos = random.randrange(len(child))\n",
    "            child[pos] = random.randint(1, max_neurons)\n",
    "            \n",
    "    return child\n",
    "def breed_population(parents, pop_size, mutation_rate=0.3, gen=1):\n",
    "    \"\"\"Create next generation from selected parents.\"\"\"\n",
    "    next_population = []\n",
    "    while len(next_population) < pop_size:\n",
    "        p1, p2 = random.sample(parents, 2)\n",
    "        child = crossover(p1, p2)\n",
    "        child = mutate(child, max_neurons=128*gen, mutation_rate=mutation_rate)\n",
    "        next_population.append(child)\n",
    "    return next_population\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "66b4cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population 0 epoch 4999 loss 0.23956814408302307\n",
      "hidden layer [10, 78, 22, 98, 21, 44, 37, 17, 5]\n",
      "population 0\n",
      "tensor([[0.1376],\n",
      "        [0.7257],\n",
      "        [0.7750],\n",
      "        [0.2083]], grad_fn=<SigmoidBackward0>)\n",
      "population 1 epoch 4999 loss 0.07346685230731964\n",
      "hidden layer [22, 70]\n",
      "population 1\n",
      "tensor([[0.0670],\n",
      "        [0.9265],\n",
      "        [0.9305],\n",
      "        [0.0733]], grad_fn=<SigmoidBackward0>)\n",
      "population 3 epoch 4999 loss 0.010990992188453674\n",
      "hidden layer [37, 84, 95, 34, 56, 95, 71, 63, 92, 23, 49, 29, 53, 14, 51]\n",
      "population 3\n",
      "tensor([[0.0132],\n",
      "        [0.9895],\n",
      "        [0.9895],\n",
      "        [0.0095]], grad_fn=<SigmoidBackward0>)\n",
      "population 5 epoch 4999 loss 0.00828021951019764\n",
      "hidden layer [69, 84, 14, 83, 23, 96, 13, 27, 27, 73, 37]\n",
      "population 5\n",
      "tensor([[0.0077],\n",
      "        [0.9911],\n",
      "        [0.9906],\n",
      "        [0.0070]], grad_fn=<SigmoidBackward0>)\n",
      "population 8 epoch 4999 loss 0.004878249950706959\n",
      "hidden layer [57, 60, 48, 80, 76, 62, 64, 47]\n",
      "population 8\n",
      "tensor([[0.0046],\n",
      "        [0.9964],\n",
      "        [0.9941],\n",
      "        [0.0053]], grad_fn=<SigmoidBackward0>)\n",
      "population 10 epoch 4999 loss 0.0028779511339962482\n",
      "hidden layer [31, 92, 46, 63, 100, 38, 73, 82, 92]\n",
      "population 10\n",
      "tensor([[0.0022],\n",
      "        [0.9969],\n",
      "        [0.9974],\n",
      "        [0.0036]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "population = init_population(20, max_layers=20, max_neurons=100)\n",
    "accuracy = []\n",
    "best_loss = float('inf')\n",
    "for pop_number, hiddenlayers in enumerate(population):\n",
    "    model = nn(2,1,torch.sigmoid,*hiddenlayers,lr=0.01)\n",
    "    for epoch in range(5000):\n",
    "        y_pred = model.forward(xor_X)\n",
    "        loss = model.loss(xor_Y,y_pred).mean()\n",
    "        model.backpropagation(loss)\n",
    "        if loss < best_loss:\n",
    "            if epoch > 4998:\n",
    "                print(f\"population {pop_number} epoch {epoch} loss {loss}\")\n",
    "                #print(model.weights)\n",
    "    accuracy.append(1-loss)     \n",
    "    if loss < best_loss:\n",
    "        print('hidden layer',hiddenlayers)\n",
    "        print(f\"population {pop_number}\")\n",
    "        y_pred = model.forward(xor_X)\n",
    "        print(y_pred)\n",
    "        best_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "607fac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer [52, 6, 39, 73, 8, 55, 3, 127, 110, 53, 62, 40, 118, 111, 39, 72, 44]\n",
      "population 0\n",
      "tensor([[0.4998],\n",
      "        [0.4998],\n",
      "        [0.5003],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
      "hidden layer [92, 17, 88, 94, 105, 123, 46, 79, 112, 88, 5, 57]\n",
      "population 4\n",
      "tensor([[0.3918],\n",
      "        [0.5022],\n",
      "        [0.4981],\n",
      "        [0.5064]], grad_fn=<SigmoidBackward0>)\n",
      "hidden layer [117, 20, 40]\n",
      "population 7\n",
      "tensor([[0.4671],\n",
      "        [0.6258],\n",
      "        [0.4792],\n",
      "        [0.4434]], grad_fn=<SigmoidBackward0>)\n",
      "hidden layer [86, 50, 15, 64, 110, 120, 57]\n",
      "population 16\n",
      "tensor([[0.2675],\n",
      "        [0.6471],\n",
      "        [0.6606],\n",
      "        [0.3133]], grad_fn=<SigmoidBackward0>)\n",
      "gen 1 [(tensor(0.6133, grad_fn=<SubBackward0>), [86, 50, 15, 64, 110, 120, 57]), (tensor(0.3943, grad_fn=<SubBackward0>), [117, 20, 40]), (tensor(0.3768, grad_fn=<SubBackward0>), [53, 76, 46, 64, 40, 70, 96, 83, 96, 48, 42, 42, 56, 93, 36, 94])]\n",
      "hidden layer [92, 68, 17, 88, 94, 105, 123, 46, 79, 112, 120, 57]\n",
      "population 10\n",
      "tensor([[0.0948],\n",
      "        [0.8959],\n",
      "        [0.8753],\n",
      "        [0.0433]], grad_fn=<SigmoidBackward0>)\n",
      "gen 2 [(tensor(0.9021, grad_fn=<SubBackward0>), [92, 68, 17, 88, 94, 105, 123, 46, 79, 112, 120, 57]), (tensor(0.3949, grad_fn=<SubBackward0>), [53, 76, 46, 64, 40, 70, 96, 83, 96, 48, 63, 4, 73, 82, 120, 114, 48, 17]), (tensor(0.3857, grad_fn=<SubBackward0>), [53, 76, 46, 64, 40, 70, 96, 83, 96, 48, 42, 78, 63, 73, 82, 120, 48, 17])]\n",
      "gen 3 [(tensor(0.8334, grad_fn=<SubBackward0>), [86, 50, 54, 64, 110, 120, 57]), (tensor(0.4829, grad_fn=<SubBackward0>), [53, 76, 46, 64, 40, 70, 96, 83, 96, 48, 65, 57]), (tensor(0.4266, grad_fn=<SubBackward0>), [92, 63, 4, 73, 82, 46, 64, 40, 70, 96, 83, 96, 48, 63, 4, 73, 82, 120, 114, 48])]\n",
      "gen 4 [(tensor(0.8377, grad_fn=<SubBackward0>), [125, 36, 53, 76, 46, 21, 117, 64, 70, 96, 83, 96, 48, 65, 57]), (tensor(0.8098, grad_fn=<SubBackward0>), [53, 76, 46, 64, 97, 118, 106, 104]), (tensor(0.7537, grad_fn=<SubBackward0>), [85, 78, 114, 69])]\n",
      "hidden layer [53, 76, 46, 40, 70, 96, 96, 48, 83, 96, 50, 65, 57, 73, 82]\n",
      "population 0\n",
      "tensor([[0.0737],\n",
      "        [0.9165],\n",
      "        [0.9232],\n",
      "        [0.0715]], grad_fn=<SigmoidBackward0>)\n",
      "gen 5 [(tensor(0.9195, grad_fn=<SubBackward0>), [53, 76, 46, 40, 70, 96, 96, 48, 83, 96, 50, 65, 57, 73, 82]), (tensor(0.8553, grad_fn=<SubBackward0>), [53, 76, 21, 117, 64, 70, 96, 83, 96, 48, 65, 57]), (tensor(0.8503, grad_fn=<SubBackward0>), [122, 28, 71, 104, 59, 34, 77, 124, 8, 79, 116, 77, 23, 45, 88, 96, 125])]\n",
      "hidden layer [53, 76, 46, 70, 96, 96, 48, 83, 96, 50, 65, 57, 88, 96, 125]\n",
      "population 13\n",
      "tensor([[0.0361],\n",
      "        [0.9622],\n",
      "        [0.9664],\n",
      "        [0.0324]], grad_fn=<SigmoidBackward0>)\n",
      "gen 6 [(tensor(0.9640, grad_fn=<SubBackward0>), [53, 76, 46, 70, 96, 96, 48, 83, 96, 50, 65, 57, 88, 96, 125]), (tensor(0.8719, grad_fn=<SubBackward0>), [53, 76, 58, 46, 40, 99, 70, 96, 96, 48, 83, 115, 110, 120, 57]), (tensor(0.7828, grad_fn=<SubBackward0>), [115, 110, 120, 57])]\n",
      "gen 7 [(tensor(0.9524, grad_fn=<SubBackward0>), [122, 28, 32, 71, 104, 59, 34, 116, 96, 48, 83, 115, 110, 120, 57]), (tensor(0.8028, grad_fn=<SubBackward0>), [26, 125, 54, 64, 110, 120, 87, 46, 40, 70, 96, 78, 93, 17, 44, 114]), (tensor(0.7278, grad_fn=<SubBackward0>), [83, 96, 50, 57, 96, 50, 57])]\n",
      "gen 8 [(tensor(0.9297, grad_fn=<SubBackward0>), [122, 28, 32, 71, 104, 59, 34, 116, 96, 48, 83, 115, 110, 120, 57, 74, 76]), (tensor(0.9258, grad_fn=<SubBackward0>), [26, 125, 54, 64, 96, 96, 48, 83, 96, 50, 83]), (tensor(0.9024, grad_fn=<SubBackward0>), [112, 125, 54, 64, 110, 120, 87, 46, 40, 70, 96, 78, 93, 17, 44, 114, 57])]\n",
      "gen 9 [(tensor(0.9459, grad_fn=<SubBackward0>), [126, 59, 120, 91, 98, 126, 83, 120, 57]), (tensor(0.9113, grad_fn=<SubBackward0>), [115, 26, 125, 54, 64, 110, 120, 87, 46, 70, 83, 120, 57]), (tensor(0.8173, grad_fn=<SubBackward0>), [112, 125, 121, 50, 57])]\n",
      "gen 10 [(tensor(0.9179, grad_fn=<SubBackward0>), [76, 64, 110, 120, 87, 46, 70, 83, 120, 57]), (tensor(0.9058, grad_fn=<SubBackward0>), [112, 83, 120, 117, 57]), (tensor(0.8730, grad_fn=<SubBackward0>), [122, 38, 32, 83, 92, 120, 57, 12, 98, 55, 32, 57])]\n",
      "gen 11 [(tensor(0.9130, grad_fn=<SubBackward0>), [112, 125, 121, 97]), (tensor(0.8828, grad_fn=<SubBackward0>), [37, 112, 83, 120, 117, 57, 72]), (tensor(0.7590, grad_fn=<SubBackward0>), [31, 83, 120, 117])]\n",
      "gen 12 [(tensor(0.8873, grad_fn=<SubBackward0>), [104, 60, 49, 99, 64, 69, 122, 60, 117, 57, 72]), (tensor(0.8677, grad_fn=<SubBackward0>), [30, 83, 83, 120, 46, 49, 99, 69, 122, 60]), (tensor(0.8394, grad_fn=<SubBackward0>), [37, 112, 83, 120, 120])]\n",
      "gen 13 [(tensor(0.9198, grad_fn=<SubBackward0>), [127, 108, 86, 103, 80, 96]), (tensor(0.9185, grad_fn=<SubBackward0>), [73, 68, 39, 108, 86, 127]), (tensor(0.9081, grad_fn=<SubBackward0>), [112, 125, 122, 120])]\n",
      "gen 14 [(tensor(0.9620, grad_fn=<SubBackward0>), [112, 125, 102, 103, 80, 96]), (tensor(0.9604, grad_fn=<SubBackward0>), [31, 83, 120, 117, 120, 125, 122, 120]), (tensor(0.8542, grad_fn=<SubBackward0>), [112, 125, 69, 122, 60])]\n",
      "gen 15 [(tensor(0.9400, grad_fn=<SubBackward0>), [127, 108, 86, 103, 80, 49, 99, 64, 69, 122, 117, 83]), (tensor(0.9334, grad_fn=<SubBackward0>), [83, 120, 117, 101, 125, 122, 120]), (tensor(0.9260, grad_fn=<SubBackward0>), [31, 83, 120, 117, 120, 125, 122, 122, 60, 121, 117, 83])]\n",
      "hidden layer [31, 83, 116, 120, 117, 37, 58, 31, 83, 120, 117, 101, 125, 18, 122, 120]\n",
      "population 2\n",
      "tensor([[0.0214],\n",
      "        [0.9654],\n",
      "        [0.9707],\n",
      "        [0.0256]], grad_fn=<SigmoidBackward0>)\n",
      "gen 16 [(tensor(0.9716, grad_fn=<SubBackward0>), [31, 83, 116, 120, 117, 37, 58, 31, 83, 120, 117, 101, 125, 18, 122, 120]), (tensor(0.9602, grad_fn=<SubBackward0>), [127, 108, 86, 80, 49, 99, 64, 69, 122, 117, 83]), (tensor(0.9591, grad_fn=<SubBackward0>), [83, 120, 75, 101, 125, 122, 120])]\n",
      "gen 17 [(tensor(0.9386, grad_fn=<SubBackward0>), [127, 108, 52, 86, 117, 37, 58, 31, 69, 122, 60, 117, 57, 114, 72]), (tensor(0.9170, grad_fn=<SubBackward0>), [51, 101, 125, 122, 120]), (tensor(0.9074, grad_fn=<SubBackward0>), [119, 117, 77, 58, 31, 125, 118, 50, 57, 122, 120])]\n",
      "gen 18 [(tensor(0.9692, grad_fn=<SubBackward0>), [105, 31, 125, 118, 50, 57, 122, 120]), (tensor(0.9525, grad_fn=<SubBackward0>), [51, 101, 125, 122, 36, 117, 77, 58, 31, 125, 118, 50, 57, 122, 120]), (tensor(0.9180, grad_fn=<SubBackward0>), [127, 108, 52, 86, 117, 49, 96, 57, 69, 122, 117, 83])]\n",
      "gen 19 [(tensor(0.9625, grad_fn=<SubBackward0>), [127, 108, 52, 86, 42, 49, 96, 57, 69, 122, 117, 96, 49, 96, 69]), (tensor(0.8889, grad_fn=<SubBackward0>), [64, 96, 49, 96, 69, 69, 25, 122, 60, 49, 117, 57, 114]), (tensor(0.8203, grad_fn=<SubBackward0>), [127, 108, 13, 52, 86, 122, 120])]\n"
     ]
    }
   ],
   "source": [
    "population = init_population(20, max_layers=20, max_neurons=128*1)\n",
    "best_loss = float('inf')\n",
    "genscore = []\n",
    "for gen in range(1,20):    \n",
    "\n",
    "    accuracy = []\n",
    "    for pop_number, hiddenlayers in enumerate(population):\n",
    "        model = nn(2,1,torch.sigmoid,*hiddenlayers,lr=0.01)\n",
    "        for epoch in range(100):\n",
    "            y_pred = model.forward(xor_X)\n",
    "            loss = model.loss(xor_Y,y_pred).mean()\n",
    "            model.backpropagation(loss)\n",
    "            '''\n",
    "            if loss < best_loss:\n",
    "                if epoch :\n",
    "                    print(f\"population {pop_number} epoch {epoch} loss {loss}\")\n",
    "                    #print(model.weights)\n",
    "            '''\n",
    "        accuracy.append(1-loss)     \n",
    "        if loss < best_loss:\n",
    "            print('hidden layer',hiddenlayers)\n",
    "            print(f\"population {pop_number}\")\n",
    "            y_pred = model.forward(xor_X)\n",
    "            print(y_pred)\n",
    "            best_loss = loss\n",
    "    parents, score = select_parents(population, accuracy)\n",
    "    population = breed_population(parents, 15, gen)\n",
    "    population.extend(init_population(5, max_layers=20, max_neurons=128))\n",
    "    print('gen',gen, score[:3])\n",
    "    genscore.append(zip(score,[gen]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ee6ab169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<zip object at 0x000001FAEE51F800>,) (<zip object at 0x000001FAEE51F1C0>,) (<zip object at 0x000001FAEE51EAC0>,) (<zip object at 0x000001FAEE51FB80>,) (<zip object at 0x000001FAEE550D40>,)\n"
     ]
    }
   ],
   "source": [
    "print(*zip(genscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dcf3e851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((tensor(0.6133, grad_fn=<SubBackward0>), [86, 50, 15, 64, 110, 120, 57]), 1),)\n",
      "(((tensor(0.9021, grad_fn=<SubBackward0>), [92, 68, 17, 88, 94, 105, 123, 46, 79, 112, 120, 57]), 2),)\n",
      "(((tensor(0.8334, grad_fn=<SubBackward0>), [86, 50, 54, 64, 110, 120, 57]), 3),)\n",
      "(((tensor(0.8377, grad_fn=<SubBackward0>), [125, 36, 53, 76, 46, 21, 117, 64, 70, 96, 83, 96, 48, 65, 57]), 4),)\n",
      "(((tensor(0.9195, grad_fn=<SubBackward0>), [53, 76, 46, 40, 70, 96, 96, 48, 83, 96, 50, 65, 57, 73, 82]), 5),)\n",
      "(((tensor(0.9640, grad_fn=<SubBackward0>), [53, 76, 46, 70, 96, 96, 48, 83, 96, 50, 65, 57, 88, 96, 125]), 6),)\n",
      "(((tensor(0.9524, grad_fn=<SubBackward0>), [122, 28, 32, 71, 104, 59, 34, 116, 96, 48, 83, 115, 110, 120, 57]), 7),)\n",
      "(((tensor(0.9297, grad_fn=<SubBackward0>), [122, 28, 32, 71, 104, 59, 34, 116, 96, 48, 83, 115, 110, 120, 57, 74, 76]), 8),)\n",
      "(((tensor(0.9459, grad_fn=<SubBackward0>), [126, 59, 120, 91, 98, 126, 83, 120, 57]), 9),)\n",
      "(((tensor(0.9179, grad_fn=<SubBackward0>), [76, 64, 110, 120, 87, 46, 70, 83, 120, 57]), 10),)\n",
      "(((tensor(0.9130, grad_fn=<SubBackward0>), [112, 125, 121, 97]), 11),)\n",
      "(((tensor(0.8873, grad_fn=<SubBackward0>), [104, 60, 49, 99, 64, 69, 122, 60, 117, 57, 72]), 12),)\n",
      "(((tensor(0.9198, grad_fn=<SubBackward0>), [127, 108, 86, 103, 80, 96]), 13),)\n",
      "(((tensor(0.9620, grad_fn=<SubBackward0>), [112, 125, 102, 103, 80, 96]), 14),)\n",
      "(((tensor(0.9400, grad_fn=<SubBackward0>), [127, 108, 86, 103, 80, 49, 99, 64, 69, 122, 117, 83]), 15),)\n",
      "(((tensor(0.9716, grad_fn=<SubBackward0>), [31, 83, 116, 120, 117, 37, 58, 31, 83, 120, 117, 101, 125, 18, 122, 120]), 16),)\n",
      "(((tensor(0.9386, grad_fn=<SubBackward0>), [127, 108, 52, 86, 117, 37, 58, 31, 69, 122, 60, 117, 57, 114, 72]), 17),)\n",
      "(((tensor(0.9692, grad_fn=<SubBackward0>), [105, 31, 125, 118, 50, 57, 122, 120]), 18),)\n",
      "(((tensor(0.9625, grad_fn=<SubBackward0>), [127, 108, 52, 86, 42, 49, 96, 57, 69, 122, 117, 96, 49, 96, 69]), 19),)\n"
     ]
    }
   ],
   "source": [
    "for i in genscore:\n",
    "    print(*zip(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61f04b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 2050\n",
      "Current device index: 0\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCurrent device index:\u001b[39m\u001b[33m\"\u001b[39m, torch.cuda.current_device())\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create a tensor on GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTensor on GPU:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, x)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Move it back to CPU\u001b[39;00m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get GPU name\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Current device index:\", torch.cuda.current_device())\n",
    "\n",
    "    # Create a tensor on GPU\n",
    "    x = torch.rand((3,3), device=\"cuda\")\n",
    "    print(\"Tensor on GPU:\\n\", x)\n",
    "\n",
    "    # Move it back to CPU\n",
    "    y = x.to(\"cpu\")\n",
    "    print(\"Tensor moved back to CPU:\\n\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc57dd2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
